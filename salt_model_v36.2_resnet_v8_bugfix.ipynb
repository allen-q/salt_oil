{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUnFr6MO3Kk3"
   },
   "source": [
    "# Changes:\n",
    "1. Based on V35.1\n",
    "2. Fixed a bug where the encoder2 group is added twice in optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaO5fG0VW5gB"
   },
   "source": [
    "## Install required packages if running on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n6EgF7sW5gC"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install torch torchvision\n",
    "    !pip install imageio\n",
    "    !pip install Augmentor\n",
    "    !git clone https://github.com/allen-q/salt_oil.git\n",
    "    !git clone https://github.com/allen-q/salt_net.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p3h4PngQ0s86",
    "outputId": "6c9e749e-3aa5-4e04-d916-bd69201e64b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/salt_oil\n"
     ]
    }
   ],
   "source": [
    "cd salt_oil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVnBJygnW5gK"
   },
   "source": [
    "## Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1VSamfH3Kk6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as ply\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import pickle\n",
    "from salt_func_lib import *\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "import datetime as dt\n",
    "import sys\n",
    "from optparse import OptionParser\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "from io import BytesIO\n",
    "import random\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I87qLhAOW5gO"
   },
   "source": [
    "## Load Unet Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC32auGDqVZi"
   },
   "outputs": [],
   "source": [
    "from pytorch_unet.eval import eval_net\n",
    "from pytorch_unet.unet import UNet\n",
    "from pytorch_unet.unet.unet_parts import *\n",
    "from pytorch_unet.unet.resnet_v8 import *\n",
    "from pytorch_unet.utils import get_ids, split_ids, split_train_val, get_imgs_and_masks, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6O8Wz9H_iTDE"
   },
   "outputs": [],
   "source": [
    "## Setup data type based on whether GPU is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QKYhIfCtEk6C",
    "outputId": "129803f7-278b-4b9d-e607-713b6f5fbfaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type set to: <class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "else:    \n",
    "    dtype = torch.FloatTensor\n",
    "print(f'Data Type set to: {dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRawI4_RdLLk"
   },
   "outputs": [],
   "source": [
    "def setup_train(config_list):\n",
    "    for conf in config_list:\n",
    "        log.info(conf)\n",
    "    for conf in config_list:\n",
    "        exec(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30EV6nbKbtyV"
   },
   "source": [
    "## Create Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5JTwFPaaZB1"
   },
   "outputs": [],
   "source": [
    "global log\n",
    "log = get_logger('salt_model_v36.2_resnet_v8_bugfix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEXPdEFd3KmA"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53yVOPsQ3KmB"
   },
   "source": [
    "### Load train and test data from npy files or from raw images if npy files not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "wO1kf6HW3KmC",
    "outputId": "ab3a17e1-0dd3-4fb3-e27a-3837453c980d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try loading data from npy and pickle files...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "np_train_all, np_train_all_mask, X_test, misc_data = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNIS7zT23KmI"
   },
   "source": [
    "### Train Val data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2L51fSDkpyNV"
   },
   "outputs": [],
   "source": [
    "df_train_mask = pd.DataFrame((np_train_all_mask/255).sum((1,2,3)), columns=['mask_pix'])\n",
    "df_train_mask.mask_pix = df_train_mask.mask_pix.round(-2)\n",
    "\n",
    "X_train_ids, X_val_ids = (\n",
    "    train_test_split(df_train_mask.index.tolist(), \n",
    "                     test_size=0.20,\n",
    "                     stratify = df_train_mask.mask_pix,\n",
    "                     random_state=0)\n",
    ")\n",
    "\n",
    "X_train = np_train_all[X_train_ids]\n",
    "X_val = np_train_all[X_val_ids]\n",
    "y_train = np_train_all_mask[X_train_ids]\n",
    "y_val = np_train_all_mask[X_val_ids]\n",
    "depth_train = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_train_all_ids'])[X_train_ids])\n",
    ")\n",
    "depth_val = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_train_all_ids'])[X_val_ids])\n",
    ")\n",
    "depth_test = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_test_ids']))\n",
    ")\n",
    "#X_train_mean_img = X_train.mean(0).astype(np.float32)\n",
    "#X_train_mean_img = X_train.mean((0,1,2)).astype(np.float32)\n",
    "X_train_mean_img = np.clip(np_train_all/255, 0, 1).mean((0,1,2)).astype(np.float32)\n",
    "#set mean image to 0 as mean is now being handled within the model.\n",
    "X_train_mean_img = np.zeros_like(X_train_mean_img)\n",
    "\n",
    "all_data = {\n",
    "    'X_train': X_train,\n",
    "    'X_val': X_val,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'X_test': X_test,\n",
    "    'X_train_mean_img': X_train_mean_img\n",
    "}\n",
    "\n",
    "assert X_train_mean_img == np.array([0.])\n",
    "assert X_train.shape == (3200, 101, 101, 1)\n",
    "assert y_train.shape == (3200, 101, 101, 1)\n",
    "assert depth_train.shape == (3200, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dasEpZc0QmOt"
   },
   "source": [
    "## Train the model using a small data set to see if it can overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOakYP-HaZCN"
   },
   "outputs": [],
   "source": [
    "data_loader_config = '''\n",
    "train_data_params = {'batch_size': 2, 'shuffle': True,}\n",
    "val_data_params = {'batch_size': 2, 'shuffle': True,}\n",
    "train_dataLoader  = (\n",
    "    DataLoader(SaltDataset(X_train[:4], y_train[:4], depth_train[:4],\n",
    "                           X_train_mean_img, out_size=128, out_ch=1,\n",
    "                           transform=None), **train_data_params)\n",
    "                           #transform=p.torch_transform()), **data_params)\n",
    ")\n",
    "\n",
    "val_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_val[:4], y_val[:4], depth_val[:4], \n",
    "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gzDNlNTaZCa"
   },
   "outputs": [],
   "source": [
    "model_config = '''\n",
    "saltnet = UResNet(pretrained=True)\n",
    "\n",
    "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
    "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
    "loss_lovasz_hinge = LovaszHingeLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True, threshold=0.001)\n",
    "model_save_name = None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4azPo_ryaZCf"
   },
   "outputs": [],
   "source": [
    "train_params_config = '''\n",
    "train_params = {\n",
    "    'model_save_name': None,\n",
    "    'save_model_every': 10000,\n",
    "    'save_log_every': 100,\n",
    "    'num_epochs': 10,\n",
    "    'print_every': 2,\n",
    "    'log': log,\n",
    "    'mask_cutoff': 0,\n",
    "    'model_save_iou_threshold': 0.1\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xhF5_R0aZCk"
   },
   "outputs": [],
   "source": [
    "model_run_config = '''\n",
    "model = train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.5), optimizer, scheduler, train_params, all_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sO7XLEJgaZCq"
   },
   "outputs": [],
   "source": [
    "config_list = [data_loader_config, model_config, train_params_config, model_run_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pE7Q6dd3xPBR"
   },
   "outputs": [],
   "source": [
    "setup_train(config_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJ3DJ4hAQmOw"
   },
   "source": [
    "## Train the full with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AZkSxKV2sIkN",
    "outputId": "4a663add-e9ff-44ac-e81f-26589c182f4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2018 11:57:10 - salt_model_v36_resnet_0.82_baseline - INFO - Rerun the IOU 0.82 Unet34 baseline\n"
     ]
    }
   ],
   "source": [
    "log.info('salt_model_v36.2_resnet_v8_bugfix. Based on V35.1. Fixed a bug where the encoder2 group is added twice in optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_sJ4aApaZDB"
   },
   "outputs": [],
   "source": [
    "aug_pipeline_config = '''\n",
    "p = Pipeline_Salt()\n",
    "p.skew(probability=0.5, magnitude=0.3)\n",
    "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
    "p.crop_random_align(probability=1.0, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)\n",
    "p.rotate(probability=0.5, max_left_rotation=15, max_right_rotation=15)\n",
    "p.shear(probability=0.5, max_shear_left=15, max_shear_right=15)\n",
    "p.flip_left_right(probability=0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7gYECBYaZDJ"
   },
   "outputs": [],
   "source": [
    "data_loader_config = '''\n",
    "train_data_params = {'batch_size': 32,\n",
    "                     #'sampler': weighted_sampler,\n",
    "                     'shuffle': True,\n",
    "                     'drop_last': False}\n",
    "\n",
    "val_data_params = {'batch_size': 32,\n",
    "                   'shuffle': True,\n",
    "                   'drop_last': False}\n",
    "\n",
    "train_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
    "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
    "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
    ")\n",
    "\n",
    "val_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
    "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2E3iHDtlaZDR"
   },
   "outputs": [],
   "source": [
    "model_config = '''\n",
    "saltnet = UResNet(pretrained=True)\n",
    "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
    "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
    "loss_lovasz_hinge = LovaszHingeLoss()\n",
    "resnet_params = (\n",
    "    list(saltnet.conv1.parameters()) + \n",
    "    list(saltnet.encoder2.parameters()) + \n",
    "    list(saltnet.encoder3.parameters()) + \n",
    "    list(saltnet.encoder4.parameters()) + \n",
    "    list(saltnet.encoder5.parameters())\n",
    ")\n",
    "\n",
    "unet_params = (\n",
    "    list(saltnet.center.parameters()) + \n",
    "    list(saltnet.decoder5.parameters()) + \n",
    "    list(saltnet.decoder4.parameters()) + \n",
    "    list(saltnet.decoder3.parameters()) + \n",
    "    list(saltnet.decoder2.parameters()) + \n",
    "    list(saltnet.decoder1.parameters())  + \n",
    "    list(saltnet.outc.parameters())\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam([    \n",
    "    {'params': resnet_params, 'lr': 1e-4, 'weight_decay': 1e-7},\n",
    "    {'params': unet_params, 'lr': 1e-3, 'weight_decay': 1e-7},\n",
    "])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.001, min_lr=0.00001)\n",
    "\n",
    "model_save_name = f'../salt_net/salt_model_v36.2_resnet_v8_bugfix_{get_current_time_as_fname()}.ckp'\n",
    "log.info(model_save_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0YGWcupaZDW"
   },
   "outputs": [],
   "source": [
    "train_params_config = '''\n",
    "train_params = {\n",
    "    'model_save_name': model_save_name,\n",
    "    'save_model_every': 20,\n",
    "    'save_log_every': 2,\n",
    "    'num_epochs': 200,\n",
    "    'log': log,\n",
    "    'mask_cutoff': 0.,\n",
    "    'model_save_iou_threshold': 0.82\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Njb68KldaZDZ"
   },
   "outputs": [],
   "source": [
    "model_run_config = '''\n",
    "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VbLGjnuaZDc"
   },
   "outputs": [],
   "source": [
    "config_list = [aug_pipeline_config, data_loader_config, model_config, train_params_config, model_run_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1316
    },
    "colab_type": "code",
    "id": "YTb0lfCGaZDe",
    "outputId": "a26d89ff-710f-4f08-ad29-7f2c4e07bcd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2018 11:57:17 - salt_model_v36_resnet_0.82_baseline - INFO - \n",
      "p = Pipeline_Salt()\n",
      "p.skew(probability=0.5, magnitude=0.2)\n",
      "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
      "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
      "p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
      "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
      "p.flip_left_right(probability=0.5)\n",
      "\n",
      "01/10/2018 11:57:17 - salt_model_v36_resnet_0.82_baseline - INFO - \n",
      "train_data_params = {'batch_size': 32,\n",
      "                     #'sampler': weighted_sampler,\n",
      "                     'shuffle': True,\n",
      "                     'drop_last': False}\n",
      "\n",
      "val_data_params = {'batch_size': 32,\n",
      "                   'shuffle': True,\n",
      "                   'drop_last': False}\n",
      "\n",
      "train_dataLoader = (\n",
      "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
      "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
      "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
      ")\n",
      "\n",
      "val_dataLoader = (\n",
      "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
      "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
      ")\n",
      "\n",
      "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
      "\n",
      "01/10/2018 11:57:17 - salt_model_v36_resnet_0.82_baseline - INFO - \n",
      "saltnet = UResNet(pretrained=True)\n",
      "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
      "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
      "loss_lovasz_hinge = LovaszHingeLoss()\n",
      "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
      "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
      "\n",
      "model_save_name = f'../salt_net/salt_model_v36_resnet_0.82_baseline_{get_current_time_as_fname()}.ckp'\n",
      "log.info(model_save_name)\n",
      "\n",
      "01/10/2018 11:57:17 - salt_model_v36_resnet_0.82_baseline - INFO - \n",
      "train_params = {\n",
      "    'model_save_name': model_save_name,\n",
      "    'save_model_every': 20,\n",
      "    'save_log_every': 2,\n",
      "    'num_epochs': 200,\n",
      "    'log': log,\n",
      "    'mask_cutoff': 0.,\n",
      "    'model_save_iou_threshold': 0.82\n",
      "    }\n",
      "\n",
      "01/10/2018 11:57:17 - salt_model_v36_resnet_0.82_baseline - INFO - \n",
      "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet using pretrained weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2018 11:57:21 - salt_model_v36_resnet_0.82_baseline - INFO - ../salt_net/salt_model_v36_resnet_0.82_baseline_2018_10_01_21_57_21.ckp\n",
      "01/10/2018 11:57:21 - salt_model_v36_resnet_0.82_baseline - INFO - Start Training...\n",
      "01/10/2018 11:57:21 - salt_model_v36_resnet_0.82_baseline - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7feb4e888ef0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7feb4e888f28>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.1), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7feb16d57828>, {'model_save_name': '../salt_net/salt_model_v36_resnet_0.82_baseline_2018_10_01_21_57_21.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 200, 'log': <Logger salt_model_v36_resnet_0.82_baseline (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.82})\n",
      "01/10/2018 11:57:21 - salt_model_v36_resnet_0.82_baseline - INFO - Epoch 1/200\n",
      "01/10/2018 11:57:21 - salt_model_v36_resnet_0.82_baseline - INFO - --------------------\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "setup_train(config_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iM7YI8_BetLD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "salt_model_data_loader_V3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
