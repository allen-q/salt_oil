{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "salt_model_data_loader_V3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IUnFr6MO3Kk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Changes:\n",
        "1. Based on V35.1\n",
        "2. Fixed a bug where the encoder2 group is added twice in optimizer"
      ]
    },
    {
      "metadata": {
        "id": "xaO5fG0VW5gB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install required packages if running on google colab"
      ]
    },
    {
      "metadata": {
        "id": "8n6EgF7sW5gC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "09af9a47-5e88-4b5b-a65c-dd5631178099"
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    !pip install torch torchvision\n",
        "    !pip install imageio\n",
        "    !pip install Augmentor\n",
        "    !git clone https://github.com/allen-q/salt_oil.git\n",
        "    !git clone https://github.com/allen-q/salt_net.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58bca000 @  0x7f8af645a1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 19.1MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n",
            "Collecting imageio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b4/cbb592964dfd71a9de6a5b08f882fd334fb99ae09ddc82081dbb2f718c81/imageio-2.4.1.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (5.3.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Running setup.py bdist_wheel for imageio ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e0/43/31/605de9372ceaf657f152d3d5e82f42cf265d81db8bbe63cde1\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "Successfully installed imageio-2.4.1\n",
            "Collecting Augmentor\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/f4/b0eaa9d3b4120a5450ac92d4417907ca60fad5749c1f50ed95f720792350/Augmentor-0.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (5.3.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.26.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.14.6)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.3\n",
            "Cloning into 'salt_oil'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 1216 (delta 115), reused 58 (delta 30), pack-reused 1021\u001b[K\n",
            "Receiving objects: 100% (1216/1216), 616.83 MiB | 31.63 MiB/s, done.\n",
            "Resolving deltas: 100% (749/749), done.\n",
            "Checking out files: 100% (152/152), done.\n",
            "Cloning into 'salt_net'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 8516 (delta 147), reused 98 (delta 50), pack-reused 8321\u001b[K\n",
            "Receiving objects: 100% (8516/8516), 2.76 GiB | 38.88 MiB/s, done.\n",
            "Resolving deltas: 100% (3365/3365), done.\n",
            "Checking out files: 100% (4210/4210), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p3h4PngQ0s86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2b00768-76e2-47d6-b117-e5eac31155ae"
      },
      "cell_type": "code",
      "source": [
        "cd salt_oil"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/salt_oil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UVnBJygnW5gK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import required libs"
      ]
    },
    {
      "metadata": {
        "id": "x1VSamfH3Kk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ply\n",
        "import os\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import pickle\n",
        "from salt_func_lib import *\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "import datetime as dt\n",
        "import sys\n",
        "from optparse import OptionParser\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "from io import BytesIO\n",
        "import random\n",
        "import PIL\n",
        "import cv2 as cv\n",
        "% matplotlib inline\n",
        "% load_ext autoreload\n",
        "% autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I87qLhAOW5gO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Unet Modules"
      ]
    },
    {
      "metadata": {
        "id": "eC32auGDqVZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pytorch_unet.eval import eval_net\n",
        "from pytorch_unet.unet import UNet\n",
        "from pytorch_unet.unet.unet_parts import *\n",
        "from pytorch_unet.unet.resnet_v8 import *\n",
        "from pytorch_unet.utils import get_ids, split_ids, split_train_val, get_imgs_and_masks, batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O8Wz9H_iTDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Setup data type based on whether GPU is enabled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKYhIfCtEk6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94908b79-e882-40de-b2c3-303144817075"
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
        "else:    \n",
        "    dtype = torch.FloatTensor\n",
        "print(f'Data Type set to: {dtype}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Type set to: <class 'torch.cuda.FloatTensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lRawI4_RdLLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def setup_train(config_list):\n",
        "    for conf in config_list:\n",
        "        log.info(conf)\n",
        "    for conf in config_list:\n",
        "        exec(conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30EV6nbKbtyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Logger"
      ]
    },
    {
      "metadata": {
        "id": "s5JTwFPaaZB1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global log\n",
        "log = get_logger('salt_model_v36.2_resnet_v8_bugfix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEXPdEFd3KmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "53yVOPsQ3KmB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load train and test data from npy files or from raw images if npy files not exist."
      ]
    },
    {
      "metadata": {
        "id": "wO1kf6HW3KmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "044ae518-7007-489a-f6fe-b999e0e0a748"
      },
      "cell_type": "code",
      "source": [
        "np_train_all, np_train_all_mask, X_test, misc_data = load_all_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Try loading data from npy and pickle files...\n",
            "Data loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DNIS7zT23KmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Val data split"
      ]
    },
    {
      "metadata": {
        "id": "2L51fSDkpyNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_mask = pd.DataFrame((np_train_all_mask/255).sum((1,2,3)), columns=['mask_pix'])\n",
        "df_train_mask.mask_pix = df_train_mask.mask_pix.round(-2)\n",
        "\n",
        "X_train_ids, X_val_ids = (\n",
        "    train_test_split(df_train_mask.index.tolist(), \n",
        "                     test_size=0.20,\n",
        "                     stratify = df_train_mask.mask_pix,\n",
        "                     random_state=0)\n",
        ")\n",
        "\n",
        "X_train = np_train_all[X_train_ids]\n",
        "X_val = np_train_all[X_val_ids]\n",
        "y_train = np_train_all_mask[X_train_ids]\n",
        "y_val = np_train_all_mask[X_val_ids]\n",
        "depth_train = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_train_ids])\n",
        ")\n",
        "depth_val = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_val_ids])\n",
        ")\n",
        "depth_test = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_test_ids']))\n",
        ")\n",
        "#X_train_mean_img = X_train.mean(0).astype(np.float32)\n",
        "#X_train_mean_img = X_train.mean((0,1,2)).astype(np.float32)\n",
        "X_train_mean_img = np.clip(np_train_all/255, 0, 1).mean((0,1,2)).astype(np.float32)\n",
        "#set mean image to 0 as mean is now being handled within the model.\n",
        "X_train_mean_img = np.zeros_like(X_train_mean_img)\n",
        "\n",
        "all_data = {\n",
        "    'X_train': X_train,\n",
        "    'X_val': X_val,\n",
        "    'y_train': y_train,\n",
        "    'y_val': y_val,\n",
        "    'X_test': X_test,\n",
        "    'X_train_mean_img': X_train_mean_img\n",
        "}\n",
        "\n",
        "assert X_train_mean_img == np.array([0.])\n",
        "assert X_train.shape == (3200, 101, 101, 1)\n",
        "assert y_train.shape == (3200, 101, 101, 1)\n",
        "assert depth_train.shape == (3200, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dasEpZc0QmOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model using a small data set to see if it can overfit"
      ]
    },
    {
      "metadata": {
        "id": "EOakYP-HaZCN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_loader_config = '''\n",
        "train_data_params = {'batch_size': 2, 'shuffle': True,}\n",
        "val_data_params = {'batch_size': 2, 'shuffle': True,}\n",
        "train_dataLoader  = (\n",
        "    DataLoader(SaltDataset(X_train[:4], y_train[:4], depth_train[:4],\n",
        "                           X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=None), **train_data_params)\n",
        "                           #transform=p.torch_transform()), **data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val[:4], y_val[:4], depth_val[:4], \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gzDNlNTaZCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "saltnet = UResNet(pretrained=True)\n",
        "\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True, threshold=0.001)\n",
        "model_save_name = None\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4azPo_ryaZCf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params_config = '''\n",
        "train_params = {\n",
        "    'model_save_name': None,\n",
        "    'save_model_every': 10000,\n",
        "    'save_log_every': 100,\n",
        "    'num_epochs': 10,\n",
        "    'print_every': 2,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0,\n",
        "    'model_save_iou_threshold': 0.1\n",
        "    }\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xhF5_R0aZCk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_run_config = '''\n",
        "model = train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.5), optimizer, scheduler, train_params, all_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sO7XLEJgaZCq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config_list = [data_loader_config, model_config, train_params_config, model_run_config]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pE7Q6dd3xPBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "setup_train(config_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJ3DJ4hAQmOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the full with full dataset"
      ]
    },
    {
      "metadata": {
        "id": "AZkSxKV2sIkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d998c54e-1696-4b4c-f7fb-6743f4548a94"
      },
      "cell_type": "code",
      "source": [
        "log.info('salt_model_v36.2_resnet_v8_bugfix. Based on V35.1. Fixed a bug where the encoder2 group is added twice in optimizer')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/10/2018 12:28:40 - salt_model_v36.2_resnet_v8_bugfix - INFO - salt_model_v36.2_resnet_v8_bugfix. Based on V35.1. Fixed a bug where the encoder2 group is added twice in optimizer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_sJ4aApaZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aug_pipeline_config = '''\n",
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.3)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=1.0, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)\n",
        "p.rotate_random_90(probability=0.75)\n",
        "p.rotate(probability=0.5, max_left_rotation=5, max_right_rotation=5)\n",
        "p.shear(probability=0.5, max_shear_left=5, max_shear_right=5)\n",
        "p.flip_left_right(probability=0.5)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7gYECBYaZDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_loader_config = '''\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2E3iHDtlaZDR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "saltnet = UResNet(pretrained=True)\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters())  + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-4, 'weight_decay': 1e-7},\n",
        "    {'params': unet_params, 'lr': 1e-3, 'weight_decay': 1e-7},\n",
        "])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.001, min_lr=0.000001)\n",
        "\n",
        "model_save_name = f'../salt_net/salt_model_v36.2_resnet_v8_bugfix_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0YGWcupaZDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params_config = '''\n",
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 200,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.82\n",
        "    }\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Njb68KldaZDZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_run_config = '''\n",
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-VbLGjnuaZDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config_list = [aug_pipeline_config, data_loader_config, model_config, train_params_config, model_run_config]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTb0lfCGaZDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1868
        },
        "outputId": "32160646-a31e-4704-8412-5fa2267193ae"
      },
      "cell_type": "code",
      "source": [
        "setup_train(config_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/10/2018 12:35:06 - salt_model_v36.2_resnet_v8_bugfix - INFO - \n",
            "p = Pipeline_Salt()\n",
            "p.skew(probability=0.5, magnitude=0.3)\n",
            "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
            "p.crop_random_align(probability=1.0, min_factor=0.6, max_factor=1.0, mask_diff_pct=0.2)\n",
            "p.rotate_random_90(probability=0.75)\n",
            "p.rotate(probability=0.5, max_left_rotation=5, max_right_rotation=5)\n",
            "p.shear(probability=0.5, max_shear_left=5, max_shear_right=5)\n",
            "p.flip_left_right(probability=0.5)\n",
            "\n",
            "01/10/2018 12:35:06 - salt_model_v36.2_resnet_v8_bugfix - INFO - \n",
            "train_data_params = {'batch_size': 32,\n",
            "                     #'sampler': weighted_sampler,\n",
            "                     'shuffle': True,\n",
            "                     'drop_last': False}\n",
            "\n",
            "val_data_params = {'batch_size': 32,\n",
            "                   'shuffle': True,\n",
            "                   'drop_last': False}\n",
            "\n",
            "train_dataLoader = (\n",
            "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
            "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
            "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
            ")\n",
            "\n",
            "val_dataLoader = (\n",
            "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
            "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
            ")\n",
            "\n",
            "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
            "\n",
            "01/10/2018 12:35:06 - salt_model_v36.2_resnet_v8_bugfix - INFO - \n",
            "saltnet = UResNet(pretrained=True)\n",
            "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
            "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
            "loss_lovasz_hinge = LovaszHingeLoss()\n",
            "resnet_params = (\n",
            "    list(saltnet.conv1.parameters()) + \n",
            "    list(saltnet.encoder2.parameters()) + \n",
            "    list(saltnet.encoder3.parameters()) + \n",
            "    list(saltnet.encoder4.parameters()) + \n",
            "    list(saltnet.encoder5.parameters())\n",
            ")\n",
            "\n",
            "unet_params = (\n",
            "    list(saltnet.center.parameters()) + \n",
            "    list(saltnet.decoder5.parameters()) + \n",
            "    list(saltnet.decoder4.parameters()) + \n",
            "    list(saltnet.decoder3.parameters()) + \n",
            "    list(saltnet.decoder2.parameters()) + \n",
            "    list(saltnet.decoder1.parameters())  + \n",
            "    list(saltnet.outc.parameters())\n",
            ")\n",
            "\n",
            "optimizer = optim.Adam([    \n",
            "    {'params': resnet_params, 'lr': 1e-4, 'weight_decay': 1e-7},\n",
            "    {'params': unet_params, 'lr': 1e-3, 'weight_decay': 1e-7},\n",
            "])\n",
            "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.001, min_lr=0.000001)\n",
            "\n",
            "model_save_name = f'../salt_net/salt_model_v36.2_resnet_v8_bugfix_{get_current_time_as_fname()}.ckp'\n",
            "log.info(model_save_name)\n",
            "\n",
            "01/10/2018 12:35:06 - salt_model_v36.2_resnet_v8_bugfix - INFO - \n",
            "train_params = {\n",
            "    'model_save_name': model_save_name,\n",
            "    'save_model_every': 20,\n",
            "    'save_log_every': 2,\n",
            "    'num_epochs': 200,\n",
            "    'log': log,\n",
            "    'mask_cutoff': 0.,\n",
            "    'model_save_iou_threshold': 0.82\n",
            "    }\n",
            "\n",
            "01/10/2018 12:35:06 - salt_model_v36.2_resnet_v8_bugfix - INFO - \n",
            "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet using pretrained weights.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:03<00:00, 27774018.80it/s]\n",
            "01/10/2018 12:35:12 - salt_model_v36.2_resnet_v8_bugfix - INFO - ../salt_net/salt_model_v36.2_resnet_v8_bugfix_2018_10_01_22_35_12.ckp\n",
            "01/10/2018 12:35:12 - salt_model_v36.2_resnet_v8_bugfix - INFO - Start Training...\n",
            "01/10/2018 12:35:12 - salt_model_v36.2_resnet_v8_bugfix - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7ff9fde90a90>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7ff9fde906a0>}, (BCEWithLogitsLoss(), LovaszHingeLoss()), (1, 0.1), Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0001\n",
            "    weight_decay: 1e-07\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 1e-07\n",
            "), <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7ff97ff595c0>, {'model_save_name': '../salt_net/salt_model_v36.2_resnet_v8_bugfix_2018_10_01_22_35_12.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 200, 'log': <Logger salt_model_v36.2_resnet_v8_bugfix (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.82})\n",
            "01/10/2018 12:35:12 - salt_model_v36.2_resnet_v8_bugfix - INFO - Epoch 1/200\n",
            "01/10/2018 12:35:12 - salt_model_v36.2_resnet_v8_bugfix - INFO - --------------------\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iM7YI8_BetLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}