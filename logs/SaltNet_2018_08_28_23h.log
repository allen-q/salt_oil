28/08/2018 23:31:09 - SaltNet - INFO - Start Training...
28/08/2018 23:31:09 - SaltNet - INFO - Passed parameters: ['log', 'push_every', 'print_every', 'num_epochs', 'other_data', 'model_save_name', 'scheduler', 'optimizer', 'criterion', 'dataloaders', 'model']
28/08/2018 23:31:09 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:31:09 - SaltNet - INFO - --------------------
28/08/2018 23:31:17 - SaltNet - INFO - Batch Loss: 4.1380, Running loss: 4.1380, Batch IOU: 0.0000, Batch Acc: 0.3959 at iter 2, epoch 0, Time: 0m 7s
28/08/2018 23:35:16 - SaltNet - INFO - Start Training...
28/08/2018 23:35:16 - SaltNet - INFO - Passed parameters: [('log', <Logger SaltNet (DEBUG)>), ('push_every', None), ('print_every', 2), ('num_epochs', 50), ('other_data', {'X_train': array([[[[0.4627451 ],
         [0.47058824],
         [0.47058824],
         ...,
         [0.20392157],
         [0.38039216],
         [0.65882353]],

        [[0.45882353],
         [0.48627451],
         [0.50588235],
         ...,
         [0.21568627],
         [0.34901961],
         [0.61568627]],

        [[0.4745098 ],
         [0.51372549],
         [0.54509804],
         ...,
         [0.2627451 ],
         [0.36078431],
         [0.57647059]],

        ...,

        [[0.6       ],
         [0.58823529],
         [0.58431373],
         ...,
         [0.68627451],
         [0.71372549],
         [0.70980392]],

        [[0.59215686],
         [0.60392157],
         [0.61960784],
         ...,
         [0.69803922],
         [0.71764706],
         [0.70196078]],

        [[0.62352941],
         [0.65882353],
         [0.68627451],
         ...,
         [0.68627451],
         [0.69803922],
         [0.67843137]]],


       [[[0.28235294],
         [0.28627451],
         [0.28627451],
         ...,
         [0.33333333],
         [0.45098039],
         [0.57647059]],

        [[0.29411765],
         [0.30196078],
         [0.31372549],
         ...,
         [0.4627451 ],
         [0.56078431],
         [0.60392157]],

        [[0.33333333],
         [0.36470588],
         [0.39607843],
         ...,
         [0.55294118],
         [0.59607843],
         [0.57647059]],

        ...,

        [[0.34901961],
         [0.36078431],
         [0.37254902],
         ...,
         [0.27843137],
         [0.30196078],
         [0.3254902 ]],

        [[0.34117647],
         [0.35686275],
         [0.36862745],
         ...,
         [0.29803922],
         [0.3254902 ],
         [0.34509804]],

        [[0.34117647],
         [0.34901961],
         [0.36078431],
         ...,
         [0.31764706],
         [0.34509804],
         [0.36470588]]],


       [[[0.50980392],
         [0.51372549],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50196078],
         [0.4627451 ]],

        [[0.50196078],
         [0.50980392],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50588235],
         [0.48627451]],

        [[0.49803922],
         [0.50196078],
         [0.50588235],
         ...,
         [0.5254902 ],
         [0.50196078],
         [0.49411765]],

        ...,

        [[0.49019608],
         [0.4627451 ],
         [0.42745098],
         ...,
         [0.25490196],
         [0.34509804],
         [0.44313725]],

        [[0.45490196],
         [0.41176471],
         [0.38039216],
         ...,
         [0.4       ],
         [0.48627451],
         [0.56078431]],

        [[0.39607843],
         [0.36078431],
         [0.3254902 ],
         ...,
         [0.54117647],
         [0.60392157],
         [0.63921569]]],


       ...,


       [[[0.64313725],
         [0.52156863],
         [0.50980392],
         ...,
         [0.34901961],
         [0.35294118],
         [0.40392157]],

        [[0.58823529],
         [0.47843137],
         [0.39607843],
         ...,
         [0.32941176],
         [0.3372549 ],
         [0.38039216]],

        [[0.51764706],
         [0.48627451],
         [0.37647059],
         ...,
         [0.32156863],
         [0.32941176],
         [0.36078431]],

        ...,

        [[0.47843137],
         [0.41176471],
         [0.38823529],
         ...,
         [0.67058824],
         [0.61960784],
         [0.63921569]],

        [[0.40392157],
         [0.39215686],
         [0.38039216],
         ...,
         [0.67843137],
         [0.62352941],
         [0.63921569]],

        [[0.34509804],
         [0.37647059],
         [0.37254902],
         ...,
         [0.68235294],
         [0.62745098],
         [0.64313725]]],


       [[[0.43529412],
         [0.50588235],
         [0.49411765],
         ...,
         [0.70588235],
         [0.54117647],
         [0.50980392]],

        [[0.44313725],
         [0.52156863],
         [0.51764706],
         ...,
         [0.74901961],
         [0.52941176],
         [0.44313725]],

        [[0.52156863],
         [0.6       ],
         [0.58823529],
         ...,
         [0.78823529],
         [0.56470588],
         [0.43529412]],

        ...,

        [[0.29019608],
         [0.3372549 ],
         [0.2627451 ],
         ...,
         [0.50980392],
         [0.34901961],
         [0.30980392]],

        [[0.25882353],
         [0.32156863],
         [0.27843137],
         ...,
         [0.39215686],
         [0.25098039],
         [0.25490196]],

        [[0.34117647],
         [0.38823529],
         [0.36078431],
         ...,
         [0.33333333],
         [0.21176471],
         [0.23921569]]],


       [[[0.47058824],
         [0.52941176],
         [0.43529412],
         ...,
         [0.55294118],
         [0.54901961],
         [0.44313725]],

        [[0.41176471],
         [0.4       ],
         [0.38431373],
         ...,
         [0.55294118],
         [0.54117647],
         [0.41176471]],

        [[0.34901961],
         [0.37647059],
         [0.41568627],
         ...,
         [0.56078431],
         [0.50980392],
         [0.42745098]],

        ...,

        [[0.50980392],
         [0.48235294],
         [0.4745098 ],
         ...,
         [0.4627451 ],
         [0.5372549 ],
         [0.54117647]],

        [[0.4627451 ],
         [0.44313725],
         [0.43137255],
         ...,
         [0.4       ],
         [0.48235294],
         [0.54901961]],

        [[0.44313725],
         [0.45882353],
         [0.40392157],
         ...,
         [0.34901961],
         [0.43529412],
         [0.54901961]]]]), 'X_val': array([[[[0.34901961],
         [0.34117647],
         [0.35686275],
         ...,
         [0.37647059],
         [0.33333333],
         [0.33333333]],

        [[0.37254902],
         [0.36862745],
         [0.38823529],
         ...,
         [0.28627451],
         [0.2627451 ],
         [0.28235294]],

        [[0.40392157],
         [0.40392157],
         [0.41176471],
         ...,
         [0.23137255],
         [0.21960784],
         [0.25490196]],

        ...,

        [[0.41960784],
         [0.39607843],
         [0.36470588],
         ...,
         [0.61176471],
         [0.59607843],
         [0.56470588]],

        [[0.43137255],
         [0.40784314],
         [0.38823529],
         ...,
         [0.59607843],
         [0.56862745],
         [0.5254902 ]],

        [[0.43921569],
         [0.42745098],
         [0.42352941],
         ...,
         [0.56862745],
         [0.5372549 ],
         [0.49019608]]],


       [[[0.37647059],
         [0.40784314],
         [0.39215686],
         ...,
         [0.47058824],
         [0.50588235],
         [0.4745098 ]],

        [[0.44313725],
         [0.43529412],
         [0.40784314],
         ...,
         [0.41176471],
         [0.42352941],
         [0.4       ]],

        [[0.44313725],
         [0.41176471],
         [0.4       ],
         ...,
         [0.34901961],
         [0.3254902 ],
         [0.34509804]],

        ...,

        [[0.30588235],
         [0.31372549],
         [0.31764706],
         ...,
         [0.51372549],
         [0.49411765],
         [0.4745098 ]],

        [[0.3254902 ],
         [0.3254902 ],
         [0.3254902 ],
         ...,
         [0.50196078],
         [0.48627451],
         [0.47058824]],

        [[0.37254902],
         [0.36862745],
         [0.36078431],
         ...,
         [0.49019608],
         [0.48235294],
         [0.46666667]]],


       [[[0.55686275],
         [0.59607843],
         [0.62352941],
         ...,
         [0.44313725],
         [0.42745098],
         [0.4       ]],

        [[0.73333333],
         [0.77254902],
         [0.80784314],
         ...,
         [0.45882353],
         [0.44313725],
         [0.41176471]],

        [[0.88627451],
         [0.91764706],
         [0.94117647],
         ...,
         [0.4745098 ],
         [0.45882353],
         [0.43529412]],

        ...,

        [[0.32941176],
         [0.32941176],
         [0.32941176],
         ...,
         [0.26666667],
         [0.28627451],
         [0.30980392]],

        [[0.31372549],
         [0.30588235],
         [0.29803922],
         ...,
         [0.28235294],
         [0.30588235],
         [0.3254902 ]],

        [[0.30196078],
         [0.28627451],
         [0.27843137],
         ...,
         [0.30588235],
         [0.3254902 ],
         [0.34509804]]],


       ...,


       [[[0.09411765],
         [0.10196078],
         [0.09019608],
         ...,
         [0.39215686],
         [0.27843137],
         [0.34509804]],

        [[0.19607843],
         [0.21960784],
         [0.16470588],
         ...,
         [0.43921569],
         [0.33333333],
         [0.43137255]],

        [[0.35294118],
         [0.4       ],
         [0.31764706],
         ...,
         [0.5254902 ],
         [0.43921569],
         [0.54901961]],

        ...,

        [[0.33333333],
         [0.25882353],
         [0.23921569],
         ...,
         [0.58823529],
         [0.65882353],
         [0.66666667]],

        [[0.34901961],
         [0.2745098 ],
         [0.29411765],
         ...,
         [0.64313725],
         [0.67843137],
         [0.66666667]],

        [[0.35294118],
         [0.28627451],
         [0.33333333],
         ...,
         [0.63921569],
         [0.65098039],
         [0.63137255]]],


       [[[0.52156863],
         [0.52156863],
         [0.51372549],
         ...,
         [0.50588235],
         [0.50980392],
         [0.51372549]],

        [[0.5254902 ],
         [0.5372549 ],
         [0.52156863],
         ...,
         [0.51372549],
         [0.50980392],
         [0.50980392]],

        [[0.48627451],
         [0.49019608],
         [0.4745098 ],
         ...,
         [0.5372549 ],
         [0.53333333],
         [0.53333333]],

        ...,

        [[0.56078431],
         [0.56862745],
         [0.55294118],
         ...,
         [0.4745098 ],
         [0.50980392],
         [0.49019608]],

        [[0.55686275],
         [0.56078431],
         [0.54117647],
         ...,
         [0.51372549],
         [0.5372549 ],
         [0.48627451]],

        [[0.55686275],
         [0.55294118],
         [0.53333333],
         ...,
         [0.56078431],
         [0.54901961],
         [0.49019608]]],


       [[[0.23529412],
         [0.41176471],
         [0.54509804],
         ...,
         [0.56078431],
         [0.49411765],
         [0.43529412]],

        [[0.36078431],
         [0.5372549 ],
         [0.60784314],
         ...,
         [0.56078431],
         [0.49411765],
         [0.45098039]],

        [[0.52941176],
         [0.66666667],
         [0.63137255],
         ...,
         [0.55686275],
         [0.48235294],
         [0.46666667]],

        ...,

        [[0.54509804],
         [0.40784314],
         [0.3254902 ],
         ...,
         [0.44705882],
         [0.49411765],
         [0.4745098 ]],

        [[0.41176471],
         [0.32156863],
         [0.28235294],
         ...,
         [0.47058824],
         [0.51764706],
         [0.48627451]],

        [[0.32156863],
         [0.26666667],
         [0.2627451 ],
         ...,
         [0.49019608],
         [0.53333333],
         [0.49411765]]]]), 'y_train': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]]], dtype=uint8), 'y_val': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]]], dtype=uint8), 'X_test': array([[[[0.43921569],
         [0.49411765],
         [0.57254902],
         ...,
         [0.61568627],
         [0.73333333],
         [0.7254902 ]],

        [[0.45490196],
         [0.50980392],
         [0.57647059],
         ...,
         [0.61176471],
         [0.72941176],
         [0.70196078]],

        [[0.46666667],
         [0.52941176],
         [0.57254902],
         ...,
         [0.62745098],
         [0.7254902 ],
         [0.6745098 ]],

        ...,

        [[0.38039216],
         [0.44313725],
         [0.49019608],
         ...,
         [0.24313725],
         [0.30980392],
         [0.33333333]],

        [[0.39215686],
         [0.45098039],
         [0.48235294],
         ...,
         [0.33333333],
         [0.38823529],
         [0.41176471]],

        [[0.40784314],
         [0.45490196],
         [0.46666667],
         ...,
         [0.42745098],
         [0.47058824],
         [0.49803922]]],


       [[[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        ...,

        [[0.03529412],
         [0.03921569],
         [0.08235294],
         ...,
         [0.41176471],
         [0.47058824],
         [0.45490196]],

        [[0.43921569],
         [0.42745098],
         [0.47843137],
         ...,
         [0.38823529],
         [0.37647059],
         [0.33333333]],

        [[0.41176471],
         [0.43529412],
         [0.41568627],
         ...,
         [0.14117647],
         [0.10196078],
         [0.15686275]]],


       [[[0.63529412],
         [0.64705882],
         [0.63529412],
         ...,
         [0.28235294],
         [0.30588235],
         [0.27843137]],

        [[0.63137255],
         [0.63921569],
         [0.62352941],
         ...,
         [0.27843137],
         [0.30196078],
         [0.29803922]],

        [[0.63137255],
         [0.63137255],
         [0.61176471],
         ...,
         [0.25098039],
         [0.27843137],
         [0.2745098 ]],

        ...,

        [[0.67058824],
         [0.71764706],
         [0.7372549 ],
         ...,
         [0.67058824],
         [0.63921569],
         [0.58823529]],

        [[0.65098039],
         [0.70196078],
         [0.72156863],
         ...,
         [0.69803922],
         [0.65098039],
         [0.59215686]],

        [[0.63137255],
         [0.69019608],
         [0.70196078],
         ...,
         [0.71372549],
         [0.65882353],
         [0.6       ]]],


       ...,


       [[[0.22352941],
         [0.2627451 ],
         [0.27843137],
         ...,
         [0.35294118],
         [0.38039216],
         [0.42352941]],

        [[0.81568627],
         [0.8745098 ],
         [0.77254902],
         ...,
         [0.45882353],
         [0.45098039],
         [0.44313725]],

        [[0.77254902],
         [0.84705882],
         [0.87058824],
         ...,
         [0.48235294],
         [0.4627451 ],
         [0.41960784]],

        ...,

        [[0.49019608],
         [0.47843137],
         [0.47058824],
         ...,
         [0.45490196],
         [0.45490196],
         [0.46666667]],

        [[0.49803922],
         [0.48235294],
         [0.47843137],
         ...,
         [0.46666667],
         [0.49019608],
         [0.48235294]],

        [[0.50588235],
         [0.48627451],
         [0.49019608],
         ...,
         [0.48627451],
         [0.51764706],
         [0.49803922]]],


       [[[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.37254902],
         [0.34509804],
         [0.3372549 ]],

        [[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.36470588],
         [0.33333333],
         [0.3254902 ]],

        [[0.28627451],
         [0.27843137],
         [0.27058824],
         ...,
         [0.36078431],
         [0.3254902 ],
         [0.31764706]],

        ...,

        [[0.43137255],
         [0.4627451 ],
         [0.49019608],
         ...,
         [0.27058824],
         [0.27058824],
         [0.2745098 ]],

        [[0.49411765],
         [0.5254902 ],
         [0.55294118],
         ...,
         [0.31372549],
         [0.31764706],
         [0.3254902 ]],

        [[0.55294118],
         [0.58431373],
         [0.61176471],
         ...,
         [0.36862745],
         [0.38039216],
         [0.38823529]]],


       [[[0.69803922],
         [0.69803922],
         [0.69803922],
         ...,
         [0.67843137],
         [0.61960784],
         [0.57254902]],

        [[0.69803922],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6627451 ],
         [0.61176471],
         [0.56862745]],

        [[0.70196078],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6745098 ],
         [0.62352941],
         [0.57647059]],

        ...,

        [[0.71764706],
         [0.72941176],
         [0.74509804],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70196078]],

        [[0.69803922],
         [0.71764706],
         [0.73333333],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70980392]],

        [[0.69411765],
         [0.70196078],
         [0.71372549],
         ...,
         [0.69411765],
         [0.69803922],
         [0.70196078]]]]), 'X_train_mean_img': array([0.48182258], dtype=float32)}), ('model_save_name', None), ('scheduler', <torch.optim.lr_scheduler.StepLR object at 0x000002709AA55AC8>), ('optimizer', Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
)), ('criterion', BCELoss()), ('dataloaders', {'train': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E080>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E198>}), ('model', UResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (outc): outconv(
    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (sig): Sigmoid()
  )
  (up1): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up2): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up3): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up4): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
))]
28/08/2018 23:35:16 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:35:16 - SaltNet - INFO - --------------------
28/08/2018 23:35:24 - SaltNet - INFO - Batch Loss: 4.8785, Running loss: 4.8785, Batch IOU: 0.0000, Batch Acc: 0.4151 at iter 2, epoch 0, Time: 0m 7s
28/08/2018 23:46:37 - SaltNet - INFO - Start Training...
28/08/2018 23:46:37 - SaltNet - INFO - Passed parameters: {'log': <Logger SaltNet (DEBUG)>, 'push_every': None, 'print_every': 2, 'num_epochs': 50, 'other_data': {'X_train': array([[[[0.4627451 ],
         [0.47058824],
         [0.47058824],
         ...,
         [0.20392157],
         [0.38039216],
         [0.65882353]],

        [[0.45882353],
         [0.48627451],
         [0.50588235],
         ...,
         [0.21568627],
         [0.34901961],
         [0.61568627]],

        [[0.4745098 ],
         [0.51372549],
         [0.54509804],
         ...,
         [0.2627451 ],
         [0.36078431],
         [0.57647059]],

        ...,

        [[0.6       ],
         [0.58823529],
         [0.58431373],
         ...,
         [0.68627451],
         [0.71372549],
         [0.70980392]],

        [[0.59215686],
         [0.60392157],
         [0.61960784],
         ...,
         [0.69803922],
         [0.71764706],
         [0.70196078]],

        [[0.62352941],
         [0.65882353],
         [0.68627451],
         ...,
         [0.68627451],
         [0.69803922],
         [0.67843137]]],


       [[[0.28235294],
         [0.28627451],
         [0.28627451],
         ...,
         [0.33333333],
         [0.45098039],
         [0.57647059]],

        [[0.29411765],
         [0.30196078],
         [0.31372549],
         ...,
         [0.4627451 ],
         [0.56078431],
         [0.60392157]],

        [[0.33333333],
         [0.36470588],
         [0.39607843],
         ...,
         [0.55294118],
         [0.59607843],
         [0.57647059]],

        ...,

        [[0.34901961],
         [0.36078431],
         [0.37254902],
         ...,
         [0.27843137],
         [0.30196078],
         [0.3254902 ]],

        [[0.34117647],
         [0.35686275],
         [0.36862745],
         ...,
         [0.29803922],
         [0.3254902 ],
         [0.34509804]],

        [[0.34117647],
         [0.34901961],
         [0.36078431],
         ...,
         [0.31764706],
         [0.34509804],
         [0.36470588]]],


       [[[0.50980392],
         [0.51372549],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50196078],
         [0.4627451 ]],

        [[0.50196078],
         [0.50980392],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50588235],
         [0.48627451]],

        [[0.49803922],
         [0.50196078],
         [0.50588235],
         ...,
         [0.5254902 ],
         [0.50196078],
         [0.49411765]],

        ...,

        [[0.49019608],
         [0.4627451 ],
         [0.42745098],
         ...,
         [0.25490196],
         [0.34509804],
         [0.44313725]],

        [[0.45490196],
         [0.41176471],
         [0.38039216],
         ...,
         [0.4       ],
         [0.48627451],
         [0.56078431]],

        [[0.39607843],
         [0.36078431],
         [0.3254902 ],
         ...,
         [0.54117647],
         [0.60392157],
         [0.63921569]]],


       ...,


       [[[0.64313725],
         [0.52156863],
         [0.50980392],
         ...,
         [0.34901961],
         [0.35294118],
         [0.40392157]],

        [[0.58823529],
         [0.47843137],
         [0.39607843],
         ...,
         [0.32941176],
         [0.3372549 ],
         [0.38039216]],

        [[0.51764706],
         [0.48627451],
         [0.37647059],
         ...,
         [0.32156863],
         [0.32941176],
         [0.36078431]],

        ...,

        [[0.47843137],
         [0.41176471],
         [0.38823529],
         ...,
         [0.67058824],
         [0.61960784],
         [0.63921569]],

        [[0.40392157],
         [0.39215686],
         [0.38039216],
         ...,
         [0.67843137],
         [0.62352941],
         [0.63921569]],

        [[0.34509804],
         [0.37647059],
         [0.37254902],
         ...,
         [0.68235294],
         [0.62745098],
         [0.64313725]]],


       [[[0.43529412],
         [0.50588235],
         [0.49411765],
         ...,
         [0.70588235],
         [0.54117647],
         [0.50980392]],

        [[0.44313725],
         [0.52156863],
         [0.51764706],
         ...,
         [0.74901961],
         [0.52941176],
         [0.44313725]],

        [[0.52156863],
         [0.6       ],
         [0.58823529],
         ...,
         [0.78823529],
         [0.56470588],
         [0.43529412]],

        ...,

        [[0.29019608],
         [0.3372549 ],
         [0.2627451 ],
         ...,
         [0.50980392],
         [0.34901961],
         [0.30980392]],

        [[0.25882353],
         [0.32156863],
         [0.27843137],
         ...,
         [0.39215686],
         [0.25098039],
         [0.25490196]],

        [[0.34117647],
         [0.38823529],
         [0.36078431],
         ...,
         [0.33333333],
         [0.21176471],
         [0.23921569]]],


       [[[0.47058824],
         [0.52941176],
         [0.43529412],
         ...,
         [0.55294118],
         [0.54901961],
         [0.44313725]],

        [[0.41176471],
         [0.4       ],
         [0.38431373],
         ...,
         [0.55294118],
         [0.54117647],
         [0.41176471]],

        [[0.34901961],
         [0.37647059],
         [0.41568627],
         ...,
         [0.56078431],
         [0.50980392],
         [0.42745098]],

        ...,

        [[0.50980392],
         [0.48235294],
         [0.4745098 ],
         ...,
         [0.4627451 ],
         [0.5372549 ],
         [0.54117647]],

        [[0.4627451 ],
         [0.44313725],
         [0.43137255],
         ...,
         [0.4       ],
         [0.48235294],
         [0.54901961]],

        [[0.44313725],
         [0.45882353],
         [0.40392157],
         ...,
         [0.34901961],
         [0.43529412],
         [0.54901961]]]]), 'X_val': array([[[[0.34901961],
         [0.34117647],
         [0.35686275],
         ...,
         [0.37647059],
         [0.33333333],
         [0.33333333]],

        [[0.37254902],
         [0.36862745],
         [0.38823529],
         ...,
         [0.28627451],
         [0.2627451 ],
         [0.28235294]],

        [[0.40392157],
         [0.40392157],
         [0.41176471],
         ...,
         [0.23137255],
         [0.21960784],
         [0.25490196]],

        ...,

        [[0.41960784],
         [0.39607843],
         [0.36470588],
         ...,
         [0.61176471],
         [0.59607843],
         [0.56470588]],

        [[0.43137255],
         [0.40784314],
         [0.38823529],
         ...,
         [0.59607843],
         [0.56862745],
         [0.5254902 ]],

        [[0.43921569],
         [0.42745098],
         [0.42352941],
         ...,
         [0.56862745],
         [0.5372549 ],
         [0.49019608]]],


       [[[0.37647059],
         [0.40784314],
         [0.39215686],
         ...,
         [0.47058824],
         [0.50588235],
         [0.4745098 ]],

        [[0.44313725],
         [0.43529412],
         [0.40784314],
         ...,
         [0.41176471],
         [0.42352941],
         [0.4       ]],

        [[0.44313725],
         [0.41176471],
         [0.4       ],
         ...,
         [0.34901961],
         [0.3254902 ],
         [0.34509804]],

        ...,

        [[0.30588235],
         [0.31372549],
         [0.31764706],
         ...,
         [0.51372549],
         [0.49411765],
         [0.4745098 ]],

        [[0.3254902 ],
         [0.3254902 ],
         [0.3254902 ],
         ...,
         [0.50196078],
         [0.48627451],
         [0.47058824]],

        [[0.37254902],
         [0.36862745],
         [0.36078431],
         ...,
         [0.49019608],
         [0.48235294],
         [0.46666667]]],


       [[[0.55686275],
         [0.59607843],
         [0.62352941],
         ...,
         [0.44313725],
         [0.42745098],
         [0.4       ]],

        [[0.73333333],
         [0.77254902],
         [0.80784314],
         ...,
         [0.45882353],
         [0.44313725],
         [0.41176471]],

        [[0.88627451],
         [0.91764706],
         [0.94117647],
         ...,
         [0.4745098 ],
         [0.45882353],
         [0.43529412]],

        ...,

        [[0.32941176],
         [0.32941176],
         [0.32941176],
         ...,
         [0.26666667],
         [0.28627451],
         [0.30980392]],

        [[0.31372549],
         [0.30588235],
         [0.29803922],
         ...,
         [0.28235294],
         [0.30588235],
         [0.3254902 ]],

        [[0.30196078],
         [0.28627451],
         [0.27843137],
         ...,
         [0.30588235],
         [0.3254902 ],
         [0.34509804]]],


       ...,


       [[[0.09411765],
         [0.10196078],
         [0.09019608],
         ...,
         [0.39215686],
         [0.27843137],
         [0.34509804]],

        [[0.19607843],
         [0.21960784],
         [0.16470588],
         ...,
         [0.43921569],
         [0.33333333],
         [0.43137255]],

        [[0.35294118],
         [0.4       ],
         [0.31764706],
         ...,
         [0.5254902 ],
         [0.43921569],
         [0.54901961]],

        ...,

        [[0.33333333],
         [0.25882353],
         [0.23921569],
         ...,
         [0.58823529],
         [0.65882353],
         [0.66666667]],

        [[0.34901961],
         [0.2745098 ],
         [0.29411765],
         ...,
         [0.64313725],
         [0.67843137],
         [0.66666667]],

        [[0.35294118],
         [0.28627451],
         [0.33333333],
         ...,
         [0.63921569],
         [0.65098039],
         [0.63137255]]],


       [[[0.52156863],
         [0.52156863],
         [0.51372549],
         ...,
         [0.50588235],
         [0.50980392],
         [0.51372549]],

        [[0.5254902 ],
         [0.5372549 ],
         [0.52156863],
         ...,
         [0.51372549],
         [0.50980392],
         [0.50980392]],

        [[0.48627451],
         [0.49019608],
         [0.4745098 ],
         ...,
         [0.5372549 ],
         [0.53333333],
         [0.53333333]],

        ...,

        [[0.56078431],
         [0.56862745],
         [0.55294118],
         ...,
         [0.4745098 ],
         [0.50980392],
         [0.49019608]],

        [[0.55686275],
         [0.56078431],
         [0.54117647],
         ...,
         [0.51372549],
         [0.5372549 ],
         [0.48627451]],

        [[0.55686275],
         [0.55294118],
         [0.53333333],
         ...,
         [0.56078431],
         [0.54901961],
         [0.49019608]]],


       [[[0.23529412],
         [0.41176471],
         [0.54509804],
         ...,
         [0.56078431],
         [0.49411765],
         [0.43529412]],

        [[0.36078431],
         [0.5372549 ],
         [0.60784314],
         ...,
         [0.56078431],
         [0.49411765],
         [0.45098039]],

        [[0.52941176],
         [0.66666667],
         [0.63137255],
         ...,
         [0.55686275],
         [0.48235294],
         [0.46666667]],

        ...,

        [[0.54509804],
         [0.40784314],
         [0.3254902 ],
         ...,
         [0.44705882],
         [0.49411765],
         [0.4745098 ]],

        [[0.41176471],
         [0.32156863],
         [0.28235294],
         ...,
         [0.47058824],
         [0.51764706],
         [0.48627451]],

        [[0.32156863],
         [0.26666667],
         [0.2627451 ],
         ...,
         [0.49019608],
         [0.53333333],
         [0.49411765]]]]), 'y_train': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]]], dtype=uint8), 'y_val': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]]], dtype=uint8), 'X_test': array([[[[0.43921569],
         [0.49411765],
         [0.57254902],
         ...,
         [0.61568627],
         [0.73333333],
         [0.7254902 ]],

        [[0.45490196],
         [0.50980392],
         [0.57647059],
         ...,
         [0.61176471],
         [0.72941176],
         [0.70196078]],

        [[0.46666667],
         [0.52941176],
         [0.57254902],
         ...,
         [0.62745098],
         [0.7254902 ],
         [0.6745098 ]],

        ...,

        [[0.38039216],
         [0.44313725],
         [0.49019608],
         ...,
         [0.24313725],
         [0.30980392],
         [0.33333333]],

        [[0.39215686],
         [0.45098039],
         [0.48235294],
         ...,
         [0.33333333],
         [0.38823529],
         [0.41176471]],

        [[0.40784314],
         [0.45490196],
         [0.46666667],
         ...,
         [0.42745098],
         [0.47058824],
         [0.49803922]]],


       [[[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        ...,

        [[0.03529412],
         [0.03921569],
         [0.08235294],
         ...,
         [0.41176471],
         [0.47058824],
         [0.45490196]],

        [[0.43921569],
         [0.42745098],
         [0.47843137],
         ...,
         [0.38823529],
         [0.37647059],
         [0.33333333]],

        [[0.41176471],
         [0.43529412],
         [0.41568627],
         ...,
         [0.14117647],
         [0.10196078],
         [0.15686275]]],


       [[[0.63529412],
         [0.64705882],
         [0.63529412],
         ...,
         [0.28235294],
         [0.30588235],
         [0.27843137]],

        [[0.63137255],
         [0.63921569],
         [0.62352941],
         ...,
         [0.27843137],
         [0.30196078],
         [0.29803922]],

        [[0.63137255],
         [0.63137255],
         [0.61176471],
         ...,
         [0.25098039],
         [0.27843137],
         [0.2745098 ]],

        ...,

        [[0.67058824],
         [0.71764706],
         [0.7372549 ],
         ...,
         [0.67058824],
         [0.63921569],
         [0.58823529]],

        [[0.65098039],
         [0.70196078],
         [0.72156863],
         ...,
         [0.69803922],
         [0.65098039],
         [0.59215686]],

        [[0.63137255],
         [0.69019608],
         [0.70196078],
         ...,
         [0.71372549],
         [0.65882353],
         [0.6       ]]],


       ...,


       [[[0.22352941],
         [0.2627451 ],
         [0.27843137],
         ...,
         [0.35294118],
         [0.38039216],
         [0.42352941]],

        [[0.81568627],
         [0.8745098 ],
         [0.77254902],
         ...,
         [0.45882353],
         [0.45098039],
         [0.44313725]],

        [[0.77254902],
         [0.84705882],
         [0.87058824],
         ...,
         [0.48235294],
         [0.4627451 ],
         [0.41960784]],

        ...,

        [[0.49019608],
         [0.47843137],
         [0.47058824],
         ...,
         [0.45490196],
         [0.45490196],
         [0.46666667]],

        [[0.49803922],
         [0.48235294],
         [0.47843137],
         ...,
         [0.46666667],
         [0.49019608],
         [0.48235294]],

        [[0.50588235],
         [0.48627451],
         [0.49019608],
         ...,
         [0.48627451],
         [0.51764706],
         [0.49803922]]],


       [[[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.37254902],
         [0.34509804],
         [0.3372549 ]],

        [[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.36470588],
         [0.33333333],
         [0.3254902 ]],

        [[0.28627451],
         [0.27843137],
         [0.27058824],
         ...,
         [0.36078431],
         [0.3254902 ],
         [0.31764706]],

        ...,

        [[0.43137255],
         [0.4627451 ],
         [0.49019608],
         ...,
         [0.27058824],
         [0.27058824],
         [0.2745098 ]],

        [[0.49411765],
         [0.5254902 ],
         [0.55294118],
         ...,
         [0.31372549],
         [0.31764706],
         [0.3254902 ]],

        [[0.55294118],
         [0.58431373],
         [0.61176471],
         ...,
         [0.36862745],
         [0.38039216],
         [0.38823529]]],


       [[[0.69803922],
         [0.69803922],
         [0.69803922],
         ...,
         [0.67843137],
         [0.61960784],
         [0.57254902]],

        [[0.69803922],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6627451 ],
         [0.61176471],
         [0.56862745]],

        [[0.70196078],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6745098 ],
         [0.62352941],
         [0.57647059]],

        ...,

        [[0.71764706],
         [0.72941176],
         [0.74509804],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70196078]],

        [[0.69803922],
         [0.71764706],
         [0.73333333],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70980392]],

        [[0.69411765],
         [0.70196078],
         [0.71372549],
         ...,
         [0.69411765],
         [0.69803922],
         [0.70196078]]]]), 'X_train_mean_img': array([0.48182258], dtype=float32)}, 'model_save_name': None, 'scheduler': <torch.optim.lr_scheduler.StepLR object at 0x00000270A4DF0D68>, 'optimizer': Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
), 'criterion': BCELoss(), 'dataloaders': {'train': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E080>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E198>}, 'model': UResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (outc): outconv(
    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (sig): Sigmoid()
  )
  (up1): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up2): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up3): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up4): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
)}
28/08/2018 23:46:37 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:46:37 - SaltNet - INFO - --------------------
28/08/2018 23:46:44 - SaltNet - INFO - Batch Loss: 2.1998, Running loss: 2.1998, Batch IOU: 0.0000, Batch Acc: 0.5941 at iter 2, epoch 0, Time: 0m 7s
28/08/2018 23:48:43 - SaltNet - INFO - Start Training...
28/08/2018 23:48:43 - SaltNet - INFO - Passed parameters: {'log': <Logger SaltNet (DEBUG)>, 'push_every': None, 'print_every': 2, 'num_epochs': 50, 'other_data': {'X_train': array([[[[0.4627451 ],
         [0.47058824],
         [0.47058824],
         ...,
         [0.20392157],
         [0.38039216],
         [0.65882353]],

        [[0.45882353],
         [0.48627451],
         [0.50588235],
         ...,
         [0.21568627],
         [0.34901961],
         [0.61568627]],

        [[0.4745098 ],
         [0.51372549],
         [0.54509804],
         ...,
         [0.2627451 ],
         [0.36078431],
         [0.57647059]],

        ...,

        [[0.6       ],
         [0.58823529],
         [0.58431373],
         ...,
         [0.68627451],
         [0.71372549],
         [0.70980392]],

        [[0.59215686],
         [0.60392157],
         [0.61960784],
         ...,
         [0.69803922],
         [0.71764706],
         [0.70196078]],

        [[0.62352941],
         [0.65882353],
         [0.68627451],
         ...,
         [0.68627451],
         [0.69803922],
         [0.67843137]]],


       [[[0.28235294],
         [0.28627451],
         [0.28627451],
         ...,
         [0.33333333],
         [0.45098039],
         [0.57647059]],

        [[0.29411765],
         [0.30196078],
         [0.31372549],
         ...,
         [0.4627451 ],
         [0.56078431],
         [0.60392157]],

        [[0.33333333],
         [0.36470588],
         [0.39607843],
         ...,
         [0.55294118],
         [0.59607843],
         [0.57647059]],

        ...,

        [[0.34901961],
         [0.36078431],
         [0.37254902],
         ...,
         [0.27843137],
         [0.30196078],
         [0.3254902 ]],

        [[0.34117647],
         [0.35686275],
         [0.36862745],
         ...,
         [0.29803922],
         [0.3254902 ],
         [0.34509804]],

        [[0.34117647],
         [0.34901961],
         [0.36078431],
         ...,
         [0.31764706],
         [0.34509804],
         [0.36470588]]],


       [[[0.50980392],
         [0.51372549],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50196078],
         [0.4627451 ]],

        [[0.50196078],
         [0.50980392],
         [0.51372549],
         ...,
         [0.54117647],
         [0.50588235],
         [0.48627451]],

        [[0.49803922],
         [0.50196078],
         [0.50588235],
         ...,
         [0.5254902 ],
         [0.50196078],
         [0.49411765]],

        ...,

        [[0.49019608],
         [0.4627451 ],
         [0.42745098],
         ...,
         [0.25490196],
         [0.34509804],
         [0.44313725]],

        [[0.45490196],
         [0.41176471],
         [0.38039216],
         ...,
         [0.4       ],
         [0.48627451],
         [0.56078431]],

        [[0.39607843],
         [0.36078431],
         [0.3254902 ],
         ...,
         [0.54117647],
         [0.60392157],
         [0.63921569]]],


       ...,


       [[[0.64313725],
         [0.52156863],
         [0.50980392],
         ...,
         [0.34901961],
         [0.35294118],
         [0.40392157]],

        [[0.58823529],
         [0.47843137],
         [0.39607843],
         ...,
         [0.32941176],
         [0.3372549 ],
         [0.38039216]],

        [[0.51764706],
         [0.48627451],
         [0.37647059],
         ...,
         [0.32156863],
         [0.32941176],
         [0.36078431]],

        ...,

        [[0.47843137],
         [0.41176471],
         [0.38823529],
         ...,
         [0.67058824],
         [0.61960784],
         [0.63921569]],

        [[0.40392157],
         [0.39215686],
         [0.38039216],
         ...,
         [0.67843137],
         [0.62352941],
         [0.63921569]],

        [[0.34509804],
         [0.37647059],
         [0.37254902],
         ...,
         [0.68235294],
         [0.62745098],
         [0.64313725]]],


       [[[0.43529412],
         [0.50588235],
         [0.49411765],
         ...,
         [0.70588235],
         [0.54117647],
         [0.50980392]],

        [[0.44313725],
         [0.52156863],
         [0.51764706],
         ...,
         [0.74901961],
         [0.52941176],
         [0.44313725]],

        [[0.52156863],
         [0.6       ],
         [0.58823529],
         ...,
         [0.78823529],
         [0.56470588],
         [0.43529412]],

        ...,

        [[0.29019608],
         [0.3372549 ],
         [0.2627451 ],
         ...,
         [0.50980392],
         [0.34901961],
         [0.30980392]],

        [[0.25882353],
         [0.32156863],
         [0.27843137],
         ...,
         [0.39215686],
         [0.25098039],
         [0.25490196]],

        [[0.34117647],
         [0.38823529],
         [0.36078431],
         ...,
         [0.33333333],
         [0.21176471],
         [0.23921569]]],


       [[[0.47058824],
         [0.52941176],
         [0.43529412],
         ...,
         [0.55294118],
         [0.54901961],
         [0.44313725]],

        [[0.41176471],
         [0.4       ],
         [0.38431373],
         ...,
         [0.55294118],
         [0.54117647],
         [0.41176471]],

        [[0.34901961],
         [0.37647059],
         [0.41568627],
         ...,
         [0.56078431],
         [0.50980392],
         [0.42745098]],

        ...,

        [[0.50980392],
         [0.48235294],
         [0.4745098 ],
         ...,
         [0.4627451 ],
         [0.5372549 ],
         [0.54117647]],

        [[0.4627451 ],
         [0.44313725],
         [0.43137255],
         ...,
         [0.4       ],
         [0.48235294],
         [0.54901961]],

        [[0.44313725],
         [0.45882353],
         [0.40392157],
         ...,
         [0.34901961],
         [0.43529412],
         [0.54901961]]]]), 'X_val': array([[[[0.34901961],
         [0.34117647],
         [0.35686275],
         ...,
         [0.37647059],
         [0.33333333],
         [0.33333333]],

        [[0.37254902],
         [0.36862745],
         [0.38823529],
         ...,
         [0.28627451],
         [0.2627451 ],
         [0.28235294]],

        [[0.40392157],
         [0.40392157],
         [0.41176471],
         ...,
         [0.23137255],
         [0.21960784],
         [0.25490196]],

        ...,

        [[0.41960784],
         [0.39607843],
         [0.36470588],
         ...,
         [0.61176471],
         [0.59607843],
         [0.56470588]],

        [[0.43137255],
         [0.40784314],
         [0.38823529],
         ...,
         [0.59607843],
         [0.56862745],
         [0.5254902 ]],

        [[0.43921569],
         [0.42745098],
         [0.42352941],
         ...,
         [0.56862745],
         [0.5372549 ],
         [0.49019608]]],


       [[[0.37647059],
         [0.40784314],
         [0.39215686],
         ...,
         [0.47058824],
         [0.50588235],
         [0.4745098 ]],

        [[0.44313725],
         [0.43529412],
         [0.40784314],
         ...,
         [0.41176471],
         [0.42352941],
         [0.4       ]],

        [[0.44313725],
         [0.41176471],
         [0.4       ],
         ...,
         [0.34901961],
         [0.3254902 ],
         [0.34509804]],

        ...,

        [[0.30588235],
         [0.31372549],
         [0.31764706],
         ...,
         [0.51372549],
         [0.49411765],
         [0.4745098 ]],

        [[0.3254902 ],
         [0.3254902 ],
         [0.3254902 ],
         ...,
         [0.50196078],
         [0.48627451],
         [0.47058824]],

        [[0.37254902],
         [0.36862745],
         [0.36078431],
         ...,
         [0.49019608],
         [0.48235294],
         [0.46666667]]],


       [[[0.55686275],
         [0.59607843],
         [0.62352941],
         ...,
         [0.44313725],
         [0.42745098],
         [0.4       ]],

        [[0.73333333],
         [0.77254902],
         [0.80784314],
         ...,
         [0.45882353],
         [0.44313725],
         [0.41176471]],

        [[0.88627451],
         [0.91764706],
         [0.94117647],
         ...,
         [0.4745098 ],
         [0.45882353],
         [0.43529412]],

        ...,

        [[0.32941176],
         [0.32941176],
         [0.32941176],
         ...,
         [0.26666667],
         [0.28627451],
         [0.30980392]],

        [[0.31372549],
         [0.30588235],
         [0.29803922],
         ...,
         [0.28235294],
         [0.30588235],
         [0.3254902 ]],

        [[0.30196078],
         [0.28627451],
         [0.27843137],
         ...,
         [0.30588235],
         [0.3254902 ],
         [0.34509804]]],


       ...,


       [[[0.09411765],
         [0.10196078],
         [0.09019608],
         ...,
         [0.39215686],
         [0.27843137],
         [0.34509804]],

        [[0.19607843],
         [0.21960784],
         [0.16470588],
         ...,
         [0.43921569],
         [0.33333333],
         [0.43137255]],

        [[0.35294118],
         [0.4       ],
         [0.31764706],
         ...,
         [0.5254902 ],
         [0.43921569],
         [0.54901961]],

        ...,

        [[0.33333333],
         [0.25882353],
         [0.23921569],
         ...,
         [0.58823529],
         [0.65882353],
         [0.66666667]],

        [[0.34901961],
         [0.2745098 ],
         [0.29411765],
         ...,
         [0.64313725],
         [0.67843137],
         [0.66666667]],

        [[0.35294118],
         [0.28627451],
         [0.33333333],
         ...,
         [0.63921569],
         [0.65098039],
         [0.63137255]]],


       [[[0.52156863],
         [0.52156863],
         [0.51372549],
         ...,
         [0.50588235],
         [0.50980392],
         [0.51372549]],

        [[0.5254902 ],
         [0.5372549 ],
         [0.52156863],
         ...,
         [0.51372549],
         [0.50980392],
         [0.50980392]],

        [[0.48627451],
         [0.49019608],
         [0.4745098 ],
         ...,
         [0.5372549 ],
         [0.53333333],
         [0.53333333]],

        ...,

        [[0.56078431],
         [0.56862745],
         [0.55294118],
         ...,
         [0.4745098 ],
         [0.50980392],
         [0.49019608]],

        [[0.55686275],
         [0.56078431],
         [0.54117647],
         ...,
         [0.51372549],
         [0.5372549 ],
         [0.48627451]],

        [[0.55686275],
         [0.55294118],
         [0.53333333],
         ...,
         [0.56078431],
         [0.54901961],
         [0.49019608]]],


       [[[0.23529412],
         [0.41176471],
         [0.54509804],
         ...,
         [0.56078431],
         [0.49411765],
         [0.43529412]],

        [[0.36078431],
         [0.5372549 ],
         [0.60784314],
         ...,
         [0.56078431],
         [0.49411765],
         [0.45098039]],

        [[0.52941176],
         [0.66666667],
         [0.63137255],
         ...,
         [0.55686275],
         [0.48235294],
         [0.46666667]],

        ...,

        [[0.54509804],
         [0.40784314],
         [0.3254902 ],
         ...,
         [0.44705882],
         [0.49411765],
         [0.4745098 ]],

        [[0.41176471],
         [0.32156863],
         [0.28235294],
         ...,
         [0.47058824],
         [0.51764706],
         [0.48627451]],

        [[0.32156863],
         [0.26666667],
         [0.2627451 ],
         ...,
         [0.49019608],
         [0.53333333],
         [0.49411765]]]]), 'y_train': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        [[255],
         [255],
         [255],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]]], dtype=uint8), 'y_val': array([[[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]],


       [[[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]],

        [[255],
         [255],
         [255],
         ...,
         [255],
         [255],
         [255]]],


       ...,


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]],

        [[  0],
         [  0],
         [  0],
         ...,
         [  0],
         [  0],
         [  0]]],


       [[[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        ...,

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]],

        [[  0],
         [  0],
         [  0],
         ...,
         [255],
         [255],
         [255]]]], dtype=uint8), 'X_test': array([[[[0.43921569],
         [0.49411765],
         [0.57254902],
         ...,
         [0.61568627],
         [0.73333333],
         [0.7254902 ]],

        [[0.45490196],
         [0.50980392],
         [0.57647059],
         ...,
         [0.61176471],
         [0.72941176],
         [0.70196078]],

        [[0.46666667],
         [0.52941176],
         [0.57254902],
         ...,
         [0.62745098],
         [0.7254902 ],
         [0.6745098 ]],

        ...,

        [[0.38039216],
         [0.44313725],
         [0.49019608],
         ...,
         [0.24313725],
         [0.30980392],
         [0.33333333]],

        [[0.39215686],
         [0.45098039],
         [0.48235294],
         ...,
         [0.33333333],
         [0.38823529],
         [0.41176471]],

        [[0.40784314],
         [0.45490196],
         [0.46666667],
         ...,
         [0.42745098],
         [0.47058824],
         [0.49803922]]],


       [[[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        [[0.34117647],
         [0.34117647],
         [0.34117647],
         ...,
         [0.34117647],
         [0.34117647],
         [0.34117647]],

        ...,

        [[0.03529412],
         [0.03921569],
         [0.08235294],
         ...,
         [0.41176471],
         [0.47058824],
         [0.45490196]],

        [[0.43921569],
         [0.42745098],
         [0.47843137],
         ...,
         [0.38823529],
         [0.37647059],
         [0.33333333]],

        [[0.41176471],
         [0.43529412],
         [0.41568627],
         ...,
         [0.14117647],
         [0.10196078],
         [0.15686275]]],


       [[[0.63529412],
         [0.64705882],
         [0.63529412],
         ...,
         [0.28235294],
         [0.30588235],
         [0.27843137]],

        [[0.63137255],
         [0.63921569],
         [0.62352941],
         ...,
         [0.27843137],
         [0.30196078],
         [0.29803922]],

        [[0.63137255],
         [0.63137255],
         [0.61176471],
         ...,
         [0.25098039],
         [0.27843137],
         [0.2745098 ]],

        ...,

        [[0.67058824],
         [0.71764706],
         [0.7372549 ],
         ...,
         [0.67058824],
         [0.63921569],
         [0.58823529]],

        [[0.65098039],
         [0.70196078],
         [0.72156863],
         ...,
         [0.69803922],
         [0.65098039],
         [0.59215686]],

        [[0.63137255],
         [0.69019608],
         [0.70196078],
         ...,
         [0.71372549],
         [0.65882353],
         [0.6       ]]],


       ...,


       [[[0.22352941],
         [0.2627451 ],
         [0.27843137],
         ...,
         [0.35294118],
         [0.38039216],
         [0.42352941]],

        [[0.81568627],
         [0.8745098 ],
         [0.77254902],
         ...,
         [0.45882353],
         [0.45098039],
         [0.44313725]],

        [[0.77254902],
         [0.84705882],
         [0.87058824],
         ...,
         [0.48235294],
         [0.4627451 ],
         [0.41960784]],

        ...,

        [[0.49019608],
         [0.47843137],
         [0.47058824],
         ...,
         [0.45490196],
         [0.45490196],
         [0.46666667]],

        [[0.49803922],
         [0.48235294],
         [0.47843137],
         ...,
         [0.46666667],
         [0.49019608],
         [0.48235294]],

        [[0.50588235],
         [0.48627451],
         [0.49019608],
         ...,
         [0.48627451],
         [0.51764706],
         [0.49803922]]],


       [[[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.37254902],
         [0.34509804],
         [0.3372549 ]],

        [[0.28627451],
         [0.27058824],
         [0.25490196],
         ...,
         [0.36470588],
         [0.33333333],
         [0.3254902 ]],

        [[0.28627451],
         [0.27843137],
         [0.27058824],
         ...,
         [0.36078431],
         [0.3254902 ],
         [0.31764706]],

        ...,

        [[0.43137255],
         [0.4627451 ],
         [0.49019608],
         ...,
         [0.27058824],
         [0.27058824],
         [0.2745098 ]],

        [[0.49411765],
         [0.5254902 ],
         [0.55294118],
         ...,
         [0.31372549],
         [0.31764706],
         [0.3254902 ]],

        [[0.55294118],
         [0.58431373],
         [0.61176471],
         ...,
         [0.36862745],
         [0.38039216],
         [0.38823529]]],


       [[[0.69803922],
         [0.69803922],
         [0.69803922],
         ...,
         [0.67843137],
         [0.61960784],
         [0.57254902]],

        [[0.69803922],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6627451 ],
         [0.61176471],
         [0.56862745]],

        [[0.70196078],
         [0.69411765],
         [0.69411765],
         ...,
         [0.6745098 ],
         [0.62352941],
         [0.57647059]],

        ...,

        [[0.71764706],
         [0.72941176],
         [0.74509804],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70196078]],

        [[0.69803922],
         [0.71764706],
         [0.73333333],
         ...,
         [0.69803922],
         [0.70196078],
         [0.70980392]],

        [[0.69411765],
         [0.70196078],
         [0.71372549],
         ...,
         [0.69411765],
         [0.69803922],
         [0.70196078]]]]), 'X_train_mean_img': array([0.48182258], dtype=float32)}, 'model_save_name': None, 'scheduler': <torch.optim.lr_scheduler.StepLR object at 0x000002709AB32940>, 'optimizer': Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
), 'criterion': BCELoss(), 'dataloaders': {'train': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E080>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x000002709AA7E198>}, 'model': UResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (outc): outconv(
    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (sig): Sigmoid()
  )
  (up1): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up2): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up3): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
  (up4): up(
    (upscale): Upsample(scale_factor=2, mode=bilinear)
    (conv): double_conv(
      (conv): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace)
      )
    )
  )
)}
28/08/2018 23:48:43 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:48:43 - SaltNet - INFO - --------------------
28/08/2018 23:49:09 - SaltNet - INFO - Start Training...
28/08/2018 23:49:09 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:49:09 - SaltNet - INFO - --------------------
28/08/2018 23:49:17 - SaltNet - INFO - Batch Loss: 4.3748, Running loss: 4.3748, Batch IOU: 0.0000, Batch Acc: 0.3838 at iter 2, epoch 0, Time: 0m 7s
28/08/2018 23:52:54 - SaltNet - INFO - Start Training...
28/08/2018 23:52:54 - SaltNet - INFO - Epoch 0/49
28/08/2018 23:52:54 - SaltNet - INFO - --------------------
28/08/2018 23:53:01 - SaltNet - INFO - Batch Loss: 2.0488, Running loss: 2.0488, Batch IOU: 0.0000, Batch Acc: 0.5688 at iter 2, epoch 0, Time: 0m 7s
28/08/2018 23:53:02 - SaltNet - INFO - train Mean IOU: 0.0000, Mean Acc: 0.6203 at epoch 0
28/08/2018 23:53:05 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7725 at epoch 0
28/08/2018 23:53:05 - SaltNet - INFO - Model state is not saved as the out_file_prefix is None
28/08/2018 23:53:05 - SaltNet - INFO - Best Val Mean IOU so far: 0.5
28/08/2018 23:53:06 - SaltNet - INFO - Epoch 1/49
28/08/2018 23:53:06 - SaltNet - INFO - --------------------
28/08/2018 23:53:13 - SaltNet - INFO - Batch Loss: 1.6610, Running loss: 1.7776, Batch IOU: 0.0000, Batch Acc: 0.6897 at iter 4, epoch 1, Time: 0m 18s
28/08/2018 23:53:13 - SaltNet - INFO - train Mean IOU: 0.0250, Mean Acc: 0.7318 at epoch 1
28/08/2018 23:53:17 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7690 at epoch 1
28/08/2018 23:53:17 - SaltNet - INFO - Epoch 2/49
28/08/2018 23:53:17 - SaltNet - INFO - --------------------
28/08/2018 23:53:24 - SaltNet - INFO - Batch Loss: 1.4979, Running loss: 1.4852, Batch IOU: 0.0000, Batch Acc: 0.6042 at iter 6, epoch 2, Time: 0m 29s
28/08/2018 23:53:25 - SaltNet - INFO - train Mean IOU: 0.0000, Mean Acc: 0.7133 at epoch 2
28/08/2018 23:53:28 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7724 at epoch 2
28/08/2018 23:53:28 - SaltNet - INFO - Epoch 3/49
28/08/2018 23:53:28 - SaltNet - INFO - --------------------
28/08/2018 23:53:35 - SaltNet - INFO - Batch Loss: 0.5652, Running loss: 1.2553, Batch IOU: 0.2000, Batch Acc: 0.8309 at iter 8, epoch 3, Time: 0m 41s
28/08/2018 23:53:36 - SaltNet - INFO - train Mean IOU: 0.1000, Mean Acc: 0.8283 at epoch 3
28/08/2018 23:53:39 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.6263 at epoch 3
28/08/2018 23:53:39 - SaltNet - INFO - Epoch 4/49
28/08/2018 23:53:39 - SaltNet - INFO - --------------------
28/08/2018 23:53:46 - SaltNet - INFO - Batch Loss: 0.6345, Running loss: 1.1370, Batch IOU: 0.0000, Batch Acc: 0.8054 at iter 10, epoch 4, Time: 0m 51s
28/08/2018 23:53:47 - SaltNet - INFO - train Mean IOU: 0.3250, Mean Acc: 0.8622 at epoch 4
28/08/2018 23:53:50 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.5215 at epoch 4
28/08/2018 23:53:50 - SaltNet - INFO - Epoch 5/49
28/08/2018 23:53:50 - SaltNet - INFO - --------------------
28/08/2018 23:53:56 - SaltNet - INFO - Batch Loss: 0.5341, Running loss: 1.0922, Batch IOU: 0.2000, Batch Acc: 0.8722 at iter 12, epoch 5, Time: 1m 2s
28/08/2018 23:53:57 - SaltNet - INFO - train Mean IOU: 0.1000, Mean Acc: 0.8493 at epoch 5
28/08/2018 23:54:00 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.5250 at epoch 5
28/08/2018 23:54:00 - SaltNet - INFO - Epoch 6/49
28/08/2018 23:54:00 - SaltNet - INFO - --------------------
28/08/2018 23:54:07 - SaltNet - INFO - Batch Loss: 0.2414, Running loss: 1.0525, Batch IOU: 0.1500, Batch Acc: 0.8682 at iter 14, epoch 6, Time: 1m 12s
28/08/2018 23:54:07 - SaltNet - INFO - train Mean IOU: 0.1750, Mean Acc: 0.9080 at epoch 6
28/08/2018 23:54:11 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.5397 at epoch 6
28/08/2018 23:54:11 - SaltNet - INFO - Epoch 7/49
28/08/2018 23:54:11 - SaltNet - INFO - --------------------
28/08/2018 23:54:17 - SaltNet - INFO - Batch Loss: 0.2115, Running loss: 1.0248, Batch IOU: 0.0500, Batch Acc: 0.9414 at iter 16, epoch 7, Time: 1m 23s
28/08/2018 23:54:18 - SaltNet - INFO - train Mean IOU: 0.2250, Mean Acc: 0.9254 at epoch 7
28/08/2018 23:54:21 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7112 at epoch 7
28/08/2018 23:54:21 - SaltNet - INFO - Epoch 8/49
28/08/2018 23:54:21 - SaltNet - INFO - --------------------
28/08/2018 23:54:28 - SaltNet - INFO - Batch Loss: 0.1110, Running loss: 0.9982, Batch IOU: 0.5000, Batch Acc: 0.9719 at iter 18, epoch 8, Time: 1m 33s
28/08/2018 23:54:28 - SaltNet - INFO - train Mean IOU: 0.3000, Mean Acc: 0.9628 at epoch 8
28/08/2018 23:54:32 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7668 at epoch 8
28/08/2018 23:54:32 - SaltNet - INFO - Epoch 9/49
28/08/2018 23:54:32 - SaltNet - INFO - --------------------
28/08/2018 23:54:39 - SaltNet - INFO - Batch Loss: 0.1972, Running loss: 0.9956, Batch IOU: 0.0000, Batch Acc: 0.9295 at iter 20, epoch 9, Time: 1m 44s
28/08/2018 23:54:39 - SaltNet - INFO - train Mean IOU: 0.2250, Mean Acc: 0.9523 at epoch 9
28/08/2018 23:54:42 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7704 at epoch 9
28/08/2018 23:54:42 - SaltNet - INFO - Epoch 10/49
28/08/2018 23:54:42 - SaltNet - INFO - --------------------
28/08/2018 23:54:49 - SaltNet - INFO - Batch Loss: 0.0587, Running loss: 0.9935, Batch IOU: 0.4000, Batch Acc: 0.9758 at iter 22, epoch 10, Time: 1m 55s
28/08/2018 23:54:50 - SaltNet - INFO - train Mean IOU: 0.4500, Mean Acc: 0.9798 at epoch 10
28/08/2018 23:54:53 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7709 at epoch 10
28/08/2018 23:54:53 - SaltNet - INFO - Epoch 11/49
28/08/2018 23:54:53 - SaltNet - INFO - --------------------
28/08/2018 23:55:00 - SaltNet - INFO - Batch Loss: 0.1520, Running loss: 1.0108, Batch IOU: 0.0000, Batch Acc: 0.9430 at iter 24, epoch 11, Time: 2m 5s
28/08/2018 23:55:01 - SaltNet - INFO - train Mean IOU: 0.3250, Mean Acc: 0.9494 at epoch 11
28/08/2018 23:55:04 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7707 at epoch 11
28/08/2018 23:55:04 - SaltNet - INFO - Epoch 12/49
28/08/2018 23:55:04 - SaltNet - INFO - --------------------
28/08/2018 23:55:10 - SaltNet - INFO - Batch Loss: 0.1286, Running loss: 1.0459, Batch IOU: 0.7000, Batch Acc: 0.9308 at iter 26, epoch 12, Time: 2m 16s
28/08/2018 23:55:11 - SaltNet - INFO - train Mean IOU: 0.3500, Mean Acc: 0.9570 at epoch 12
28/08/2018 23:55:14 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7711 at epoch 12
28/08/2018 23:55:14 - SaltNet - INFO - Epoch 13/49
28/08/2018 23:55:14 - SaltNet - INFO - --------------------
28/08/2018 23:55:21 - SaltNet - INFO - Batch Loss: 0.0799, Running loss: 1.0687, Batch IOU: 0.2500, Batch Acc: 0.9612 at iter 28, epoch 13, Time: 2m 27s
28/08/2018 23:55:22 - SaltNet - INFO - train Mean IOU: 0.6250, Mean Acc: 0.9730 at epoch 13
28/08/2018 23:55:25 - SaltNet - INFO - val Mean IOU: 0.0000, Mean Acc: 0.7742 at epoch 13
28/08/2018 23:55:25 - SaltNet - INFO - Epoch 14/49
28/08/2018 23:55:25 - SaltNet - INFO - --------------------
28/08/2018 23:55:32 - SaltNet - INFO - Batch Loss: 0.0813, Running loss: 1.0713, Batch IOU: 0.5000, Batch Acc: 0.9745 at iter 30, epoch 14, Time: 2m 38s
28/08/2018 23:55:33 - SaltNet - INFO - train Mean IOU: 0.3500, Mean Acc: 0.9740 at epoch 14
28/08/2018 23:55:36 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7852 at epoch 14
28/08/2018 23:55:36 - SaltNet - INFO - Epoch 15/49
28/08/2018 23:55:36 - SaltNet - INFO - --------------------
28/08/2018 23:55:44 - SaltNet - INFO - Batch Loss: 0.0608, Running loss: 1.0578, Batch IOU: 0.4000, Batch Acc: 0.9764 at iter 32, epoch 15, Time: 2m 49s
28/08/2018 23:55:44 - SaltNet - INFO - train Mean IOU: 0.7000, Mean Acc: 0.9806 at epoch 15
28/08/2018 23:55:48 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7923 at epoch 15
28/08/2018 23:55:48 - SaltNet - INFO - Epoch 16/49
28/08/2018 23:55:48 - SaltNet - INFO - --------------------
28/08/2018 23:55:55 - SaltNet - INFO - Batch Loss: 0.0412, Running loss: 1.0399, Batch IOU: 0.5000, Batch Acc: 0.9829 at iter 34, epoch 16, Time: 3m 0s
28/08/2018 23:55:55 - SaltNet - INFO - train Mean IOU: 0.4500, Mean Acc: 0.9875 at epoch 16
28/08/2018 23:55:59 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7961 at epoch 16
28/08/2018 23:55:59 - SaltNet - INFO - Epoch 17/49
28/08/2018 23:55:59 - SaltNet - INFO - --------------------
28/08/2018 23:56:07 - SaltNet - INFO - Batch Loss: 0.0314, Running loss: 1.0202, Batch IOU: 0.4500, Batch Acc: 0.9952 at iter 36, epoch 17, Time: 3m 13s
28/08/2018 23:56:08 - SaltNet - INFO - train Mean IOU: 0.4750, Mean Acc: 0.9901 at epoch 17
28/08/2018 23:56:11 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.8070 at epoch 17
28/08/2018 23:56:11 - SaltNet - INFO - Epoch 18/49
28/08/2018 23:56:11 - SaltNet - INFO - --------------------
28/08/2018 23:56:19 - SaltNet - INFO - Batch Loss: 0.0342, Running loss: 0.9974, Batch IOU: 0.4500, Batch Acc: 0.9827 at iter 38, epoch 18, Time: 3m 24s
28/08/2018 23:56:20 - SaltNet - INFO - train Mean IOU: 0.7250, Mean Acc: 0.9879 at epoch 18
28/08/2018 23:56:23 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.8236 at epoch 18
28/08/2018 23:56:23 - SaltNet - INFO - Epoch 19/49
28/08/2018 23:56:23 - SaltNet - INFO - --------------------
28/08/2018 23:56:31 - SaltNet - INFO - Batch Loss: 0.0508, Running loss: 0.9709, Batch IOU: 0.9500, Batch Acc: 0.9847 at iter 40, epoch 19, Time: 3m 37s
28/08/2018 23:56:32 - SaltNet - INFO - train Mean IOU: 0.4750, Mean Acc: 0.9875 at epoch 19
28/08/2018 23:56:35 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.8307 at epoch 19
28/08/2018 23:56:35 - SaltNet - INFO - Epoch 20/49
28/08/2018 23:56:35 - SaltNet - INFO - --------------------
28/08/2018 23:56:44 - SaltNet - INFO - Batch Loss: 0.0298, Running loss: 0.9414, Batch IOU: 0.8000, Batch Acc: 0.9966 at iter 42, epoch 20, Time: 3m 49s
28/08/2018 23:56:44 - SaltNet - INFO - train Mean IOU: 0.8750, Mean Acc: 0.9918 at epoch 20
28/08/2018 23:56:48 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.8277 at epoch 20
28/08/2018 23:56:48 - SaltNet - INFO - Epoch 21/49
28/08/2018 23:56:48 - SaltNet - INFO - --------------------
28/08/2018 23:56:55 - SaltNet - INFO - Batch Loss: 0.0231, Running loss: 0.9119, Batch IOU: 0.7500, Batch Acc: 0.9910 at iter 44, epoch 21, Time: 4m 1s
28/08/2018 23:56:56 - SaltNet - INFO - train Mean IOU: 0.8750, Mean Acc: 0.9918 at epoch 21
28/08/2018 23:56:59 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.8136 at epoch 21
28/08/2018 23:56:59 - SaltNet - INFO - Epoch 22/49
28/08/2018 23:56:59 - SaltNet - INFO - --------------------
28/08/2018 23:57:06 - SaltNet - INFO - Batch Loss: 0.0278, Running loss: 0.8871, Batch IOU: 0.6500, Batch Acc: 0.9886 at iter 46, epoch 22, Time: 4m 12s
28/08/2018 23:57:07 - SaltNet - INFO - train Mean IOU: 0.7750, Mean Acc: 0.9903 at epoch 22
28/08/2018 23:57:10 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7969 at epoch 22
28/08/2018 23:57:10 - SaltNet - INFO - Epoch 23/49
28/08/2018 23:57:10 - SaltNet - INFO - --------------------
28/08/2018 23:57:17 - SaltNet - INFO - Batch Loss: 0.0204, Running loss: 0.8666, Batch IOU: 0.9000, Batch Acc: 0.9951 at iter 48, epoch 23, Time: 4m 23s
28/08/2018 23:57:18 - SaltNet - INFO - train Mean IOU: 0.9000, Mean Acc: 0.9943 at epoch 23
28/08/2018 23:57:22 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7914 at epoch 23
28/08/2018 23:57:22 - SaltNet - INFO - Epoch 24/49
28/08/2018 23:57:22 - SaltNet - INFO - --------------------
28/08/2018 23:57:30 - SaltNet - INFO - Batch Loss: 0.0147, Running loss: 0.8493, Batch IOU: 0.9500, Batch Acc: 0.9967 at iter 50, epoch 24, Time: 4m 35s
28/08/2018 23:57:31 - SaltNet - INFO - train Mean IOU: 0.9250, Mean Acc: 0.9961 at epoch 24
28/08/2018 23:57:34 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7885 at epoch 24
28/08/2018 23:57:34 - SaltNet - INFO - Epoch 25/49
28/08/2018 23:57:34 - SaltNet - INFO - --------------------
28/08/2018 23:57:42 - SaltNet - INFO - Batch Loss: 0.0293, Running loss: 0.8344, Batch IOU: 0.1000, Batch Acc: 0.9899 at iter 52, epoch 25, Time: 4m 48s
28/08/2018 23:57:43 - SaltNet - INFO - train Mean IOU: 0.5500, Mean Acc: 0.9916 at epoch 25
28/08/2018 23:57:46 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7918 at epoch 25
28/08/2018 23:57:46 - SaltNet - INFO - Epoch 26/49
28/08/2018 23:57:46 - SaltNet - INFO - --------------------
28/08/2018 23:57:54 - SaltNet - INFO - Batch Loss: 0.0118, Running loss: 0.8187, Batch IOU: 0.9000, Batch Acc: 0.9955 at iter 54, epoch 26, Time: 4m 59s
28/08/2018 23:57:55 - SaltNet - INFO - train Mean IOU: 0.9500, Mean Acc: 0.9962 at epoch 26
28/08/2018 23:57:58 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7871 at epoch 26
28/08/2018 23:57:58 - SaltNet - INFO - Epoch 27/49
28/08/2018 23:57:58 - SaltNet - INFO - --------------------
28/08/2018 23:58:06 - SaltNet - INFO - Batch Loss: 0.0100, Running loss: 0.8066, Batch IOU: 0.9500, Batch Acc: 0.9959 at iter 56, epoch 27, Time: 5m 12s
28/08/2018 23:58:07 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9971 at epoch 27
28/08/2018 23:58:10 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7855 at epoch 27
28/08/2018 23:58:10 - SaltNet - INFO - Epoch 28/49
28/08/2018 23:58:10 - SaltNet - INFO - --------------------
28/08/2018 23:58:18 - SaltNet - INFO - Batch Loss: 0.0096, Running loss: 0.7971, Batch IOU: 1.0000, Batch Acc: 0.9980 at iter 58, epoch 28, Time: 5m 24s
28/08/2018 23:58:19 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9972 at epoch 28
28/08/2018 23:58:22 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7848 at epoch 28
28/08/2018 23:58:22 - SaltNet - INFO - Epoch 29/49
28/08/2018 23:58:22 - SaltNet - INFO - --------------------
28/08/2018 23:58:30 - SaltNet - INFO - Batch Loss: 0.0120, Running loss: 0.7892, Batch IOU: 0.4000, Batch Acc: 0.9978 at iter 60, epoch 29, Time: 5m 36s
28/08/2018 23:58:31 - SaltNet - INFO - train Mean IOU: 0.7000, Mean Acc: 0.9963 at epoch 29
28/08/2018 23:58:35 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7856 at epoch 29
28/08/2018 23:58:35 - SaltNet - INFO - Epoch 30/49
28/08/2018 23:58:35 - SaltNet - INFO - --------------------
28/08/2018 23:58:43 - SaltNet - INFO - Batch Loss: 0.0090, Running loss: 0.7813, Batch IOU: 0.9000, Batch Acc: 0.9967 at iter 62, epoch 30, Time: 5m 48s
28/08/2018 23:58:43 - SaltNet - INFO - train Mean IOU: 0.9500, Mean Acc: 0.9974 at epoch 30
28/08/2018 23:58:47 - SaltNet - INFO - val Mean IOU: 0.2500, Mean Acc: 0.7842 at epoch 30
28/08/2018 23:58:47 - SaltNet - INFO - Epoch 31/49
28/08/2018 23:58:47 - SaltNet - INFO - --------------------
28/08/2018 23:58:56 - SaltNet - INFO - Batch Loss: 0.0087, Running loss: 0.7760, Batch IOU: 1.0000, Batch Acc: 0.9983 at iter 64, epoch 31, Time: 6m 1s
28/08/2018 23:58:56 - SaltNet - INFO - train Mean IOU: 0.9500, Mean Acc: 0.9975 at epoch 31
28/08/2018 23:59:00 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7832 at epoch 31
28/08/2018 23:59:00 - SaltNet - INFO - Epoch 32/49
28/08/2018 23:59:00 - SaltNet - INFO - --------------------
28/08/2018 23:59:08 - SaltNet - INFO - Batch Loss: 0.0079, Running loss: 0.7725, Batch IOU: 1.0000, Batch Acc: 0.9969 at iter 66, epoch 32, Time: 6m 14s
28/08/2018 23:59:09 - SaltNet - INFO - train Mean IOU: 1.0000, Mean Acc: 0.9981 at epoch 32
28/08/2018 23:59:13 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7836 at epoch 32
28/08/2018 23:59:13 - SaltNet - INFO - Epoch 33/49
28/08/2018 23:59:13 - SaltNet - INFO - --------------------
28/08/2018 23:59:22 - SaltNet - INFO - Batch Loss: 0.0081, Running loss: 0.7687, Batch IOU: 0.9500, Batch Acc: 0.9975 at iter 68, epoch 33, Time: 6m 27s
28/08/2018 23:59:22 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9975 at epoch 33
28/08/2018 23:59:27 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7832 at epoch 33
28/08/2018 23:59:27 - SaltNet - INFO - Epoch 34/49
28/08/2018 23:59:27 - SaltNet - INFO - --------------------
28/08/2018 23:59:37 - SaltNet - INFO - Batch Loss: 0.0069, Running loss: 0.7656, Batch IOU: 1.0000, Batch Acc: 0.9984 at iter 70, epoch 34, Time: 6m 42s
28/08/2018 23:59:37 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9982 at epoch 34
28/08/2018 23:59:41 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7825 at epoch 34
28/08/2018 23:59:41 - SaltNet - INFO - Epoch 35/49
28/08/2018 23:59:41 - SaltNet - INFO - --------------------
28/08/2018 23:59:50 - SaltNet - INFO - Batch Loss: 0.0070, Running loss: 0.7636, Batch IOU: 0.9500, Batch Acc: 0.9992 at iter 72, epoch 35, Time: 6m 56s
28/08/2018 23:59:51 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9985 at epoch 35
28/08/2018 23:59:56 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7836 at epoch 35
28/08/2018 23:59:56 - SaltNet - INFO - Epoch 36/49
28/08/2018 23:59:56 - SaltNet - INFO - --------------------
29/08/2018 00:00:07 - SaltNet - INFO - Batch Loss: 0.0064, Running loss: 0.7606, Batch IOU: 1.0000, Batch Acc: 0.9977 at iter 74, epoch 36, Time: 7m 12s
29/08/2018 00:00:08 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9985 at epoch 36
29/08/2018 00:00:13 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7840 at epoch 36
29/08/2018 00:00:13 - SaltNet - INFO - Epoch 37/49
29/08/2018 00:00:13 - SaltNet - INFO - --------------------
29/08/2018 00:00:22 - SaltNet - INFO - Batch Loss: 0.0056, Running loss: 0.7573, Batch IOU: 1.0000, Batch Acc: 0.9992 at iter 76, epoch 37, Time: 7m 28s
29/08/2018 00:00:23 - SaltNet - INFO - train Mean IOU: 0.9750, Mean Acc: 0.9987 at epoch 37
29/08/2018 00:00:28 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7832 at epoch 37
29/08/2018 00:00:28 - SaltNet - INFO - Epoch 38/49
29/08/2018 00:00:28 - SaltNet - INFO - --------------------
29/08/2018 00:00:37 - SaltNet - INFO - Batch Loss: 0.0054, Running loss: 0.7552, Batch IOU: 1.0000, Batch Acc: 0.9985 at iter 78, epoch 38, Time: 7m 43s
29/08/2018 00:00:38 - SaltNet - INFO - train Mean IOU: 1.0000, Mean Acc: 0.9988 at epoch 38
29/08/2018 00:00:42 - SaltNet - INFO - val Mean IOU: 0.5000, Mean Acc: 0.7826 at epoch 38
29/08/2018 00:00:42 - SaltNet - INFO - Epoch 39/49
29/08/2018 00:00:42 - SaltNet - INFO - --------------------
