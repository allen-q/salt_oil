{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "salt_model_data_loader_V3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IUnFr6MO3Kk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Changes:\n",
        "1. Use updated data augumentation functions.\n",
        "2. Use ReduceLROnPlateau scheduler\n",
        "3. Fine tune based on previous version trained with 150 epochs."
      ]
    },
    {
      "metadata": {
        "id": "xaO5fG0VW5gB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install required packages if running on google colab"
      ]
    },
    {
      "metadata": {
        "id": "8n6EgF7sW5gC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    !pip install torch torchvision\n",
        "    !pip install imageio\n",
        "    !pip install Augmentor\n",
        "    !git clone https://github.com/allen-q/salt_oil.git\n",
        "    !git clone https://github.com/allen-q/salt_net.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3h4PngQ0s86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd salt_oil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVnBJygnW5gK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import required libs"
      ]
    },
    {
      "metadata": {
        "id": "x1VSamfH3Kk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ply\n",
        "import os\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import pickle\n",
        "from salt_func_lib import *\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "import datetime as dt\n",
        "import sys\n",
        "from optparse import OptionParser\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "from io import BytesIO\n",
        "import Augmentor\n",
        "from Augmentor.Operations import *\n",
        "from Augmentor import *\n",
        "import random\n",
        "import PIL\n",
        "import cv2 as cv\n",
        "% matplotlib inline\n",
        "% load_ext autoreload\n",
        "% autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I87qLhAOW5gO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Unet Modules"
      ]
    },
    {
      "metadata": {
        "id": "eC32auGDqVZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pytorch_unet.eval import eval_net\n",
        "from pytorch_unet.unet import UNet\n",
        "from pytorch_unet.unet.unet_parts import *\n",
        "from pytorch_unet.unet.resnet import *\n",
        "from pytorch_unet.utils import get_ids, split_ids, split_train_val, get_imgs_and_masks, batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O8Wz9H_iTDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Setup data type based on whether GPU is enabled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKYhIfCtEk6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
        "else:    \n",
        "    dtype = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51wk3a_bTtv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Data Type set to: {dtype}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30EV6nbKbtyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Global Variables"
      ]
    },
    {
      "metadata": {
        "id": "8zcHyi6AMfDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_global_variables():\n",
        "    \"\"\"initialize global variables such as db connection, logger etc.\"\"\"\n",
        "    global log\n",
        "    log = get_logger('SaltNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLILkc8Vbtya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_global_variables()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNoyvMPbFOF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_brightness(img, alpha=None, beta=None):\n",
        "    if alpha is None:\n",
        "        # get a random num from 0.75 to 1.25\n",
        "        alpha = (random.random()/2)+0.75\n",
        "    if beta is None:\n",
        "        # get a random num from -30 to 30\n",
        "        beta = round((random.random()-0.5)*60)\n",
        "    #print(f'a:{alpha}, b:{beta}')\n",
        "    img_new = cv.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "    return img_new.reshape(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KwNexNnZxQ7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaltDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, np_img, np_mask, df_depth, mean_img, out_size=101, \n",
        "                 out_ch=1, transform=None, random_brightness=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (string): Path to the image files.\n",
        "            train (bool): Load train or test data\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.np_img = np_img\n",
        "        self.np_mask = np_mask.clip(0,1)\n",
        "        self.df_depth = df_depth\n",
        "        self.mean_img = mean_img\n",
        "        self.out_size = out_size\n",
        "        self.out_ch = out_ch\n",
        "        self.transform = transform\n",
        "        self.random_brightness = random_brightness\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.np_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, torch.Tensor):\n",
        "            idx = idx.item()\n",
        "            \n",
        "        X = self.np_img[idx]\n",
        "        #X = X - self.mean_img\n",
        "\n",
        "        if self.np_mask is None:\n",
        "            y = np.zeros((101,101,1))\n",
        "        else:\n",
        "            y = self.np_mask[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img_in = PIL.Image.fromarray(np.c_[np.tile(X, 2), y*255])\n",
        "            #img_in = PIL.Image.fromarray(np.tile(y, 3)*255)\n",
        "            transformed = np.array(self.transform(img_in))\n",
        "            #X = np.clip(transformed[:,:,0:1]/255, 0., 1.) - self.mean_img\n",
        "            X = transformed[:,:,0:1]\n",
        "            y = np.clip(transformed[:,:,2:3]/255, 0., 1.)\n",
        "            \n",
        "        if self.random_brightness > random.random():            \n",
        "            X = adjust_brightness(X)\n",
        "            X = np.clip(X/255, 0., 1.) - self.mean_img\n",
        "        else:\n",
        "            X = np.clip(X/255, 0., 1.) - self.mean_img            \n",
        "        #from boxx import g\n",
        "        #g()\n",
        "        X = np.moveaxis(X, -1,0)\n",
        "\n",
        "        pad_size = self.out_size - X.shape[2]\n",
        "        pad_first = pad_size//2\n",
        "        pad_last = pad_size - pad_first\n",
        "        X = np.pad(X, [(0, 0),(pad_first, pad_last), (pad_first, pad_last)], mode='reflect')\n",
        "\n",
        "        d = self.df_depth.iloc[idx,0]\n",
        "\n",
        "        X = torch.from_numpy(X).float().type(dtype)\n",
        "        X = X.repeat(self.out_ch,1,1)\n",
        "        y = transform.resize(y, (101, 101), mode='constant', preserve_range=True)\n",
        "        y = torch.from_numpy(y).ge(0.5).float().squeeze().type(dtype)\n",
        "\n",
        "        return (X,y,d,idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q0_gBiSvxQ7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Pipeline_Salt(Augmentor.Pipeline):\n",
        "    def __init__(self, source_directory=None, output_directory=\"output\", save_format=None):\n",
        "        super(Pipeline_Salt, self).__init__(source_directory, output_directory, save_format)\n",
        "\n",
        "    def torch_transform(self):\n",
        "        def _transform(image):\n",
        "            for operation in self.operations:\n",
        "                r = round(random.uniform(0, 1), 1)\n",
        "                if r <= operation.probability:\n",
        "                    if not isinstance(image, list):\n",
        "                        image = [image]                        \n",
        "                    #print(type(operation))\n",
        "                    #print(np.array(image[0]).shape)                        \n",
        "                    image = operation.perform_operation(image)[0]\n",
        "\n",
        "            return image\n",
        "\n",
        "            \n",
        "        return _transform\n",
        "    \n",
        "    def crop_random_align(self, probability, min_factor, max_factor, mask_diff_pct, resample_filter=\"BICUBIC\"):     \n",
        "        if not 0 < probability <= 1:\n",
        "            raise ValueError(Pipeline._probability_error_text)\n",
        "        elif not (min_factor>0) and (min_factor<=1):\n",
        "            raise ValueError(\"min_factor must be between 0 and 1.\")\n",
        "        elif not (max_factor>0) and (min_factor<=1):\n",
        "            raise ValueError(\"max_factor must be between 0 and 1.\")\n",
        "        elif resample_filter not in Pipeline._legal_filters:\n",
        "            raise ValueError(\"The save_filter argument must be one of %s.\" % Pipeline._legal_filters)\n",
        "        else:\n",
        "            self.add_operation(CropRandomAlign(probability, min_factor, max_factor, mask_diff_pct, resample_filter))\n",
        "            \n",
        "    def resize_random(self, probability, min_factor, max_factor, resample_filter=\"BICUBIC\"):\n",
        "        if not 0 < probability <= 1:\n",
        "            raise ValueError(Pipeline._probability_error_text)\n",
        "        elif resample_filter not in Pipeline._legal_filters:\n",
        "            raise ValueError(\"The save_filter argument must be one of %s.\" % Pipeline._legal_filters)\n",
        "        else:\n",
        "            self.add_operation(ResizeRandom(probability=probability, min_factor=min_factor,\n",
        "                                            max_factor=max_factor, resample_filter=resample_filter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZ_h79Pusl6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResizeRandom(Operation):\n",
        "    \"\"\"\n",
        "    This class is used to resize an image by a random factor between min_factor and max_factor.\n",
        "    \"\"\"\n",
        "    def __init__(self, probability, min_factor, max_factor, resample_filter=\"BICUBIC\"):\n",
        "        Operation.__init__(self, probability)\n",
        "        self.min_factor = min_factor\n",
        "        self.max_factor = max_factor\n",
        "        self.resample_filter = resample_filter\n",
        "\n",
        "    def perform_operation(self, images):\n",
        "        \"\"\"\n",
        "        Resize the passed image and returns the resized image. Uses the\n",
        "        parameters passed to the constructor to resize the passed image.\n",
        "\n",
        "        :param images: The image to resize.\n",
        "        :type images: List containing PIL.Image object(s).\n",
        "        :return: The transformed image(s) as a list of object(s) of type\n",
        "         PIL.Image.\n",
        "        \"\"\"\n",
        "\n",
        "        def do(image):\n",
        "            width, height = image.size\n",
        "            resize_factor = random.randrange(round(self.min_factor*100), round(self.max_factor*100), 1)/100\n",
        "            width = round(width*resize_factor) \n",
        "            height = round(height*resize_factor) \n",
        "            print(f'New Width: {width}, New Height: {height}')\n",
        "            return image.resize((width, height), eval(\"Image.%s\" % self.resample_filter))\n",
        "\n",
        "        augmented_images = []\n",
        "\n",
        "        for image in images:\n",
        "            augmented_images.append(do(image))\n",
        "\n",
        "        return augmented_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUgnV0wpsl6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CropRandomAlign(Operation):\n",
        "    \"\"\"\n",
        "    This class is used to crop images a random factor between min_factor and max_factor and resize it to its original size.\n",
        "    \"\"\"\n",
        "    def __init__(self, probability, min_factor, max_factor, mask_diff_pct, resample_filter=\"BICUBIC\"):\n",
        "        Operation.__init__(self, probability)\n",
        "        self.min_factor = min_factor\n",
        "        self.max_factor = max_factor\n",
        "        self.mask_diff_pct = mask_diff_pct\n",
        "        self.resample_filter = resample_filter\n",
        "\n",
        "    def perform_operation(self, images):\n",
        "        \"\"\"\n",
        "        Crop the passed :attr:`images` by percentage area, returning the crop as an\n",
        "        image.\n",
        "\n",
        "        :param images: The image(s) to crop an area from.\n",
        "        :type images: List containing PIL.Image object(s).\n",
        "        :return: The transformed image(s) as a list of object(s) of type\n",
        "         PIL.Image.\n",
        "        \"\"\"\n",
        "\n",
        "        resize_factor = random.randrange(round(self.min_factor*100), round(self.max_factor*100), 1)/100\n",
        "\n",
        "        # The images must be of identical size, which is checked by Pipeline.ground_truth().\n",
        "        w, h = images[0].size\n",
        "\n",
        "        w_new = int(floor(w * resize_factor))  # TODO: Floor might return 0, so we need to check this.\n",
        "        h_new = int(floor(h * resize_factor))\n",
        "\n",
        "        def do(image, w, h):\n",
        "            img_np = np.array(image)\n",
        "            mask_in = img_np[:,:,2]\n",
        "            mask_in_pct = (mask_in>0).sum()/mask_in.size\n",
        "            img_out_candidate = None\n",
        "            lowest_diff = 1\n",
        "            for i in range(20):  \n",
        "                left_shift = random.randint(0, int((w - w_new)))\n",
        "                down_shift = random.randint(0, int((h - h_new)))\n",
        "                img_out = image.crop((left_shift, down_shift, w_new + left_shift, h_new + down_shift))\n",
        "                mask_out = np.array(img_out)[:,:,2]\n",
        "                mask_out_pct = (mask_out>0).sum()/mask_out.size\n",
        "                #print(f'mask_in_pct:{mask_in_pct}, mask_out_pct:{mask_out_pct}')\n",
        "                if (mask_in_pct==0) or (abs((mask_out_pct/mask_in_pct)-1) <= self.mask_diff_pct):                    \n",
        "                    img_out_candidate = img_out\n",
        "                    break\n",
        "                if (abs((mask_out_pct/mask_in_pct)-1)) <= lowest_diff:\n",
        "                    lowest_diff = abs((mask_out_pct/mask_in_pct)-1)\n",
        "                    img_out_candidate = img_out\n",
        "            if img_out_candidate is None:\n",
        "                img_out_candidate = image\n",
        "                print('Failed to crop image to fit requirements. Use orignal image.')\n",
        "            #print(f'Image Size after crop:{img_out_candidate.size}')\n",
        "            mask_out = np.array(img_out_candidate)[:,:,2]\n",
        "            #print(f'image mask pct:{(mask_out>0).sum()/mask_out.size}')\n",
        "            img_out_final = img_out_candidate.resize((w, h), eval(\"Image.%s\" % self.resample_filter))\n",
        "            #print(f'Image Size after resize:{img_out_final.size}')            \n",
        "            \n",
        "            return img_out_final\n",
        "            \n",
        "        augmented_images = []\n",
        "\n",
        "        for image in images:\n",
        "            augmented_images.append(do(image, w, h))\n",
        "\n",
        "        return augmented_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5Xa50QZsl6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''p = Pipeline_Salt()\n",
        "\n",
        "p.crop_random_align(1, 0.3, 0.5, 0.01)\n",
        "\n",
        "p.resize_random(probability=1,min_factor=1.1, max_factor=2.5, resample_filter='BILINEAR')\n",
        "\n",
        "img = np.c_[np.tile(X_train[1507], 2), y_train[1507]]\n",
        "\n",
        "plt.imshow(img[:,:,2], cmap='gray')\n",
        "\n",
        "img_in = PIL.Image.fromarray(img)\n",
        "tsfm = p.torch_transform()\n",
        "img_out = tsfm(img_in)\n",
        "\n",
        "np.array(img_out).shape\n",
        "\n",
        "plt.imshow(np.array(img_out)[:,:,2], cmap='gray')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEXPdEFd3KmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "53yVOPsQ3KmB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load train and test data from npy files or from raw images if npy files not exist."
      ]
    },
    {
      "metadata": {
        "id": "wO1kf6HW3KmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np_train_all, np_train_all_mask, X_test, misc_data = load_all_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUAORGGdEgJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate number of mask pixels per image"
      ]
    },
    {
      "metadata": {
        "id": "Hyt5JXyrEgKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_mask = pd.DataFrame((np_train_all_mask/255).sum((1,2,3)), columns=['mask_pix'])\n",
        "\n",
        "df_train_mask.mask_pix = df_train_mask.mask_pix.round(-2)\n",
        "\n",
        "mask_pix_bins = df_train_mask.mask_pix.sort_values().unique()\n",
        "# Due to zooming and crop, under-sample all black and all white masks, over-sample images with small mask areas.\n",
        "mask_pix_bin_weights = ([1.] + np.r_[2:1:102j].tolist() + [0.2])\n",
        "mask_pix_bin_weights = dict(zip(mask_pix_bins, mask_pix_bin_weights))\n",
        "\n",
        "train_all_sample_weight = df_train_mask.mask_pix.map(mask_pix_bin_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lq_sH6YeEgKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.log10(df_train_mask.mask_pix.div(100).add(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTkpzBqmGRN2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove black images"
      ]
    },
    {
      "metadata": {
        "id": "8BXkNsiZGRN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#black_img_ids = (np_train_all.max((1,2,3))==0)\n",
        "\n",
        "#np_train_all = np_train_all[~black_img_ids]\n",
        "#np_train_all_mask = np_train_all_mask[~black_img_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obPeKNjDGRN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np_train_all.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZqPs7VnYd56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove images with all black masks"
      ]
    },
    {
      "metadata": {
        "id": "lzqSzGzEYd5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#black_mask_ids = (np_train_all_mask.max((1,2,3))==0)\n",
        "#np_train_all = np_train_all[~black_mask_ids]\n",
        "#np_train_all_mask = np_train_all_mask[~black_mask_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNIS7zT23KmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Val data split"
      ]
    },
    {
      "metadata": {
        "id": "Q8HLh-bNQmNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np_train_all = np.clip(np_train_all/255, 0, 1)\n",
        "#X_test = np.clip(X_test/255, 0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqYjA-Ud3KmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_ids, X_val_ids = (\n",
        "    train_test_split(df_train_mask.index.tolist(), \n",
        "                     test_size=0.20,\n",
        "                     stratify = df_train_mask.mask_pix,\n",
        "                     random_state=0)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GAWRi1bLpyM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./data/df_train_img_iou.pickle', 'rb') as f:\n",
        "    df_train_img_iou = pickle.load(f)\n",
        "\n",
        "train_hard_img_id= (\n",
        "    [misc_data['np_train_all_ids'].index(e) for e in df_train_img_iou.loc[df_train_img_iou.type=='HARD'].id]\n",
        ")\n",
        "\n",
        "#X_train_ids = np.setdiff1d(X_train_ids, train_hard_img_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEqXO7GM3KmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np_train_all[X_train_ids]\n",
        "X_val = np_train_all[X_val_ids]\n",
        "y_train = np_train_all_mask[X_train_ids]\n",
        "y_val = np_train_all_mask[X_val_ids]\n",
        "depth_train = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_train_ids])\n",
        ")\n",
        "depth_val = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_val_ids])\n",
        ")\n",
        "depth_test = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_test_ids']))\n",
        ")\n",
        "#X_train_mean_img = X_train.mean(0).astype(np.float32)\n",
        "#X_train_mean_img = X_train.mean((0,1,2)).astype(np.float32)\n",
        "X_train_mean_img = np.clip(np_train_all/255, 0, 1).mean((0,1,2)).astype(np.float32)\n",
        "\n",
        "all_data = {\n",
        "    'X_train': X_train,\n",
        "    'X_val': X_val,\n",
        "    'y_train': y_train,\n",
        "    'y_val': y_val,\n",
        "    'X_test': X_test,\n",
        "    'X_train_mean_img': np.zeros_like(X_train_mean_img)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6BSSFObEgKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sample_weight = train_all_sample_weight[X_train_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ZVs5X-EpyNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dw2YwtbSmHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_mean_img = np.zeros_like(X_train_mean_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5cc6IFsXVU3j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_mean_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2L51fSDkpyNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zl5Q4dsOpyNa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "koLKXAYPpyNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "depth_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfYxl3YIR9LG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''p = Pipeline_Salt(min_mask_ratio=0.9)\n",
        "p.crop_random(probability=1, percentage_area=0.8, randomise_percentage_area=False)\n",
        "p.resize(probability=1, width=101, height=101, resample_filter='BILINEAR')\n",
        "img = np.c_[np.tile(X_train[469], 2), y_train[469]]\n",
        "img_in = PIL.Image.fromarray(img)\n",
        "tsfm = p.torch_transform()\n",
        "img_out = tsfm(img_in)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bMOyfebQmON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.95, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=5, max_right_rotation=5)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eXIcYoDqVcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Train Dataloader"
      ]
    },
    {
      "metadata": {
        "id": "uYerp5hjW5gu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values, depth_train.shape[0])\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': True}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           X_train_mean_img, out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "sample = iter(dataloaders['train']).__next__()\n",
        "\n",
        "assert sample[0].shape == torch.Size([train_data_params['batch_size'], 1, 128, 128])\n",
        "assert sample[1].shape == torch.Size([train_data_params['batch_size'], 101, 101])\n",
        "assert sample[2].shape == torch.Size([train_data_params['batch_size']])\n",
        "assert sample[3].shape == torch.Size([train_data_params['batch_size']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHZ6rNjxFOIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = iter(train_dataLoader).__next__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fgi872V02Fsz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch, d_batch, X_id = t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dp1YZ7D5QmOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for X_batch, y_batch, d_batch, X_id in dataloaders['train']:\n",
        "    i+=1\n",
        "    if i>30:\n",
        "        break\n",
        "    X_orig = X_train[X_id[0]].squeeze()/255\n",
        "    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "    y_orig = y_train[X_id[0]].squeeze()\n",
        "    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "    print(f'{X_orig.sum()}, {X_tsfm.sum()}')\n",
        "    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm],\n",
        "                       [f'X Original-{X_id[0]}', 'X Transformed', 'y Original', 'y Transformed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS4kZWQnW5gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Train Dataloader for sanity check"
      ]
    },
    {
      "metadata": {
        "id": "lP-yemq8pyOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(depth_train['weight'][:8], 2)#weight \n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values[:8], 2)\n",
        "train_data_params = {'batch_size': 2, 'shuffle': True,}\n",
        "val_data_params = {'batch_size': 2, 'shuffle': True,}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEA7t3xaQmOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataLoader  = (\n",
        "    DataLoader(SaltDataset(X_train[:4], y_train[:4], depth_train[:4],\n",
        "                           X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=None), **train_data_params)\n",
        "                           #transform=p.torch_transform()), **data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val[:4], y_val[:4], depth_val[:4], \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r2hyd9ryGROf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = iter(train_dataLoader).__next__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v34uY0GkGROl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch, d_batch, X_id = t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjWYq0PnjVlT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch[0].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3NeHMttxPA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_iter_stats(y_pred, y_batch, X_batch, X_id, train_params, other_data, epoch_losses, epoch, iter_count, start):\n",
        "    #from boxx import g\n",
        "    #g(), \n",
        "    epoch_losses = [round(e.item(),4) for e in torch.stack(epoch_losses).mean(0)]\n",
        "    iou_batch = calc_mean_iou(y_pred.ge(train_params['mask_cutoff']), y_batch)\n",
        "    iou_acc = calc_clf_accuracy(y_pred.ge(train_params['mask_cutoff']), y_batch)\n",
        "\n",
        "    log.info('Losses: {}, Batch IOU: {:.4f}, Batch Acc: {:.4f} at iter {}, epoch {}, Time: {}'.format(\n",
        "            epoch_losses, iou_batch, iou_acc, iter_count, epoch, timeSince(start))\n",
        "    )\n",
        "\n",
        "    X_train = other_data['X_train']\n",
        "    y_train = other_data['y_train']\n",
        "    X_train_mean_img = other_data['X_train_mean_img']\n",
        "    #print(all_losses)\n",
        "    X_orig = X_train[X_id[0]].squeeze()/255\n",
        "    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()\n",
        "    X_tsfm = X_tsfm[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "    y_orig = y_train[X_id[0]].squeeze()\n",
        "    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "    y_tsfm_pred =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm, y_tsfm_pred],\n",
        "                       ['X Original', 'X Transformed', 'y Original', 'y Transformed', 'y Predicted'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DT72CtdxPA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_epoch_stats(model, y_pred, y_batch, X_batch, X_id, other_data, pred_vs_true_epoch, train_params, phase, epoch, iter_count, best_iou, all_losses, epoch_losses, best_model):    \n",
        "    y_pred_epoch = torch.cat([e[0] for e in pred_vs_true_epoch])\n",
        "    y_true_epoch = torch.cat([e[1] for e in pred_vs_true_epoch])\n",
        "\n",
        "    mean_iou_epoch = calc_mean_iou(y_pred_epoch.ge(train_params['mask_cutoff']), y_true_epoch.float())\n",
        "    mean_acc_epoch = calc_clf_accuracy(y_pred_epoch.ge(train_params['mask_cutoff']), y_true_epoch.float())\n",
        "    mean_loss_epoch = [round(e.item(),4) for e in torch.stack(epoch_losses).mean(0)]\n",
        "\n",
        "    if phase == 'val':        \n",
        "        X_val = other_data['X_val']\n",
        "        y_val = other_data['y_val']\n",
        "        X_orig = X_val[X_id[0]].squeeze()/255\n",
        "        y_orig = y_val[X_id[0]].squeeze()\n",
        "        y_pred2 =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "        plot_img_mask_pred([X_orig, y_orig, y_pred2],\n",
        "                           ['Val X Original', 'Val y Original', 'Val y Predicted'])\n",
        "        if mean_iou_epoch > best_iou:\n",
        "            best_iou = mean_iou_epoch\n",
        "            stats = {'best_iou': best_iou,\n",
        "                   'all_losses': all_losses,\n",
        "                   'iter_count': iter_count}\n",
        "            best_model = (epoch, copy.deepcopy(model.state_dict()),\n",
        "                                              copy.deepcopy(optimizer.state_dict()),\n",
        "                                              copy.deepcopy(scheduler.state_dict()), stats, train_params['model_save_name'], '.')\n",
        "            log.info(save_model_state_to_chunks(*best_model))\n",
        "            log.info('Best Val Mean IOU so far: {}'.format(best_iou))        \n",
        "        log.info('Val   IOU: {:.4f}, Acc: {:.4f}, Best Val IOU: {:.4f} at epoch {}'.format(mean_iou_epoch, mean_acc_epoch, best_iou, epoch))\n",
        "    else:\n",
        "        log.info('Train IOU: {:.4f}, Acc: {:.4f}, Loss: {} at epoch {}'.format(mean_iou_epoch, mean_acc_epoch, mean_loss_epoch, epoch))\n",
        "        X_train = other_data['X_train']\n",
        "        y_train = other_data['y_train']\n",
        "        X_train_mean_img = other_data['X_train_mean_img']\n",
        "        X_orig = X_train[X_id[0]].squeeze()/255\n",
        "        X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()\n",
        "        X_tsfm = X_tsfm[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "        y_orig = y_train[X_id[0]].squeeze()\n",
        "        y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "        y_tsfm_pred =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "        plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm, y_tsfm_pred],\n",
        "                           ['X Original', 'X Transformed', 'y Original', 'y Transformed', 'y Predicted'])\n",
        "        \n",
        "    return best_iou, best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfa9Y5hlxPBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model_to_git(epoch, train_params, num_epochs, prev_best_iou, best_iou, best_model):    \n",
        "    if (epoch % train_params['save_model_every']== 0) | (epoch == num_epochs-1):\n",
        "        if train_params['model_save_name'] is None:\n",
        "            log.info(\"Skip pushing model to git as model_save_name is None.\")\n",
        "        elif (best_model is not None) and (best_iou > prev_best_iou):\n",
        "            log.info(save_model_state_to_chunks(*best_model))\n",
        "            push_model_to_git(ckp_name=train_params['model_save_name'])\n",
        "            prev_best_iou = best_iou\n",
        "        else:\n",
        "            log.info(\"Skip pushing model to git as there's no improvement\")\n",
        "            \n",
        "    return prev_best_iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-pRk5cqxPBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_loss(y_pred, y_batch, loss_fns, loss_fn_weights):\n",
        "     losses = []\n",
        "     for loss_fn, loss_fn_weight in zip(loss_fns, loss_fn_weights):\n",
        "         loss = loss_fn_weight * loss_fn(y_pred, y_batch)\n",
        "         losses.append(loss)  \n",
        "\n",
        "     return torch.stack(losses + [torch.stack(losses).sum()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGqBDcs3xPBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, loss_fns, loss_fn_weights, optimizer, scheduler, train_params, other_data):\n",
        "    log.info('Start Training...')    \n",
        "    log.info((dataloaders, loss_fns, loss_fn_weights, optimizer, scheduler, train_params))\n",
        "    num_epochs = train_params['num_epochs']\n",
        "    start = time.time()\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    best_model = None\n",
        "    best_iou = 0.0    \n",
        "    prev_best_iou = train_params['model_save_iou_threshold']\n",
        "    all_losses = []\n",
        "    iter_count = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        log.info('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        log.info('-' * 20)\n",
        "        if (epoch % train_params['save_log_every'] == 0):\n",
        "            push_log_to_git()\n",
        "        epoch_losses = []\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()      \n",
        "            pred_vs_true_epoch = []\n",
        "            for X_batch, y_batch, d_batch, X_id in dataloaders[phase]:\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    y_pred = model(X_batch)\n",
        "                    pred_vs_true_epoch.append([y_pred, y_batch])\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        losses = calc_loss(y_pred, y_batch.float(), loss_fns, loss_fn_weights)\n",
        "                        epoch_losses.append(losses)\n",
        "                        all_losses.append(losses)\n",
        "                        loss = losses[-1]\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        iter_count += 1\n",
        "            best_iou, best_model = log_epoch_stats(model, y_pred, y_batch, X_batch, X_id, other_data, pred_vs_true_epoch, train_params, \n",
        "                                                   phase, epoch, iter_count, best_iou, all_losses, epoch_losses, best_model)\n",
        "            \n",
        "        prev_best_iou = save_model_to_git(epoch, train_params, num_epochs, prev_best_iou, best_iou, best_model)\n",
        "        #from boxx import g\n",
        "        #g()\n",
        "        epoch_avg_loss = np.mean([e[-1].item() for e in epoch_losses])\n",
        "        #log.info(f'scheduler best: {scheduler.best} num_bad_epochs:{scheduler.num_bad_epochs}')\n",
        "        log.info(scheduler.step(epoch))\n",
        "\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model[1])\n",
        "    log.info('-' * 20)\n",
        "    log.info(f'Training complete in {(time.time() - start) // 60} mins. Best Val IOU {round(best_iou, 4)}')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dasEpZc0QmOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model using a small data set to see if it can overfit"
      ]
    },
    {
      "metadata": {
        "id": "2OoY1-HV8DZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True, threshold=0.001)\n",
        "model_save_name = None\n",
        "\n",
        "# Test Run\n",
        "#trained_model = train_model(saltnet, dataloaders, loss_fn_bce, loss_lovasz_hinge, optimizer, scheduler, model_save_name, \n",
        "#                other_data=all_data, num_epochs=100, print_every=8, save_model_every=None, save_log_every=None, log=log, loss2_weight=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyLX1EVIxPBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': None,\n",
        "    'save_model_every': 10000,\n",
        "    'save_log_every': 100,\n",
        "    'num_epochs': 10,\n",
        "    'print_every': 2,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0,\n",
        "    'model_save_iou_threshold': 0.1\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOBrMR_y03nO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scheduler.num_bad_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pE7Q6dd3xPBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.5), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJ3DJ4hAQmOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the full with full dataset"
      ]
    },
    {
      "metadata": {
        "id": "AZkSxKV2sIkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with Resnet 34 as backbone with Adam and updated data aug class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3treVXh_Uha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "\n",
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_new_aug_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 150,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.78\n",
        "    }\n",
        "    \n",
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yP2IQIkOD584",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ikq0ObjsDXc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8EUxk8UQmOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_new_aug_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wq1P9vlMDo06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 150,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.78\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2z9Brb8EgMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YyeACdxT7K54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_data.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkzkKviGQ1ME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "metadata": {
        "id": "6gH3StpeyZoc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with Resnet 34 as backbone with Adam and updated data aug class. Finetuning from IOU 0.8190. Less data aug. Using weight decay.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i1G7CTpsySfm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)\n",
        "\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_new_aug_finetune10_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLGTRHvqzIMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_oi9RzlTAhs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtqQX0Fdf0Gn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfnNZyIMjr2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSTGwh10UMrD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005, weight_decay=0.00001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1TB1NlPx-_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_weight_decay_finetune10_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OX55uUxAU4dF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 50,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.82\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dhAynj4XADB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "dfabc16e-a412-4a9e-e860-3456c6a4020b"
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_focal, loss_lovasz_hinge), (1, 0.05), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/09/2018 07:18:02 - SaltNet - INFO - Start Training...\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f914c233b00>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f914c2332e8>}, (FocalLoss(), LovaszHingeLoss()), (1, 0.05), Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    initial_lr: 0.0005\n",
            "    lr: 0.0005\n",
            "    weight_decay: 0.0001\n",
            "), <torch.optim.lr_scheduler.StepLR object at 0x7f914bfd79b0>, {'model_save_name': '../salt_net/Unet_res34_bce_lovasz_loss_se_weight_decay_finetune10_2018_09_25_17_00_30.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 50, 'log': <Logger SaltNet (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.82})\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - Epoch 1/50\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - --------------------\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "25/09/2018 07:21:13 - SaltNet - INFO - Train IOU: 0.8279, Acc: 0.9622, Loss: [0.0064, 0.0157, 0.0221] at epoch 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAC+CAYAAABwFT2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f914b71b160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1h0EQI7zk09r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mU7rj82kl-Aa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fine tune 2"
      ]
    },
    {
      "metadata": {
        "id": "dPpKzoJzl86z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with Resnet 34 as backbone with Adam and updated data aug class. Finetuning from IOU 0.8190. Less data aug. Using bigger weight decay 0.0001.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qbpyooDl862",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)\n",
        "\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_high)weight_decay_finetune11_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAerD30Sl863",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gqf9sxuCl863",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNVOOKvzl867",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4elknPBl868",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GZrQgTHl86-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsniDCiBl87A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_high)weight_decay_finetune11_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6VCBKdBl87B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 50,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.82\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yy917-gCl87G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "dfabc16e-a412-4a9e-e860-3456c6a4020b"
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_focal, loss_lovasz_hinge), (1, 0.05), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/09/2018 07:18:02 - SaltNet - INFO - Start Training...\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - ({'train': <torch.utils.data.dataloader.DataLoader object at 0x7f914c233b00>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f914c2332e8>}, (FocalLoss(), LovaszHingeLoss()), (1, 0.05), Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    initial_lr: 0.0005\n",
            "    lr: 0.0005\n",
            "    weight_decay: 0.0001\n",
            "), <torch.optim.lr_scheduler.StepLR object at 0x7f914bfd79b0>, {'model_save_name': '../salt_net/Unet_res34_bce_lovasz_loss_se_weight_decay_finetune10_2018_09_25_17_00_30.ckp', 'save_model_every': 20, 'save_log_every': 2, 'num_epochs': 50, 'log': <Logger SaltNet (DEBUG)>, 'mask_cutoff': 0.0, 'model_save_iou_threshold': 0.82})\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - Epoch 1/50\n",
            "25/09/2018 07:18:02 - SaltNet - INFO - --------------------\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yz6de-jqk1MN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvFrOke5k8r6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fine Tune 3"
      ]
    },
    {
      "metadata": {
        "id": "hrZeBWDpk7sX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with Resnet 34 as backbone with Adam and updated data aug class. Finetuning from IOU 0.8190. More data aug')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "syHs1nx-k7sY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.3, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=20, max_right_rotation=20)\n",
        "p.shear(probability=0.5, max_shear_left=20, max_shear_right=20)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)\n",
        "\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_more_aug_finetune11_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "train_model(saltnet, dataloaders, (loss_focal, loss_lovasz_hinge), (1, 0.05), optimizer, scheduler, train_params, all_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNrLEDE4k7sb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aOooQDhk7sc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.3, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=20, max_right_rotation=20)\n",
        "p.shear(probability=0.5, max_shear_left=20, max_shear_right=20)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MyGFaHcZk7sd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SuAvINNrk7se",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet = UResNet(pretrained=False)\n",
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_2018_09_20_12_08_04.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0kepifAk7sf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljBRWAazk7sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_bce_lovasz_loss_se_more_aug_finetune12_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bKSzBz0k7si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 50,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.82\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQDN4EgQk7sk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_focal, loss_lovasz_hinge), (1, 0.05), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9MW3YwaZQmOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Trained Model"
      ]
    },
    {
      "metadata": {
        "id": "ESBVbot1Qp7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded_model = UResNet(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIRv-uXQGROz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDpBS2c9ePeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cuoeW6MLd439",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_file_suffix = \"Unet_res34_bce_lovasz_loss_se_new_aug_finetuen1_2018_09_21_09_41_48.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "loaded_model.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbgxXtYH3KpR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Predictions on validation set"
      ]
    },
    {
      "metadata": {
        "id": "W0cFNMM0QmO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set model to evaluation mode"
      ]
    },
    {
      "metadata": {
        "id": "izo8iByg3KpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded_model.eval()\n",
        "assert loaded_model.training == False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfdN-P-j3KpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_dataLoader = DataLoader(SaltDataset(X_val, y_val, depth_val, X_train_mean_img, out_size=128), batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7M0ZHG7o6swA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    loaded_model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cAVNrwOUCkqI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8_AINAPClPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Eval model on Val data set"
      ]
    },
    {
      "metadata": {
        "id": "JMuArCUd3KpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_val_batch, y_val_batch, depth_val_batch, X_val_id_batch in val_dataLoader:\n",
        "        y_val_pred.append(loaded_model(X_val_batch))\n",
        "y_val_pred = torch.cat(y_val_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7EYzvT0fyPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.flip_left_right(probability=1)\n",
        "val_dataLoader = DataLoader(SaltDataset(X_val, y_val, depth_val, X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=p.torch_transform()), batch_size=16)\n",
        "y_val_pred_flip = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_val_batch, y_val_batch, depth_val_batch, X_val_id_batch in val_dataLoader:\n",
        "        y_val_pred_flip.append(loaded_model(X_val_batch))\n",
        "y_val_pred_flip = torch.cat(y_val_pred_flip)\n",
        "y_val_pred_flip = torch.flip(y_val_pred_flip,[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1_1icxBCsP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### merge normal pred and hflip pred"
      ]
    },
    {
      "metadata": {
        "id": "FZNYVKKPf0if",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_ens = torch.where(y_val_pred.abs() > y_val_pred_flip.abs(), y_val_pred, y_val_pred_flip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBO4WrvnCyex",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Check normal pred IOU"
      ]
    },
    {
      "metadata": {
        "id": "hSYVoI88HApH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(0, X_val, y_val_pred.gt(0), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EzTNcpMUC6Qo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Check TTA pred IOU"
      ]
    },
    {
      "metadata": {
        "id": "230OrjoPf0_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(0, X_val, y_val_pred_ens.gt(0), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZvUQtjqG_uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PYOWBAw7DCss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find best mask cutoff"
      ]
    },
    {
      "metadata": {
        "id": "dg4ZJEH_7VV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in np.r_[-0.1:0.1:50j]:\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(0, X_val, y_val_pred_ens.gt(cut_off), y_val.squeeze()), y_val.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXUNORfK8G4S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MASK_CUTOFF = np.r_[-0.1:0.1:50j][np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_ka-iqTgCYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'MASK_CUTOFF: {MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BlcQ7hthD6-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Find best ZERO_MASK_CUTOFF"
      ]
    },
    {
      "metadata": {
        "id": "nxNTal6nS8Za",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in range(0, 300, 10):\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(cut_off, X_val, y_val_pred_ens.gt(MASK_CUTOFF), y_val.squeeze()), y_val.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52zu8TbtEEAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ZERO_MASK_CUTOFF = range(0, 300, 10)[np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QC3Bk6PEEHZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'ZERO_MASK_CUTOFF: {ZERO_MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQ2C6bakEDYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred_ens.gt(MASK_CUTOFF), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "umePIs5RDvyw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### View a few val images with predictions"
      ]
    },
    {
      "metadata": {
        "id": "2_DJpL1o3KpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_val_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    val_img = X_val[rand_id]/255\n",
        "    val_mask = y_val[rand_id]\n",
        "    val_mask_pred = y_val_pred_ens.ge(MASK_CUTOFF)[rand_id]\n",
        "    plot_img_mask_pred([val_img, val_mask, val_mask_pred], range(3), img_per_line=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkD6eqk9ghEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BELGiJ1VEVw3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Eval model on Train data set"
      ]
    },
    {
      "metadata": {
        "id": "Vc8_yrUzEeWA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataLoader = DataLoader(SaltDataset(X_train, y_train, depth_train, X_train_mean_img, out_size=128), batch_size=32)\n",
        "y_train_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_train_batch, y_train_batch, depth_train_batch, X_train_id_batch in train_dataLoader:\n",
        "        y_train_pred.append(loaded_model(X_train_batch))\n",
        "y_train_pred = torch.cat(y_train_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pDFa_mNEebY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.flip_left_right(probability=1)\n",
        "train_dataLoader = DataLoader(SaltDataset(X_train, y_train, depth_train, X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=p.torch_transform()), batch_size=32)\n",
        "y_train_pred_flip = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_train_batch, y_train_batch, depth_train_batch, X_train_id_batch in train_dataLoader:\n",
        "        y_train_pred_flip.append(loaded_model(X_train_batch))\n",
        "y_train_pred_flip = torch.cat(y_train_pred_flip)\n",
        "y_train_pred_flip = torch.flip(y_train_pred_flip,[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4txEOloZFEqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### merge normal pred and hflip pred"
      ]
    },
    {
      "metadata": {
        "id": "lPCRVTSGFEqt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_pred_ens = torch.where(y_train_pred.abs() > y_train_pred_flip.abs(), y_train_pred, y_train_pred_flip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36inQqL2FEqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Check normal pred IOU"
      ]
    },
    {
      "metadata": {
        "id": "W-lLr9O9FEqw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_pred_adj = adjust_predictions(0, X_train, y_train_pred.gt(0), y_train.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HxkzmfT-FEqz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Check TTA pred IOU"
      ]
    },
    {
      "metadata": {
        "id": "2nxT3zdGFEq0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_pred_adj = adjust_predictions(0, X_train, y_train_pred_ens.gt(0), y_train.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7LEjByXFEq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AlqUaaKpFEq6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find best mask cutoff"
      ]
    },
    {
      "metadata": {
        "id": "DT58yYpmFEq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in np.r_[-0.2:0.2:50j]:\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(0, X_train, y_train_pred_ens.gt(cut_off), y_train.squeeze()), y_train.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7UxZ7-qiFj8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.r_[-0.2:0.2:50j][np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHeROpnjFEq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MASK_CUTOFF = np.r_[-0.1:0.1:50j][np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DQnSzmkGMvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MASK_CUTOFF = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Jyt5H9kFEq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'MASK_CUTOFF: {MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLUZy7TAFErD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Find best ZERO_MASK_CUTOFF"
      ]
    },
    {
      "metadata": {
        "id": "y2STul6jFErD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in range(0, 300, 10):\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(cut_off, X_train, y_train_pred_ens.gt(MASK_CUTOFF), y_train.squeeze()), y_train.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odyOnmrbFErG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ZERO_MASK_CUTOFF = range(0, 300, 10)[np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCjKZY5tFErH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'ZERO_MASK_CUTOFF: {ZERO_MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ap1JdDtFErL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred_ens.gt(MASK_CUTOFF), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xv1LkCTLEqg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCR_6IO1g7xE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_train, y_train_pred_ens.gt(MASK_CUTOFF), y_train.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tqf2DKD2CCjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_train_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    img = X_train[rand_id]/255\n",
        "    mask = y_train[rand_id]\n",
        "    mask_pred = y_train_pred.ge(MASK_CUTOFF)[rand_id]\n",
        "    plot_img_mask_pred([img, mask, mask_pred], range(3), img_per_line=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkzyRPIMDrAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions on test set using TTA"
      ]
    },
    {
      "metadata": {
        "id": "x38qXbAkmFSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfLrLArrEK5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict using original image"
      ]
    },
    {
      "metadata": {
        "id": "bUDZxfzlD_Os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, out_size=128), batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqKBooA3EC4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_raw = []\n",
        "with torch.no_grad():\n",
        "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
        "        y_test_pred_raw.append(loaded_model(X_test_batch))\n",
        "y_test_pred = torch.cat(y_test_pred_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7BiVrQKEFrk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict using flipped images"
      ]
    },
    {
      "metadata": {
        "id": "KjPkHzKBmz7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.flip_left_right(probability=1)\n",
        "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=p.torch_transform()), batch_size=32)\n",
        "y_test_pred_flip = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
        "        y_test_pred_flip.append(loaded_model(X_test_batch))\n",
        "y_test_pred_flip = torch.cat(y_test_pred_flip)\n",
        "y_test_pred_flip = torch.flip(y_test_pred_flip,[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9t1Z0kiEQkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Combine non-flip and flip predictions"
      ]
    },
    {
      "metadata": {
        "id": "_zUtOPXwmz7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = torch.where(y_test_pred.abs() > y_test_pred_flip.abs(), y_test_pred, y_test_pred_flip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzkEuhBwEXBl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Adjust predictions"
      ]
    },
    {
      "metadata": {
        "id": "JaDNBnwsBqF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MASK_CUTOFF = 0\n",
        "ZERO_MASK_CUTOFF = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89y4w6drFKSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'MASK_CUTOFF:{MASK_CUTOFF}, ZERO_MASK_CUTOFF:{ZERO_MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSe7dmyMqnPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_test, y_test_pred.gt(MASK_CUTOFF))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pd9DjVswEwUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Show segmentation masks for a few images"
      ]
    },
    {
      "metadata": {
        "id": "c9j_HYo6ExVL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_test_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    img = X_test[rand_id]/255\n",
        "    mask_pred = y_test_pred.ge(0.5)[rand_id]\n",
        "    plot_img_mask_pred([img, mask_pred], range(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bmi3NISwEaOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare for submission"
      ]
    },
    {
      "metadata": {
        "id": "fATv5NS6hnkU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_rle = rle_encoder3d(y_test_pred_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBNylCIDhnkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_adj.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwSpGmvthnkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle = pd.DataFrame(index=misc_data['np_test_ids'], data=y_test_pred_rle).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r3bS6FoNhnki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.columns = ['id', 'rle_mask']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRDcCLpohnkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle[df_test_rle.rle_mask==''].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkOmz86lhnkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xr_NOtxBhnky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.to_csv(f'submission_{get_current_time_as_fname()}.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n__2CiMjhnk2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCv-diichnk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgzFDdcShnlA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('submission_2018_09_21_13_11_16.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1D61fkPaiUR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}