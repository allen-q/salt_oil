{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUnFr6MO3Kk3"
   },
   "source": [
    "# Changes:\n",
    "1. Use the 1st version UNET\n",
    "2. Use focal loss function\n",
    "3. Best Val Mean IOU so far: 0.7804 at epoch 209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaO5fG0VW5gB"
   },
   "source": [
    "## Install required packages if running on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "8n6EgF7sW5gC",
    "outputId": "3c5a3693-02c3-46a6-c784-de8ff2cef635"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    !pip install torch torchvision\n",
    "    !pip install imageio\n",
    "    !git clone https://github.com/allen-q/salt_oil.git\n",
    "    !git clone https://github.com/allen-q/salt_net.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tH3tfAVnW5gG",
    "outputId": "89647e0a-e806-49a3-f53f-e51beda825c8"
   },
   "outputs": [],
   "source": [
    "cd salt_oil/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVnBJygnW5gK"
   },
   "source": [
    "## Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1VSamfH3Kk6"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as ply\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import pickle\n",
    "from salt_func_lib import *\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "import datetime as dt\n",
    "import sys\n",
    "from optparse import OptionParser\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "from io import BytesIO\n",
    "% matplotlib inline\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I87qLhAOW5gO"
   },
   "source": [
    "## Load Unet Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC32auGDqVZi"
   },
   "outputs": [],
   "source": [
    "from pytorch_unet.eval import eval_net\n",
    "from pytorch_unet.unet import UNet\n",
    "from pytorch_unet.unet.unet_parts import *\n",
    "from pytorch_unet.utils import get_ids, split_ids, split_train_val, get_imgs_and_masks, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6O8Wz9H_iTDE"
   },
   "outputs": [],
   "source": [
    "## Setup data type based on whether GPU is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKYhIfCtEk6C"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "else:    \n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "51wk3a_bTtv-",
    "outputId": "da357c28-ca47-4e49-f8d0-76bee8b45343"
   },
   "outputs": [],
   "source": [
    "print(f'Data Type set to: {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30EV6nbKbtyV"
   },
   "source": [
    "## Create Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zcHyi6AMfDf"
   },
   "outputs": [],
   "source": [
    "def init_global_variables():\n",
    "    \"\"\"initialize global variables such as db connection, logger etc.\"\"\"\n",
    "    global log\n",
    "    log = get_logger('SaltNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLILkc8Vbtya"
   },
   "outputs": [],
   "source": [
    "init_global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEXPdEFd3KmA"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53yVOPsQ3KmB"
   },
   "source": [
    "### Load train and test data from npy files or from raw images if npy files not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "wO1kf6HW3KmC",
    "outputId": "29f40ef2-28ff-4aea-daba-952ef0b3a418"
   },
   "outputs": [],
   "source": [
    "np_train_all, np_train_all_mask, X_test, misc_data = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTkpzBqmGRN2"
   },
   "source": [
    "### Remove black images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BXkNsiZGRN3"
   },
   "outputs": [],
   "source": [
    "#black_img_ids = (np_train_all.max((1,2,3))==0)\n",
    "\n",
    "#np_train_all = np_train_all[~black_img_ids]\n",
    "#np_train_all_mask = np_train_all_mask[~black_img_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "obPeKNjDGRN6",
    "outputId": "903926ec-41e0-4ba0-d242-bbf133997c6d"
   },
   "outputs": [],
   "source": [
    "np_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZqPs7VnYd56"
   },
   "source": [
    "### Remove images with all black masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzqSzGzEYd5-"
   },
   "outputs": [],
   "source": [
    "#black_mask_ids = (np_train_all_mask.max((1,2,3))==0)\n",
    "#np_train_all = np_train_all[~black_mask_ids]\n",
    "#np_train_all_mask = np_train_all_mask[~black_mask_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNIS7zT23KmI"
   },
   "source": [
    "### Train Val data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8HLh-bNQmNz"
   },
   "outputs": [],
   "source": [
    "np_train_all = np.clip(np_train_all/255, 0, 1)\n",
    "X_test = np.clip(X_test/255, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqYjA-Ud3KmI"
   },
   "outputs": [],
   "source": [
    "X_train_ids, X_val_ids = (\n",
    "    train_test_split(np.arange(len(np_train_all)), \n",
    "                     test_size=0.20, \n",
    "                     random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEqXO7GM3KmN"
   },
   "outputs": [],
   "source": [
    "X_train = np_train_all[X_train_ids]\n",
    "X_val = np_train_all[X_val_ids]\n",
    "y_train = np_train_all_mask[X_train_ids]\n",
    "y_val = np_train_all_mask[X_val_ids]\n",
    "depth_train = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_train_all_ids'])[X_train_ids])\n",
    ")\n",
    "depth_val = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_train_all_ids'])[X_val_ids])\n",
    ")\n",
    "depth_test = (\n",
    "    misc_data['df_train_all_depth']\n",
    "    .reindex(np.array(misc_data['np_test_ids']))\n",
    ")\n",
    "#X_train_mean_img = X_train.mean(0).astype(np.float32)\n",
    "X_train_mean_img = X_train.mean((0,1,2)).astype(np.float32)\n",
    "\n",
    "all_data = {\n",
    "    'X_train': X_train,\n",
    "    'X_val': X_val,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'X_test': X_test,\n",
    "    'X_train_mean_img': X_train_mean_img\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0bMOyfebQmON",
    "outputId": "0c226166-14b5-49dc-e962-85c92ba172f9"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eXIcYoDqVcF"
   },
   "source": [
    "### Create a Train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYerp5hjW5gu"
   },
   "outputs": [],
   "source": [
    "composed_tsfm = transforms.Compose([Rescale(scale='random', max_scale=2),\n",
    "                                    RandomCrop(101),\n",
    "                                    Flip(orient='random')])\n",
    "\n",
    "data_params = {'batch_size': 32,\n",
    "               'shuffle': True,\n",
    "               'drop_last': False}\n",
    "\n",
    "train_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
    "                           X_train_mean_img, out_size=128,  out_ch=1,\n",
    "                           transform=composed_tsfm), **data_params)\n",
    ")\n",
    "\n",
    "val_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
    "                           X_train_mean_img, out_size=128, out_ch=1), **data_params)\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
    "\n",
    "sample = iter(dataloaders['train']).__next__()\n",
    "\n",
    "assert sample[0].shape == torch.Size([data_params['batch_size'], 1, 128, 128])\n",
    "assert sample[1].shape == torch.Size([data_params['batch_size'], 101, 101])\n",
    "assert sample[2].shape == torch.Size([data_params['batch_size']])\n",
    "assert sample[3].shape == torch.Size([data_params['batch_size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "colab_type": "code",
    "id": "dp1YZ7D5QmOg",
    "outputId": "fd86408c-ed29-48eb-e223-684cb8a1357a"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for X_batch, y_batch, d_batch, X_id in dataloaders['train']:\n",
    "    i+=1\n",
    "    if i>3:\n",
    "        break\n",
    "    X_orig = X_train[X_id[0]].squeeze()\n",
    "    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()[13:114,13:114] + X_train_mean_img.squeeze()\n",
    "    y_orig = y_train[X_id[0]].squeeze()\n",
    "    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
    "    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm],\n",
    "                       [f'X Original-{X_id[0]}', 'X Transformed', 'y Original', 'y Transformed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GbN1-S12btDL",
    "outputId": "61ae70d5-885b-4181-a279-9a516eb1fe3c"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qS4kZWQnW5gw"
   },
   "source": [
    "### Create a Train Dataloader for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEA7t3xaQmOo"
   },
   "outputs": [],
   "source": [
    "data_params = {'batch_size': 2,\n",
    "               'shuffle': True,\n",
    "               'drop_last': False}\n",
    "\n",
    "train_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_train[:4], y_train[:4], depth_train[:4],\n",
    "                           X_train_mean_img, out_size=128, out_ch=1,\n",
    "                           transform=None), **data_params)\n",
    ")\n",
    "\n",
    "val_dataLoader = (\n",
    "    DataLoader(SaltDataset(X_val[:4], y_val[:4], depth_val[:4], \n",
    "                           X_train_mean_img, out_size=128, out_ch=1), **data_params)\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2hyd9ryGROf"
   },
   "outputs": [],
   "source": [
    "t = iter(train_dataLoader).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v34uY0GkGROl"
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch, d_batch, X_id = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EO4pel0cjVlR"
   },
   "outputs": [],
   "source": [
    "y_batch.view(y_batch.shape[0],-1).mean(1)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.4,0.6,1]).type(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjWYq0PnjVlT"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion1, criterion2, optimizer, scheduler, model_save_name, other_data={}, \n",
    "                num_epochs=25, print_every=2, save_model_every=None, save_log_every=None, log=get_logger('SaltNet')):\n",
    "    #args = locals()\n",
    "    #args = {k:v.shape if isinstance(v, (torch.Tensor, np.ndarray)) else v for k,v in args.items()}\n",
    "    #args = {k:v.shape if isinstance(v, (torch.Tensor, np.ndarray)) else v for k,v in args.items()}\n",
    "    log.info('Start Training...')\n",
    "    #log.info('Passed parameters: {}'.format(args))\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_model = None\n",
    "    best_iou = 0.0\n",
    "    all_losses = []\n",
    "    iter_count = 0\n",
    "    X_train = other_data['X_train']\n",
    "    X_val = other_data['X_val']\n",
    "    y_train = other_data['y_train']\n",
    "    y_val = other_data['y_val']\n",
    "    X_train_mean_img = other_data['X_train_mean_img']\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        log.info('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        log.info('-' * 20)\n",
    "        if save_log_every is not None:\n",
    "            if (epoch % save_log_every == 0):\n",
    "                push_log_to_git()\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            epoch_loss = []\n",
    "            epoch_mask_loss = []\n",
    "            pred_vs_true_epoch = []\n",
    "\n",
    "            for X_batch, y_batch, d_batch, X_id in dataloaders[phase]:\n",
    "                #print(X_batch.shape)\n",
    "                #print(len(iter(dataloaders[phase])))\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred, y_mask_pred = model(X_batch)\n",
    "                    pred_vs_true_epoch.append([y_pred, y_batch])\n",
    "                    #from boxx import g\n",
    "                    #g()\n",
    "                    loss_pix = criterion1(y_pred, y_batch.float())        \n",
    "                    y_batch2 = (y_batch.view(y_batch.shape[0],-1).mean(1)==1).float()\n",
    "                    loss_mask = criterion2(y_mask_pred, y_batch2)\n",
    "                    print(f'Loss1: {loss1}, Loss2:{loss2}')\n",
    "                    loss = loss_pix + loss_mask\n",
    "                    all_losses.append(loss.item())\n",
    "                    epoch_loss.append(loss.item())\n",
    "                    epoch_mask_loss.append(loss_mask.item())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        iter_count += 1\n",
    "                if (phase == 'train') & (iter_count % print_every == 0):\n",
    "                    iou_batch = calc_mean_iou(y_pred.ge(0.5), y_batch.float())\n",
    "                    iou_acc = calc_clf_accuracy(y_pred.ge(0.5), y_batch.float())\n",
    "\n",
    "                    log.info('Batch Loss: {:.4f}, Epoch loss: {:.4f}, Epoch mask loss: {:.4f}, Batch IOU: {:.4f}, Batch Acc: {:.4f} at iter {}, epoch {}, Time: {}'.format(\n",
    "                        np.mean(all_losses[-print_every:]), np.mean(epoch_loss), np.mean(epoch_mask_loss),iou_batch, iou_acc, iter_count, epoch, timeSince(start))\n",
    "                    )\n",
    "                    X_orig = X_train[X_id[0]].squeeze()\n",
    "                    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()\n",
    "                    X_tsfm = transform.resize(X_tsfm, (128, 128), mode='constant', preserve_range=True)\n",
    "                    X_tsfm = X_tsfm[13:114,13:114] + X_train_mean_img.squeeze()\n",
    "                    #X_tsfm = X_batch[0][X_batch[0].sum((1,2)).argmax()].squeeze().cpu().detach().numpy()[:101,:101] + X_train_mean_img.squeeze()\n",
    "\n",
    "                    y_orig = y_train[X_id[0]].squeeze()\n",
    "                    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
    "                    y_tsfm_pred =  y_pred[0].squeeze().gt(0.5)\n",
    "                    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm, y_tsfm_pred],\n",
    "                                       ['X Original', 'X Transformed', 'y Original', 'y Transformed', 'y Predicted'])\n",
    "\n",
    "            y_pred_epoch = torch.cat([e[0] for e in pred_vs_true_epoch])\n",
    "            y_true_epoch = torch.cat([e[1] for e in pred_vs_true_epoch])\n",
    "            #from boxx import g\n",
    "            #g()\n",
    "            mean_iou_epoch = calc_mean_iou(y_pred_epoch.ge(0.5), y_true_epoch.float())\n",
    "            mean_acc_epoch = calc_clf_accuracy(y_pred_epoch.ge(0.5), y_true_epoch.float())\n",
    "            log.info('{} Mean IOU: {:.4f}, Mean Acc: {:.4f}, Best Val IOU: {:.4f} at epoch {}'.format(phase, mean_iou_epoch, mean_acc_epoch, best_iou, epoch))\n",
    "            if phase == 'val' and mean_iou_epoch > best_iou:\n",
    "                best_iou = mean_iou_epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                stats = {'best_iou': best_iou,\n",
    "                         'all_losses': all_losses,\n",
    "                         'iter_count': iter_count}\n",
    "                log.info(save_model_state_to_chunks(epoch, copy.deepcopy(model.state_dict()),\n",
    "                                                    copy.deepcopy(optimizer.state_dict()),\n",
    "                                                    copy.deepcopy(scheduler.state_dict()), stats, model_save_name, '.'))\n",
    "                best_model = (epoch, copy.deepcopy(model.state_dict()),\n",
    "                                                    copy.deepcopy(optimizer.state_dict()),\n",
    "                                                    copy.deepcopy(scheduler.state_dict()), stats, model_save_name, '.')\n",
    "                log.info('Best Val Mean IOU so far: {}'.format(best_iou))\n",
    "                # Visualize 1 val sample and predictions\n",
    "                X_orig = X_val[X_id[0]].squeeze()\n",
    "                y_orig = y_val[X_id[0]].squeeze()\n",
    "                y_pred2 =  y_pred[0].squeeze().gt(0.5)\n",
    "                plot_img_mask_pred([X_orig, y_orig, y_pred2],\n",
    "                                   ['Val X Original', 'Val y Original', 'Val y Predicted'])\n",
    "        if save_model_every is not None:\n",
    "            if (epoch % save_model_every == 0) | (epoch == num_epochs-1):\n",
    "                if best_model is not None:\n",
    "                    log.info(save_model_state_to_chunks(*best_model))                \n",
    "                    push_model_to_git(ckp_name=model_save_name)\n",
    "                    best_model = None\n",
    "                else:\n",
    "                    log.info(\"Skip pushing model to git as there's no improvement\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    log.info('-' * 20)\n",
    "    time_elapsed = time.time() - start\n",
    "    log.info('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log.info('Best val IOU: {:4f}'.format(best_iou))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dasEpZc0QmOt"
   },
   "source": [
    "## Train the model using a small data set to see if it can overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "7SbmYNEfkWQB",
    "outputId": "a58ddaf3-3229-48cc-9114-c5c8db503f41"
   },
   "outputs": [],
   "source": [
    "saltnet = UNet(n_channels=1, n_classes=1, pred_overall_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUpXWmcBYd6o"
   },
   "outputs": [],
   "source": [
    "#saltnet = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
    "\n",
    "loss_focal = FocalLoss(alpha=0.25, gamma=2)\n",
    "loss_focal_mask = FocalLoss(alpha=0.25, gamma=3)\n",
    "#loss_fn_iou = IOU_Loss()\n",
    "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "model_save_name = None\n",
    "\n",
    "# Test Run\n",
    "trained_model = train_model(saltnet, dataloaders, loss_focal, loss_focal_mask, optimizer, scheduler, model_save_name, \n",
    "                other_data=all_data, num_epochs=50, print_every=2, save_model_every=None, save_log_every=None, log=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJ3DJ4hAQmOw"
   },
   "source": [
    "## Train the full with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlWpXuqfjVlY"
   },
   "outputs": [],
   "source": [
    "saltnet = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
    "saltnet.load_state_dict(torch.load('Unet_Resnet34_scale_1.2_baseline_2018_08_29_10_41_13.ckp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116209
    },
    "colab_type": "code",
    "id": "u8EUxk8UQmOx",
    "outputId": "c6985226-1ef7-443c-9cdb-159c2113f6cf"
   },
   "outputs": [],
   "source": [
    "#saltnet = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
    "saltnet = UNet(n_channels=1, n_classes=1)\n",
    "\n",
    "loss_fn_bce = nn.BCELoss()\n",
    "loss_focal = FocalLoss(alpha=0.25, gamma=2)\n",
    "#loss_fn_iou = IOU_Loss()\n",
    "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "model_save_name = f'Unet_unet_focal_loss_baseline_{get_current_time_as_fname()}.ckp'\n",
    "\n",
    "# Test Run\n",
    "trained_model = train_model(saltnet, dataloaders, loss_focal, optimizer, scheduler, model_save_name, \n",
    "                            other_data=all_data, num_epochs=250, print_every=50, push_every=5, log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjq6xItfYd7i"
   },
   "outputs": [],
   "source": [
    "push_to_git??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MW3YwaZQmOz"
   },
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "nhbzdnLKmXvv",
    "outputId": "4d33d7b4-52d3-4623-ae97-25a7d4750f85"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIRv-uXQGROz"
   },
   "outputs": [],
   "source": [
    "loaded_model = trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6MJDoaNS5SA"
   },
   "outputs": [],
   "source": [
    "'''loaded_model = resnet18unet()\n",
    "model_file_suffix = \"Unet_Resnet34_scale_1.2_baseline_2018_08_29_10_41_13.ckp\"\n",
    "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
    "loaded_model.load_state_dict(model_state_dict['model'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6XTR_yEKoKE"
   },
   "outputs": [],
   "source": [
    "loaded_model = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
    "model_file_suffix = \"Unet_Resnet34_scale_1.2_baseline_2018_08_29_10_41_13.ckp\"\n",
    "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
    "loaded_model.load_state_dict(model_state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-k_yN6WKy92"
   },
   "outputs": [],
   "source": [
    "torch.save(loaded_model.state_dict(), 'Unet_Resnet34_scale_1.2_baseline_2018_08_29_10_41_13.ckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kegmy71jLW5i"
   },
   "outputs": [],
   "source": [
    "    log.info('Pushing model state to git.')\n",
    "    get_ipython().system(\"git config user.email 'allen.qin.au@gmail.com'\")\n",
    "    get_ipython().system('git add .')\n",
    "    get_ipython().system('git commit -m \"Unet_Resnet34_scale_1.2_baseline_2018_08_29_10_41_13.\"')\n",
    "    get_ipython().system('git push https://allen.qin.au%40gmail.com:github0mygod@github.com/allen-q/salt_oil.git --all --force')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbgxXtYH3KpR"
   },
   "source": [
    "### Make Predictions on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0cFNMM0QmO4"
   },
   "source": [
    "### Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izo8iByg3KpP"
   },
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "assert loaded_model.training == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfdN-P-j3KpS"
   },
   "outputs": [],
   "source": [
    "val_dataLoader = DataLoader(SaltDataset(X_val, y_val, depth_val, X_train_mean_img, img_out_size=128), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7M0ZHG7o6swA"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMuArCUd3KpU"
   },
   "outputs": [],
   "source": [
    "y_val_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_val_batch, y_val_batch, depth_val_batch, X_val_id_batch in val_dataLoader:\n",
    "        y_val_pred.append(loaded_model(X_val_batch))\n",
    "y_val_pred = torch.cat(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxNTal6nS8Za"
   },
   "outputs": [],
   "source": [
    "train_dataLoader = DataLoader(SaltDataset(X_train, y_train, depth_train, X_train_mean_img, img_out_size=128), batch_size=16)\n",
    "y_train_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_train_batch, y_train_batch, depth_train_batch, X_train_id_batch in train_dataLoader:\n",
    "        y_train_pred.append(loaded_model(X_train_batch))\n",
    "y_train_pred = torch.cat(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_DJpL1o3KpY"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rand_id = np.random.choice(X_val_id_batch)\n",
    "    print(f'Image ID: {rand_id}')\n",
    "    val_img = X_val[rand_id]\n",
    "    val_mask = y_val[rand_id]\n",
    "    val_mask_pred = y_val_pred.ge(0.5)[rand_id]\n",
    "    plot_img_mask_pred([val_img, val_mask, val_mask_pred], range(3), img_per_line=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkD6eqk9ghEe"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rand_id = np.random.choice(X_train_id_batch)\n",
    "    print(f'Image ID: {rand_id}')\n",
    "    img = X_train[rand_id]\n",
    "    mask = y_train[rand_id]\n",
    "    mask_pred = y_train_pred.ge(0.5)[rand_id]\n",
    "    plot_img_mask_pred([img, mask, mask_pred], range(3), img_per_line=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFW4BqZx8VzV"
   },
   "outputs": [],
   "source": [
    "ZERO_MASK_CUTOFF = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMbnI4J6Jkr1"
   },
   "outputs": [],
   "source": [
    "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred.gt(0.5), y_val.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPOBqHPDVbzS"
   },
   "outputs": [],
   "source": [
    "y_val_pred_adj = adjust_predictions(100, X_val, y_val_pred.gt(0.5), y_val.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgcUBfKx8rpd"
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for cut_off in range(0, 3000, 10):\n",
    "  print(cut_off)\n",
    "  results.append(calc_mean_iou(adjust_predictions(cut_off, X_val, y_val_pred.gt(0.5), y_val.squeeze()), y_val.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcfUIfJyNna6"
   },
   "outputs": [],
   "source": [
    "ZERO_MASK_CUTOFF = range(0, 3000, 10)[np.argmax(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmT8DPBnGRPh"
   },
   "outputs": [],
   "source": [
    "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred.gt(0.5), y_val.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCR_6IO1g7xE"
   },
   "outputs": [],
   "source": [
    "y_train_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_train, y_train_pred.gt(0.5), y_train.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1oSze9o3Kp_"
   },
   "source": [
    "## Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6ocZkIAS8Zf"
   },
   "outputs": [],
   "source": [
    "#test_dataLoader = DataLoader(SaltDataset(np_test[:10], None, depth_test, X_train_mean_img), batch_size=4)\n",
    "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, img_out_size=128), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChMRx1kh3KqE"
   },
   "outputs": [],
   "source": [
    "y_test_pred_raw = []\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
    "        y_test_pred_raw.append(loaded_model(X_test_batch))\n",
    "y_test_pred = torch.cat(y_test_pred_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XiRFXS8K3KqI"
   },
   "source": [
    "### Show segmentation masks for a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8_mXXfA3KqI"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rand_id = np.random.choice(X_test_id_batch)\n",
    "    print(f'Image ID: {rand_id}')\n",
    "    img = X_test[rand_id]\n",
    "    mask_pred = y_test_pred.ge(0.5)[rand_id]\n",
    "    plot_img_mask_pred([img, mask_pred], range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnjDYjvp3KqK"
   },
   "source": [
    "### Adjust predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jojQbvhtS8Zn"
   },
   "outputs": [],
   "source": [
    "y_test_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_test, y_test_pred.gt(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M52jKbLA3KqM"
   },
   "source": [
    "### Encode predictions using RLE(Run Length Encoding) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uW0shno43KqM"
   },
   "outputs": [],
   "source": [
    "y_test_pred_rle = rle_encoder3d(y_test_pred_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdPQnJqUS8Zr"
   },
   "outputs": [],
   "source": [
    "y_test_pred_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GaCKooz3KqN"
   },
   "outputs": [],
   "source": [
    "df_test_rle = pd.DataFrame(index=misc_data['np_test_ids'], data=y_test_pred_rle).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loaXDzkM3KqQ"
   },
   "outputs": [],
   "source": [
    "df_test_rle.columns = ['id', 'rle_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_iM1oRr3KqS"
   },
   "outputs": [],
   "source": [
    "df_test_rle[df_test_rle.rle_mask==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJzlb6q7cCM-"
   },
   "outputs": [],
   "source": [
    "df_test_rle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09CFLpNL3KqY"
   },
   "outputs": [],
   "source": [
    "df_test_rle.to_csv(f'submission_{get_current_time_as_fname()}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_1B43JYGRQI"
   },
   "outputs": [],
   "source": [
    "push_to_git()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "salt_model_data_loader_V3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
