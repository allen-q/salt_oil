{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "salt_model_data_loader_V3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IUnFr6MO3Kk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Changes:\n",
        "1. Use Unet with Squeeze and Excitation blocks"
      ]
    },
    {
      "metadata": {
        "id": "xaO5fG0VW5gB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install required packages if running on google colab"
      ]
    },
    {
      "metadata": {
        "id": "8n6EgF7sW5gC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    !pip install torch torchvision\n",
        "    !pip install imageio\n",
        "    !pip install Augmentor\n",
        "    !git clone https://github.com/allen-q/salt_oil.git\n",
        "    !git clone https://github.com/allen-q/salt_net.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3h4PngQ0s86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd salt_oil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVnBJygnW5gK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import required libs"
      ]
    },
    {
      "metadata": {
        "id": "x1VSamfH3Kk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ply\n",
        "import os\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import math\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import pickle\n",
        "from salt_func_lib import *\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "import datetime as dt\n",
        "import sys\n",
        "from optparse import OptionParser\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "from io import BytesIO\n",
        "import Augmentor\n",
        "from Augmentor.Operations import *\n",
        "from Augmentor import *\n",
        "import random\n",
        "import PIL\n",
        "import cv2 as cv\n",
        "% matplotlib inline\n",
        "% load_ext autoreload\n",
        "% autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I87qLhAOW5gO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Unet Modules"
      ]
    },
    {
      "metadata": {
        "id": "eC32auGDqVZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pytorch_unet.eval import eval_net\n",
        "from pytorch_unet.unet import UNet\n",
        "from pytorch_unet.unet.unet_parts import *\n",
        "from pytorch_unet.unet.resnet_v8 import *\n",
        "from pytorch_unet.utils import get_ids, split_ids, split_train_val, get_imgs_and_masks, batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O8Wz9H_iTDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Setup data type based on whether GPU is enabled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKYhIfCtEk6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
        "else:    \n",
        "    dtype = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51wk3a_bTtv-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'Data Type set to: {dtype}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "30EV6nbKbtyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Global Variables"
      ]
    },
    {
      "metadata": {
        "id": "8zcHyi6AMfDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_global_variables():\n",
        "    \"\"\"initialize global variables such as db connection, logger etc.\"\"\"\n",
        "    global log\n",
        "    log = get_logger('SaltNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLILkc8Vbtya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init_global_variables()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNoyvMPbFOF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_brightness(img, alpha=None, beta=None):\n",
        "    if alpha is None:\n",
        "        # get a random num from 0.75 to 1.25\n",
        "        alpha = (random.random()/2)+0.75\n",
        "    if beta is None:\n",
        "        # get a random num from -30 to 30\n",
        "        beta = round((random.random()-0.5)*60)\n",
        "    #print(f'a:{alpha}, b:{beta}')\n",
        "    img_new = cv.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "    return img_new.reshape(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KwNexNnZxQ7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaltDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, np_img, np_mask, df_depth, mean_img, out_size=101, \n",
        "                 out_ch=1, transform=None, random_brightness=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (string): Path to the image files.\n",
        "            train (bool): Load train or test data\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.np_img = np_img\n",
        "        self.np_mask = np_mask.clip(0,1)\n",
        "        self.df_depth = df_depth\n",
        "        self.mean_img = mean_img\n",
        "        self.out_size = out_size\n",
        "        self.out_ch = out_ch\n",
        "        self.transform = transform\n",
        "        self.random_brightness = random_brightness\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.np_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, torch.Tensor):\n",
        "            idx = idx.item()\n",
        "            \n",
        "        X = self.np_img[idx]\n",
        "        #X = X - self.mean_img\n",
        "\n",
        "        if self.np_mask is None:\n",
        "            y = np.zeros((101,101,1))\n",
        "        else:\n",
        "            y = self.np_mask[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img_in = PIL.Image.fromarray(np.c_[np.tile(X, 2), y*255])\n",
        "            #img_in = PIL.Image.fromarray(np.tile(y, 3)*255)\n",
        "            transformed = np.array(self.transform(img_in))\n",
        "            #X = np.clip(transformed[:,:,0:1]/255, 0., 1.) - self.mean_img\n",
        "            X = transformed[:,:,0:1]\n",
        "            y = np.clip(transformed[:,:,2:3]/255, 0., 1.)\n",
        "            \n",
        "        if self.random_brightness > random.random():            \n",
        "            X = adjust_brightness(X)\n",
        "            X = np.clip(X/255, 0., 1.) - self.mean_img\n",
        "        else:\n",
        "            X = np.clip(X/255, 0., 1.) - self.mean_img            \n",
        "        #from boxx import g\n",
        "        #g()\n",
        "        X = np.moveaxis(X, -1,0)\n",
        "\n",
        "        pad_size = self.out_size - X.shape[2]\n",
        "        pad_first = pad_size//2\n",
        "        pad_last = pad_size - pad_first\n",
        "        X = np.pad(X, [(0, 0),(pad_first, pad_last), (pad_first, pad_last)], mode='reflect')\n",
        "\n",
        "        d = self.df_depth.iloc[idx,0]\n",
        "\n",
        "        X = torch.from_numpy(X).float().type(dtype)\n",
        "        X = X.repeat(self.out_ch,1,1)\n",
        "        y = transform.resize(y, (101, 101), mode='constant', preserve_range=True)\n",
        "        y = torch.from_numpy(y).ge(0.5).float().squeeze().type(dtype)\n",
        "\n",
        "        return (X,y,d,idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q0_gBiSvxQ7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Pipeline_Salt(Augmentor.Pipeline):\n",
        "    def __init__(self, source_directory=None, output_directory=\"output\", save_format=None):\n",
        "        super(Pipeline_Salt, self).__init__(source_directory, output_directory, save_format)\n",
        "\n",
        "    def torch_transform(self):\n",
        "        def _transform(image):\n",
        "            for operation in self.operations:\n",
        "                r = round(random.uniform(0, 1), 1)\n",
        "                if r <= operation.probability:\n",
        "                    if not isinstance(image, list):\n",
        "                        image = [image]                        \n",
        "                    #print(type(operation))\n",
        "                    #print(np.array(image[0]).shape)                        \n",
        "                    image = operation.perform_operation(image)[0]\n",
        "\n",
        "            return image\n",
        "\n",
        "            \n",
        "        return _transform\n",
        "    \n",
        "    def crop_random_align(self, probability, min_factor, max_factor, mask_diff_pct, resample_filter=\"BICUBIC\"):     \n",
        "        if not 0 < probability <= 1:\n",
        "            raise ValueError(Pipeline._probability_error_text)\n",
        "        elif not (min_factor>0) and (min_factor<=1):\n",
        "            raise ValueError(\"min_factor must be between 0 and 1.\")\n",
        "        elif not (max_factor>0) and (min_factor<=1):\n",
        "            raise ValueError(\"max_factor must be between 0 and 1.\")\n",
        "        elif resample_filter not in Pipeline._legal_filters:\n",
        "            raise ValueError(\"The save_filter argument must be one of %s.\" % Pipeline._legal_filters)\n",
        "        else:\n",
        "            self.add_operation(CropRandomAlign(probability, min_factor, max_factor, mask_diff_pct, resample_filter))\n",
        "            \n",
        "    def resize_random(self, probability, min_factor, max_factor, resample_filter=\"BICUBIC\"):\n",
        "        if not 0 < probability <= 1:\n",
        "            raise ValueError(Pipeline._probability_error_text)\n",
        "        elif resample_filter not in Pipeline._legal_filters:\n",
        "            raise ValueError(\"The save_filter argument must be one of %s.\" % Pipeline._legal_filters)\n",
        "        else:\n",
        "            self.add_operation(ResizeRandom(probability=probability, min_factor=min_factor,\n",
        "                                            max_factor=max_factor, resample_filter=resample_filter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZ_h79Pusl6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResizeRandom(Operation):\n",
        "    \"\"\"\n",
        "    This class is used to resize an image by a random factor between min_factor and max_factor.\n",
        "    \"\"\"\n",
        "    def __init__(self, probability, min_factor, max_factor, resample_filter=\"BICUBIC\"):\n",
        "        Operation.__init__(self, probability)\n",
        "        self.min_factor = min_factor\n",
        "        self.max_factor = max_factor\n",
        "        self.resample_filter = resample_filter\n",
        "\n",
        "    def perform_operation(self, images):\n",
        "        \"\"\"\n",
        "        Resize the passed image and returns the resized image. Uses the\n",
        "        parameters passed to the constructor to resize the passed image.\n",
        "\n",
        "        :param images: The image to resize.\n",
        "        :type images: List containing PIL.Image object(s).\n",
        "        :return: The transformed image(s) as a list of object(s) of type\n",
        "         PIL.Image.\n",
        "        \"\"\"\n",
        "\n",
        "        def do(image):\n",
        "            width, height = image.size\n",
        "            resize_factor = random.randrange(round(self.min_factor*100), round(self.max_factor*100), 1)/100\n",
        "            width = round(width*resize_factor) \n",
        "            height = round(height*resize_factor) \n",
        "            print(f'New Width: {width}, New Height: {height}')\n",
        "            return image.resize((width, height), eval(\"Image.%s\" % self.resample_filter))\n",
        "\n",
        "        augmented_images = []\n",
        "\n",
        "        for image in images:\n",
        "            augmented_images.append(do(image))\n",
        "\n",
        "        return augmented_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUgnV0wpsl6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CropRandomAlign(Operation):\n",
        "    \"\"\"\n",
        "    This class is used to crop images a random factor between min_factor and max_factor and resize it to its original size.\n",
        "    \"\"\"\n",
        "    def __init__(self, probability, min_factor, max_factor, mask_diff_pct, resample_filter=\"BICUBIC\"):\n",
        "        Operation.__init__(self, probability)\n",
        "        self.min_factor = min_factor\n",
        "        self.max_factor = max_factor\n",
        "        self.mask_diff_pct = mask_diff_pct\n",
        "        self.resample_filter = resample_filter\n",
        "\n",
        "    def perform_operation(self, images):\n",
        "        \"\"\"\n",
        "        Crop the passed :attr:`images` by percentage area, returning the crop as an\n",
        "        image.\n",
        "\n",
        "        :param images: The image(s) to crop an area from.\n",
        "        :type images: List containing PIL.Image object(s).\n",
        "        :return: The transformed image(s) as a list of object(s) of type\n",
        "         PIL.Image.\n",
        "        \"\"\"\n",
        "\n",
        "        resize_factor = random.randrange(round(self.min_factor*100), round(self.max_factor*100), 1)/100\n",
        "\n",
        "        # The images must be of identical size, which is checked by Pipeline.ground_truth().\n",
        "        w, h = images[0].size\n",
        "\n",
        "        w_new = int(floor(w * resize_factor))  # TODO: Floor might return 0, so we need to check this.\n",
        "        h_new = int(floor(h * resize_factor))\n",
        "\n",
        "        def do(image, w, h):\n",
        "            img_np = np.array(image)\n",
        "            mask_in = img_np[:,:,2]\n",
        "            mask_in_pct = (mask_in>0).sum()/mask_in.size\n",
        "            img_out_candidate = None\n",
        "            lowest_diff = 1\n",
        "            for i in range(20):  \n",
        "                left_shift = random.randint(0, int((w - w_new)))\n",
        "                down_shift = random.randint(0, int((h - h_new)))\n",
        "                img_out = image.crop((left_shift, down_shift, w_new + left_shift, h_new + down_shift))\n",
        "                mask_out = np.array(img_out)[:,:,2]\n",
        "                mask_out_pct = (mask_out>0).sum()/mask_out.size\n",
        "                #print(f'mask_in_pct:{mask_in_pct}, mask_out_pct:{mask_out_pct}')\n",
        "                if (mask_in_pct==0) or (abs((mask_out_pct/mask_in_pct)-1) <= self.mask_diff_pct):                    \n",
        "                    img_out_candidate = img_out\n",
        "                    break\n",
        "                if (abs((mask_out_pct/mask_in_pct)-1)) <= lowest_diff:\n",
        "                    lowest_diff = abs((mask_out_pct/mask_in_pct)-1)\n",
        "                    img_out_candidate = img_out\n",
        "            if img_out_candidate is None:\n",
        "                img_out_candidate = image\n",
        "                print('Failed to crop image to fit requirements. Use orignal image.')\n",
        "            #print(f'Image Size after crop:{img_out_candidate.size}')\n",
        "            mask_out = np.array(img_out_candidate)[:,:,2]\n",
        "            #print(f'image mask pct:{(mask_out>0).sum()/mask_out.size}')\n",
        "            img_out_final = img_out_candidate.resize((w, h), eval(\"Image.%s\" % self.resample_filter))\n",
        "            #print(f'Image Size after resize:{img_out_final.size}')            \n",
        "            \n",
        "            return img_out_final\n",
        "            \n",
        "        augmented_images = []\n",
        "\n",
        "        for image in images:\n",
        "            augmented_images.append(do(image, w, h))\n",
        "\n",
        "        return augmented_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5Xa50QZsl6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''p = Pipeline_Salt()\n",
        "\n",
        "p.crop_random_align(1, 0.3, 0.5, 0.01)\n",
        "\n",
        "p.resize_random(probability=1,min_factor=1.1, max_factor=2.5, resample_filter='BILINEAR')\n",
        "\n",
        "img = np.c_[np.tile(X_train[1507], 2), y_train[1507]]\n",
        "\n",
        "plt.imshow(img[:,:,2], cmap='gray')\n",
        "\n",
        "img_in = PIL.Image.fromarray(img)\n",
        "tsfm = p.torch_transform()\n",
        "img_out = tsfm(img_in)\n",
        "\n",
        "np.array(img_out).shape\n",
        "\n",
        "plt.imshow(np.array(img_out)[:,:,2], cmap='gray')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEXPdEFd3KmA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "metadata": {
        "id": "53yVOPsQ3KmB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load train and test data from npy files or from raw images if npy files not exist."
      ]
    },
    {
      "metadata": {
        "id": "wO1kf6HW3KmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np_train_all, np_train_all_mask, X_test, misc_data = load_all_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUAORGGdEgJx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate number of mask pixels per image"
      ]
    },
    {
      "metadata": {
        "id": "Hyt5JXyrEgKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_mask = pd.DataFrame((np_train_all_mask/255).sum((1,2,3)), columns=['mask_pix'])\n",
        "\n",
        "df_train_mask.mask_pix = df_train_mask.mask_pix.round(-2)\n",
        "\n",
        "mask_pix_bins = df_train_mask.mask_pix.sort_values().unique()\n",
        "# Due to zooming and crop, under-sample all black and all white masks, over-sample images with small mask areas.\n",
        "mask_pix_bin_weights = ([1.] + np.r_[2:1:102j].tolist() + [0.2])\n",
        "mask_pix_bin_weights = dict(zip(mask_pix_bins, mask_pix_bin_weights))\n",
        "\n",
        "train_all_sample_weight = df_train_mask.mask_pix.map(mask_pix_bin_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lq_sH6YeEgKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.log10(df_train_mask.mask_pix.div(100).add(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTkpzBqmGRN2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove black images"
      ]
    },
    {
      "metadata": {
        "id": "8BXkNsiZGRN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#black_img_ids = (np_train_all.max((1,2,3))==0)\n",
        "\n",
        "#np_train_all = np_train_all[~black_img_ids]\n",
        "#np_train_all_mask = np_train_all_mask[~black_img_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "obPeKNjDGRN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np_train_all.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZqPs7VnYd56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove images with all black masks"
      ]
    },
    {
      "metadata": {
        "id": "lzqSzGzEYd5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#black_mask_ids = (np_train_all_mask.max((1,2,3))==0)\n",
        "#np_train_all = np_train_all[~black_mask_ids]\n",
        "#np_train_all_mask = np_train_all_mask[~black_mask_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNIS7zT23KmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Val data split"
      ]
    },
    {
      "metadata": {
        "id": "Q8HLh-bNQmNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np_train_all = np.clip(np_train_all/255, 0, 1)\n",
        "#X_test = np.clip(X_test/255, 0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqYjA-Ud3KmI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_ids, X_val_ids = (\n",
        "    train_test_split(df_train_mask.index.tolist(), \n",
        "                     test_size=0.20,\n",
        "                     stratify = df_train_mask.mask_pix,\n",
        "                     random_state=0)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GAWRi1bLpyM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('./data/df_train_img_iou.pickle', 'rb') as f:\n",
        "    df_train_img_iou = pickle.load(f)\n",
        "\n",
        "train_hard_img_id= (\n",
        "    [misc_data['np_train_all_ids'].index(e) for e in df_train_img_iou.loc[df_train_img_iou.type=='HARD'].id]\n",
        ")\n",
        "\n",
        "#X_train_ids = np.setdiff1d(X_train_ids, train_hard_img_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEqXO7GM3KmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np_train_all[X_train_ids]\n",
        "X_val = np_train_all[X_val_ids]\n",
        "y_train = np_train_all_mask[X_train_ids]\n",
        "y_val = np_train_all_mask[X_val_ids]\n",
        "depth_train = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_train_ids])\n",
        ")\n",
        "depth_val = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_train_all_ids'])[X_val_ids])\n",
        ")\n",
        "depth_test = (\n",
        "    misc_data['df_train_all_depth']\n",
        "    .reindex(np.array(misc_data['np_test_ids']))\n",
        ")\n",
        "#X_train_mean_img = X_train.mean(0).astype(np.float32)\n",
        "#X_train_mean_img = X_train.mean((0,1,2)).astype(np.float32)\n",
        "X_train_mean_img = np.clip(np_train_all/255, 0, 1).mean((0,1,2)).astype(np.float32)\n",
        "\n",
        "all_data = {\n",
        "    'X_train': X_train,\n",
        "    'X_val': X_val,\n",
        "    'y_train': y_train,\n",
        "    'y_val': y_val,\n",
        "    'X_test': X_test,\n",
        "    'X_train_mean_img': np.zeros_like(X_train_mean_img)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6BSSFObEgKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sample_weight = train_all_sample_weight[X_train_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ZVs5X-EpyNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-dw2YwtbSmHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_mean_img = np.zeros_like(X_train_mean_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5cc6IFsXVU3j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_mean_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2L51fSDkpyNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zl5Q4dsOpyNa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "koLKXAYPpyNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "depth_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfYxl3YIR9LG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''p = Pipeline_Salt(min_mask_ratio=0.9)\n",
        "p.crop_random(probability=1, percentage_area=0.8, randomise_percentage_area=False)\n",
        "p.resize(probability=1, width=101, height=101, resample_filter='BILINEAR')\n",
        "img = np.c_[np.tile(X_train[469], 2), y_train[469]]\n",
        "img_in = PIL.Image.fromarray(img)\n",
        "tsfm = p.torch_transform()\n",
        "img_out = tsfm(img_in)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0bMOyfebQmON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.2)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.5, min_factor=0.5, max_factor=0.95, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=5, max_right_rotation=5)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eXIcYoDqVcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Train Dataloader"
      ]
    },
    {
      "metadata": {
        "id": "uYerp5hjW5gu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values, depth_train.shape[0])\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': True}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           X_train_mean_img, out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "sample = iter(dataloaders['train']).__next__()\n",
        "\n",
        "assert sample[0].shape == torch.Size([train_data_params['batch_size'], 1, 128, 128])\n",
        "assert sample[1].shape == torch.Size([train_data_params['batch_size'], 101, 101])\n",
        "assert sample[2].shape == torch.Size([train_data_params['batch_size']])\n",
        "assert sample[3].shape == torch.Size([train_data_params['batch_size']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHZ6rNjxFOIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = iter(train_dataLoader).__next__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fgi872V02Fsz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch, d_batch, X_id = t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dp1YZ7D5QmOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for X_batch, y_batch, d_batch, X_id in dataloaders['train']:\n",
        "    i+=1\n",
        "    if i>30:\n",
        "        break\n",
        "    X_orig = X_train[X_id[0]].squeeze()/255\n",
        "    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "    y_orig = y_train[X_id[0]].squeeze()\n",
        "    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "    print(f'{X_orig.sum()}, {X_tsfm.sum()}')\n",
        "    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm],\n",
        "                       [f'X Original-{X_id[0]}', 'X Transformed', 'y Original', 'y Transformed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS4kZWQnW5gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Train Dataloader for sanity check"
      ]
    },
    {
      "metadata": {
        "id": "lP-yemq8pyOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(depth_train['weight'][:8], 2)#weight \n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values[:8], 2)\n",
        "train_data_params = {'batch_size': 32, 'shuffle': True,}\n",
        "val_data_params = {'batch_size': 32, 'shuffle': True,}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEA7t3xaQmOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataLoader  = (\n",
        "    DataLoader(SaltDataset(X_train[:32], y_train[:32], depth_train[:32],\n",
        "                           X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=None), **train_data_params)\n",
        "                           #transform=p.torch_transform()), **data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val[:32], y_val[:32], depth_val[:32], \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r2hyd9ryGROf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = iter(train_dataLoader).__next__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v34uY0GkGROl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch, d_batch, X_id = t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjWYq0PnjVlT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch[0].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3NeHMttxPA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_iter_stats(y_pred, y_batch, X_batch, X_id, train_params, other_data, epoch_losses, epoch, iter_count, start):\n",
        "    #from boxx import g\n",
        "    #g(), \n",
        "    epoch_losses = [round(e.item(),4) for e in torch.stack(epoch_losses).mean(0)]\n",
        "    iou_batch = calc_mean_iou(y_pred.ge(train_params['mask_cutoff']), y_batch)\n",
        "    iou_acc = calc_clf_accuracy(y_pred.ge(train_params['mask_cutoff']), y_batch)\n",
        "\n",
        "    log.info('Losses: {}, Batch IOU: {:.4f}, Batch Acc: {:.4f} at iter {}, epoch {}, Time: {}'.format(\n",
        "            epoch_losses, iou_batch, iou_acc, iter_count, epoch, timeSince(start))\n",
        "    )\n",
        "\n",
        "    X_train = other_data['X_train']\n",
        "    y_train = other_data['y_train']\n",
        "    X_train_mean_img = other_data['X_train_mean_img']\n",
        "    #print(all_losses)\n",
        "    X_orig = X_train[X_id[0]].squeeze()/255\n",
        "    X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()\n",
        "    X_tsfm = X_tsfm[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "    y_orig = y_train[X_id[0]].squeeze()\n",
        "    y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "    y_tsfm_pred =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "    plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm, y_tsfm_pred],\n",
        "                       ['X Original', 'X Transformed', 'y Original', 'y Transformed', 'y Predicted'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DT72CtdxPA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_epoch_stats(model, y_pred, y_batch, X_batch, X_id, other_data, pred_vs_true_epoch, train_params, phase, epoch, iter_count, best_iou, all_losses, epoch_losses, best_model):    \n",
        "    y_pred_epoch = torch.cat([e[0] for e in pred_vs_true_epoch])\n",
        "    y_true_epoch = torch.cat([e[1] for e in pred_vs_true_epoch])\n",
        "\n",
        "    mean_iou_epoch = calc_mean_iou(y_pred_epoch.ge(train_params['mask_cutoff']), y_true_epoch.float())\n",
        "    mean_acc_epoch = calc_clf_accuracy(y_pred_epoch.ge(train_params['mask_cutoff']), y_true_epoch.float())\n",
        "    mean_loss_epoch = [round(e.item(),4) for e in torch.stack(epoch_losses).mean(0)]\n",
        "\n",
        "    if phase == 'val':        \n",
        "        X_val = other_data['X_val']\n",
        "        y_val = other_data['y_val']\n",
        "        X_orig = X_val[X_id[0]].squeeze()/255\n",
        "        y_orig = y_val[X_id[0]].squeeze()\n",
        "        y_pred2 =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "        plot_img_mask_pred([X_orig, y_orig, y_pred2],\n",
        "                           ['Val X Original', 'Val y Original', 'Val y Predicted'])\n",
        "        if mean_iou_epoch > best_iou:\n",
        "            best_iou = mean_iou_epoch\n",
        "            stats = {'best_iou': best_iou,\n",
        "                   'all_losses': all_losses,\n",
        "                   'iter_count': iter_count}\n",
        "            best_model = (epoch, copy.deepcopy(model.state_dict()),\n",
        "                                              copy.deepcopy(optimizer.state_dict()),\n",
        "                                              copy.deepcopy(scheduler.state_dict()), stats, train_params['model_save_name'], '.')\n",
        "            log.info(save_model_state_to_chunks(*best_model))\n",
        "            log.info('Best Val Mean IOU so far: {}'.format(best_iou))        \n",
        "        log.info('Val   IOU: {:.4f}, Acc: {:.4f}, Best Val IOU: {:.4f} at epoch {}'.format(mean_iou_epoch, mean_acc_epoch, best_iou, epoch))\n",
        "    else:\n",
        "        log.info('Train IOU: {:.4f}, Acc: {:.4f}, Loss: {} at epoch {}'.format(mean_iou_epoch, mean_acc_epoch, mean_loss_epoch, epoch))\n",
        "        X_train = other_data['X_train']\n",
        "        y_train = other_data['y_train']\n",
        "        X_train_mean_img = other_data['X_train_mean_img']\n",
        "        X_orig = X_train[X_id[0]].squeeze()/255\n",
        "        X_tsfm = X_batch[0,0].squeeze().cpu().detach().numpy()\n",
        "        X_tsfm = X_tsfm[13:114,13:114] + X_train_mean_img.squeeze()\n",
        "        y_orig = y_train[X_id[0]].squeeze()\n",
        "        y_tsfm = (y_batch[0].squeeze().cpu().detach().numpy())\n",
        "        y_tsfm_pred =  y_pred[0].squeeze().gt(train_params['mask_cutoff'])\n",
        "        plot_img_mask_pred([X_orig, X_tsfm, y_orig, y_tsfm, y_tsfm_pred],\n",
        "                           ['X Original', 'X Transformed', 'y Original', 'y Transformed', 'y Predicted'])\n",
        "        \n",
        "    return best_iou, best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfa9Y5hlxPBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model_to_git(epoch, train_params, num_epochs, prev_best_iou, best_iou, best_model):    \n",
        "    if (epoch % train_params['save_model_every']== 0) | (epoch == num_epochs-1):\n",
        "        if train_params['model_save_name'] is None:\n",
        "            log.info(\"Skip pushing model to git as model_save_name is None.\")\n",
        "        elif (best_model is not None) and (best_iou > prev_best_iou):\n",
        "            log.info(save_model_state_to_chunks(*best_model))\n",
        "            push_model_to_git(ckp_name=train_params['model_save_name'])\n",
        "            prev_best_iou = best_iou\n",
        "        else:\n",
        "            log.info(\"Skip pushing model to git as there's no improvement\")\n",
        "            \n",
        "    return prev_best_iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-pRk5cqxPBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_loss(y_pred, y_batch, loss_fns, loss_fn_weights):\n",
        "     losses = []\n",
        "     for loss_fn, loss_fn_weight in zip(loss_fns, loss_fn_weights):\n",
        "         loss = loss_fn_weight * loss_fn(y_pred, y_batch)\n",
        "         losses.append(loss)  \n",
        "\n",
        "     return torch.stack(losses + [torch.stack(losses).sum()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGqBDcs3xPBF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, loss_fns, loss_fn_weights, optimizer, scheduler, train_params, other_data):\n",
        "    log.info('Start Training...')    \n",
        "    log.info((dataloaders, loss_fns, loss_fn_weights, optimizer, scheduler, train_params))\n",
        "    num_epochs = train_params['num_epochs']\n",
        "    start = time.time()\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    best_model = None\n",
        "    best_iou = 0.0    \n",
        "    prev_best_iou = train_params['model_save_iou_threshold']\n",
        "    all_losses = []\n",
        "    iter_count = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        log.info('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        log.info('-' * 20)\n",
        "        if (epoch % train_params['save_log_every'] == 0):\n",
        "            push_log_to_git()\n",
        "        epoch_losses = []\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()      \n",
        "            pred_vs_true_epoch = []\n",
        "            for X_batch, y_batch, d_batch, X_id in dataloaders[phase]:\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    y_pred = model(X_batch)\n",
        "                    pred_vs_true_epoch.append([y_pred, y_batch])\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        losses = calc_loss(y_pred, y_batch.float(), loss_fns, loss_fn_weights)\n",
        "                        epoch_losses.append(losses)\n",
        "                        all_losses.append(losses)\n",
        "                        loss = losses[-1]\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        iter_count += 1\n",
        "            best_iou, best_model = log_epoch_stats(model, y_pred, y_batch, X_batch, X_id, other_data, pred_vs_true_epoch, train_params, \n",
        "                                                   phase, epoch, iter_count, best_iou, all_losses, epoch_losses, best_model)\n",
        "            \n",
        "        prev_best_iou = save_model_to_git(epoch, train_params, num_epochs, prev_best_iou, best_iou, best_model)\n",
        "        #from boxx import g\n",
        "        #g()\n",
        "        epoch_avg_loss = np.mean([e[-1].item() for e in epoch_losses])\n",
        "        #log.info(f'scheduler best: {scheduler.best} num_bad_epochs:{scheduler.num_bad_epochs}')\n",
        "        log.info(scheduler.step(epoch_avg_loss))\n",
        "\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model[1])\n",
        "    log.info('-' * 20)\n",
        "    log.info(f'Training complete in {(time.time() - start) // 60} mins. Best Val IOU {round(best_iou, 4)}')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dasEpZc0QmOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model using a small data set to see if it can overfit"
      ]
    },
    {
      "metadata": {
        "id": "2OoY1-HV8DZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = resnet34unet(in_ch=3, bilinear=False, pretrained=False)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "\n",
        "#scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True, threshold=0.001)\n",
        "model_save_name = None\n",
        "\n",
        "# Test Run\n",
        "#trained_model = train_model(saltnet, dataloaders, loss_fn_bce, loss_lovasz_hinge, optimizer, scheduler, model_save_name, \n",
        "#                other_data=all_data, num_epochs=100, print_every=8, save_model_every=None, save_log_every=None, log=log, loss2_weight=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HyYXwj79GWDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters()) + \n",
        "    list(saltnet.encoder2.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters()) + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-4},\n",
        "    {'params': unet_params, 'lr': 1e-3},\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zynbTA_GajD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet.center"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyLX1EVIxPBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': None,\n",
        "    'save_model_every': 10000,\n",
        "    'save_log_every': 100,\n",
        "    'num_epochs': 20,\n",
        "    'print_every': 2,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0,\n",
        "    'model_save_iou_threshold': 0.1\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOBrMR_y03nO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scheduler.num_bad_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pE7Q6dd3xPBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.5), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJ3DJ4hAQmOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the full with full dataset"
      ]
    },
    {
      "metadata": {
        "id": "AZkSxKV2sIkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with refactored Resnet 34 as backbone with Adam optimizer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3treVXh_Uha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.8, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "\n",
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss())\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "#optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters()) + \n",
        "    list(saltnet.encoder2.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters()) + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-4},\n",
        "    {'params': unet_params, 'lr': 1e-3},\n",
        "])\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.6)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_refactored_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 200,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.81\n",
        "    }\n",
        "    \n",
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yP2IQIkOD584",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ikq0ObjsDXc6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "#p.skew(probability=0.5, magnitude=0.2)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.8, min_factor=0.5, max_factor=0.9, mask_diff_pct=0.2)\n",
        "#p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8EUxk8UQmOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "saltnet = UResNet(pretrained=True)\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss()\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "#optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters()) + \n",
        "    list(saltnet.encoder2.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters()) + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-4},\n",
        "    {'params': unet_params, 'lr': 1e-3},\n",
        "])\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.6)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_refactored_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wq1P9vlMDo06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 200,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.81\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2z9Brb8EgMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YyeACdxT7K54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_data.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkzkKviGQ1ME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "metadata": {
        "id": "ebdMbovxitQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Use Unet with refactored Resnet 34 as backbone with Adam optimizer. Fine tune 1 with more data aug.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYo_x9uBitQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.3)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.8, min_factor=0.4, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=20, max_right_rotation=20)\n",
        "p.shear(probability=0.5, max_shear_left=20, max_shear_right=20)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "saltnet = UResNet(pretrained=True)\n",
        "model_file_suffix = \"Unet_res34_refactored_2018_09_29_21_39_01.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])\n",
        "\n",
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss()\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "#optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters()) + \n",
        "    list(saltnet.encoder2.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters()) + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-5},\n",
        "    {'params': unet_params, 'lr': 1e-4},\n",
        "])\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.6)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_refactored_fine_tune1_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 100,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.83\n",
        "    }\n",
        "\n",
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyT96FzKitQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFT3WG3sitQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.skew(probability=0.5, magnitude=0.3)\n",
        "p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.crop_random_align(probability=0.8, min_factor=0.4, max_factor=0.9, mask_diff_pct=0.2)\n",
        "p.rotate(probability=0.5, max_left_rotation=20, max_right_rotation=20)\n",
        "p.shear(probability=0.5, max_shear_left=20, max_shear_right=20)\n",
        "p.flip_left_right(probability=0.5)\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': False}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           np.zeros_like(X_train_mean_img), out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           np.zeros_like(X_train_mean_img), out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzSAx3majN5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrXlovtRjP49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wYx_90G8jFeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet = UResNet(pretrained=True)\n",
        "model_file_suffix = \"Unet_res34_refactored_2018_09_29_21_39_01.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDCMOP8aitQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0).type(dtype))\n",
        "loss_fn_bce = nn.BCEWithLogitsLoss()\n",
        "#loss_focal = FocalLoss(0.25, 2, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "#optimizer = torch.optim.Adam(saltnet.parameters(), lr=0.001)\n",
        "resnet_params = (\n",
        "    list(saltnet.conv1.parameters()) + \n",
        "    list(saltnet.encoder2.parameters()) + \n",
        "    list(saltnet.encoder3.parameters()) + \n",
        "    list(saltnet.encoder4.parameters()) + \n",
        "    list(saltnet.encoder5.parameters()) + \n",
        "    list(saltnet.encoder2.parameters())\n",
        ")\n",
        "\n",
        "unet_params = (\n",
        "    list(saltnet.center.parameters()) + \n",
        "    list(saltnet.decoder5.parameters()) + \n",
        "    list(saltnet.decoder4.parameters()) + \n",
        "    list(saltnet.decoder3.parameters()) + \n",
        "    list(saltnet.decoder2.parameters()) + \n",
        "    list(saltnet.decoder1.parameters()) + \n",
        "    list(saltnet.outc.parameters())\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam([    \n",
        "    {'params': resnet_params, 'lr': 1e-5},\n",
        "    {'params': unet_params, 'lr': 1e-4},\n",
        "])\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, threshold=0.0001, min_lr=0.00001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.6)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_res34_refactored_fine_tune1_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtVbIYqPitQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_params = {\n",
        "    'model_save_name': model_save_name,\n",
        "    'save_model_every': 20,\n",
        "    'save_log_every': 2,\n",
        "    'num_epochs': 100,\n",
        "    'log': log,\n",
        "    'mask_cutoff': 0.,\n",
        "    'model_save_iou_threshold': 0.83\n",
        "    }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63F266sphX6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_model(saltnet, dataloaders, (loss_fn_bce, loss_lovasz_hinge), (1, 0.1), optimizer, scheduler, train_params, all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHlYUA8djspQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwLpLOyAjsxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUaoviPyhYJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fine tune 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8D60yP5hYdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info('Fine tune Unet_bce_loss_lovasz_loss_se_finetune_2018_09_15_08_56_34 net. Remove hard images. Use lovasz loss only with SGD. Less data aug')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLCZ7qsFhYYz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_config = '''\n",
        "p = Pipeline_Salt(min_mask_ratio=0.1)\n",
        "#p.skew(probability=1, magnitude=0.5)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.zoom(probability=0.5, min_factor=1.05, max_factor=1.2)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "p.crop_random(probability=0.5, percentage_area=0.8, randomise_percentage_area=False)\n",
        "p.resize(probability=1, width=101, height=101, resample_filter='BILINEAR')\n",
        "\n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values, depth_train.shape[0])\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': True}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           X_train_mean_img, out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}\n",
        "\n",
        "#saltnet = loaded_model\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss()\n",
        "loss_focal = FocalLoss(0.25, 2.0, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "optimizer = torch.optim.SGD(saltnet.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_lovasz_loss_se_finetune6_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "# Test Run\n",
        "trained_model = train_model(saltnet, dataloaders, loss_focal, loss_lovasz_hinge, optimizer, scheduler, model_save_name, \n",
        "                other_data=all_data, num_epochs=300, print_every=44, save_model_every=20, save_log_every=2, log=log, loss1_weight=0.0, loss2_weight=1.)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nuk-O_sohYU4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log.info(model_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Le_5UumAnH_V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7EHw_lzhYQu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt(min_mask_ratio=0.1)\n",
        "#p.skew(probability=1, magnitude=0.5)\n",
        "#p.random_distortion(probability=0.5, grid_width=3, grid_height=3, magnitude=3)\n",
        "p.rotate(probability=0.5, max_left_rotation=10, max_right_rotation=10)\n",
        "#p.zoom(probability=0.5, min_factor=1.05, max_factor=1.2)\n",
        "p.shear(probability=0.5, max_shear_left=10, max_shear_right=10)\n",
        "p.flip_left_right(probability=0.5)\n",
        "p.crop_random(probability=0.5, percentage_area=0.8, randomise_percentage_area=False)\n",
        "p.resize(probability=1, width=101, height=101, resample_filter='BILINEAR')\n",
        "\n",
        "#weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_sample_weight.values, depth_train.shape[0])\n",
        "\n",
        "train_data_params = {'batch_size': 32,\n",
        "                     #'sampler': weighted_sampler,\n",
        "                     'shuffle': True,\n",
        "                     'drop_last': True}\n",
        "\n",
        "val_data_params = {'batch_size': 32,\n",
        "                   'shuffle': True,\n",
        "                   'drop_last': False}\n",
        "\n",
        "train_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_train, y_train, depth_train,\n",
        "                           X_train_mean_img, out_size=128,  out_ch=1,\n",
        "                           transform=p.torch_transform(), random_brightness=0.5), **train_data_params)\n",
        ")\n",
        "\n",
        "val_dataLoader = (\n",
        "    DataLoader(SaltDataset(X_val, y_val, depth_val, \n",
        "                           X_train_mean_img, out_size=128, out_ch=1), **val_data_params)\n",
        ")\n",
        "\n",
        "dataloaders = {'train': train_dataLoader, 'val':val_dataLoader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFn5Yp8JiHrb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXgY-SnsiH6H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saltnet = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)\n",
        "model_file_suffix = \"Unet_bce_loss_lovasz_loss_se_finetune_2018_09_15_08_56_34.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "saltnet.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKG-3gxECxlG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ej3k1zVvibz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saltnet = loaded_model\n",
        "#loss_fn_bce = nn.BCEWithLogitsLoss()\n",
        "loss_focal = FocalLoss(0.25, 2.0, logits=True)\n",
        "loss_lovasz_hinge = LovaszHingeLoss()\n",
        "optimizer = torch.optim.SGD(saltnet.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)\n",
        "\n",
        "model_save_name = f'../salt_net/Unet_lovasz_loss_se_finetune6_{get_current_time_as_fname()}.ckp'\n",
        "log.info(model_save_name)\n",
        "\n",
        "# Test Run\n",
        "trained_model = train_model(saltnet, dataloaders, loss_focal, loss_lovasz_hinge, optimizer, scheduler, model_save_name, \n",
        "                other_data=all_data, num_epochs=300, print_every=44, save_model_every=20, save_log_every=2, log=log, loss1_weight=0.0, loss2_weight=1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9MW3YwaZQmOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Trained Model"
      ]
    },
    {
      "metadata": {
        "id": "ESBVbot1Qp7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIRv-uXQGROz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded_model = UNet(n_channels=1, n_classes=1, bilinear=True, logits=True, apply_se=True, r=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDpBS2c9ePeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd ../salt_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cuoeW6MLd439",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_file_suffix = \"Unet_bce_loss_lovasz_loss_se_2018_09_14_12_35_12.ckp\"\n",
        "model_state_dict = torch.load(join_files(model_file_suffix, '.', returnFileObject=True, removeChunks=False))\n",
        "loaded_model.load_state_dict(model_state_dict['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbgxXtYH3KpR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Predictions on validation set"
      ]
    },
    {
      "metadata": {
        "id": "W0cFNMM0QmO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set model to evaluation mode"
      ]
    },
    {
      "metadata": {
        "id": "izo8iByg3KpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded_model.eval()\n",
        "assert loaded_model.training == False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfdN-P-j3KpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_dataLoader = DataLoader(SaltDataset(X_val, y_val, depth_val, X_train_mean_img, out_size=128), batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7M0ZHG7o6swA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    loaded_model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMuArCUd3KpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_val_batch, y_val_batch, depth_val_batch, X_val_id_batch in val_dataLoader:\n",
        "        y_val_pred.append(loaded_model(X_val_batch))\n",
        "y_val_pred = torch.cat(y_val_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7EYzvT0fyPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.flip_left_right(probability=1)\n",
        "val_dataLoader = DataLoader(SaltDataset(X_val, y_val, depth_val, X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=p.torch_transform()), batch_size=16)\n",
        "y_val_pred_flip = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_val_batch, y_val_batch, depth_val_batch, X_val_id_batch in val_dataLoader:\n",
        "        y_val_pred_flip.append(loaded_model(X_val_batch))\n",
        "y_val_pred_flip = torch.cat(y_val_pred_flip)\n",
        "y_val_pred_flip = torch.flip(y_val_pred_flip,[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FZNYVKKPf0if",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_ens = torch.where(y_val_pred.abs() > y_val_pred_flip.abs(), y_val_pred, y_val_pred_flip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSYVoI88HApH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(0, X_val, y_val_pred.gt(0), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "230OrjoPf0_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(0, X_val, y_val_pred_ens.gt(0.113), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZvUQtjqG_uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MASK_CUTOFF = 0.113"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMy51k_WgCEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in np.r_[0.05:0.35:20j]:\n",
        "  print(i)\n",
        "  y_val_pred_adj = adjust_predictions(0, X_val, y_val_pred_ens.gt(i), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_ka-iqTgCYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxNTal6nS8Za",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataLoader = DataLoader(SaltDataset(X_train, y_train, depth_train, X_train_mean_img, out_size=128), batch_size=16)\n",
        "y_train_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_train_batch, y_train_batch, depth_train_batch, X_train_id_batch in train_dataLoader:\n",
        "        y_train_pred.append(loaded_model(X_train_batch))\n",
        "y_train_pred = torch.cat(y_train_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_DJpL1o3KpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_val_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    val_img = X_val[rand_id]/255\n",
        "    val_mask = y_val[rand_id]\n",
        "    val_mask_pred = y_val_pred.ge(0.5)[rand_id]\n",
        "    plot_img_mask_pred([val_img, val_mask, val_mask_pred], range(3), img_per_line=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkD6eqk9ghEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_train_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    img = X_train[rand_id]/255\n",
        "    mask = y_train[rand_id]\n",
        "    mask_pred = y_train_pred.ge(0.5)[rand_id]\n",
        "    plot_img_mask_pred([img, mask, mask_pred], range(3), img_per_line=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFW4BqZx8VzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ZERO_MASK_CUTOFF = 0\n",
        "MASK_CUTOFF = 0.113"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMbnI4J6Jkr1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred_ens.gt(MASK_CUTOFF), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgcUBfKx8rpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in range(0, 300, 10):\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(cut_off, X_val, y_val_pred_ens.gt(MASK_CUTOFF), y_val.squeeze()), y_val.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KcfUIfJyNna6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "range(0, 300, 10)[np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1j58cIWfqxj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmT8DPBnGRPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_val_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_val, y_val_pred.gt(MASK_CUTOFF), y_val.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCR_6IO1g7xE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_train, y_train_pred.gt(MASK_CUTOFF), y_train.squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeXdGnrPgIDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for cut_off in range(0, 300, 10):\n",
        "  print(cut_off)\n",
        "  results.append(calc_mean_iou(adjust_predictions(cut_off, X_train, y_train_pred.gt(MASK_CUTOFF), y_train.squeeze()), y_train.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQErtiLSgZPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "range(0, 3000, 10)[np.argmax(results)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1oSze9o3Kp_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions on test set"
      ]
    },
    {
      "metadata": {
        "id": "c-M7XAbPhcUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xzKpwGrhcOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6ocZkIAS8Zf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test_dataLoader = DataLoader(SaltDataset(np_test[:10], None, depth_test, X_train_mean_img), batch_size=4)\n",
        "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, out_size=128), batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ChMRx1kh3KqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_raw = []\n",
        "with torch.no_grad():\n",
        "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
        "        y_test_pred_raw.append(loaded_model(X_test_batch))\n",
        "y_test_pred = torch.cat(y_test_pred_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M52jKbLA3KqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encode predictions using RLE(Run Length Encoding) method"
      ]
    },
    {
      "metadata": {
        "id": "uW0shno43KqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_rle = rle_encoder3d(y_test_pred_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdPQnJqUS8Zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_adj.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GaCKooz3KqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle = pd.DataFrame(index=misc_data['np_test_ids'], data=y_test_pred_rle).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loaXDzkM3KqQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.columns = ['id', 'rle_mask']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_iM1oRr3KqS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle[df_test_rle.rle_mask==''].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJzlb6q7cCM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09CFLpNL3KqY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.to_csv(f'submission_{get_current_time_as_fname()}.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-yT6TajkR6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_1B43JYGRQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yV3mMqgRkYBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('submission_2018_09_15_00_18_33.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZkzyRPIMDrAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TTA"
      ]
    },
    {
      "metadata": {
        "id": "x38qXbAkmFSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfLrLArrEK5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict using original image"
      ]
    },
    {
      "metadata": {
        "id": "bUDZxfzlD_Os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, out_size=128), batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqKBooA3EC4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_raw = []\n",
        "with torch.no_grad():\n",
        "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
        "        y_test_pred_raw.append(loaded_model(X_test_batch))\n",
        "y_test_pred = torch.cat(y_test_pred_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7BiVrQKEFrk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict using flipped images"
      ]
    },
    {
      "metadata": {
        "id": "KjPkHzKBmz7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = Pipeline_Salt()\n",
        "p.flip_left_right(probability=1)\n",
        "test_dataLoader = DataLoader(SaltDataset(X_test, np.zeros_like(X_test), depth_test, X_train_mean_img, out_size=128, out_ch=1,\n",
        "                           transform=p.torch_transform()), batch_size=32)\n",
        "y_test_pred_flip = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_test_batch, y_test_batch, depth_test_batch, X_test_id_batch in test_dataLoader:\n",
        "        y_test_pred_flip.append(loaded_model(X_test_batch))\n",
        "y_test_pred_flip = torch.cat(y_test_pred_flip)\n",
        "y_test_pred_flip = torch.flip(y_test_pred_flip,[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9t1Z0kiEQkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Combine non-flip and flip predictions"
      ]
    },
    {
      "metadata": {
        "id": "_zUtOPXwmz7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = torch.where(y_test_pred.abs() > y_test_pred_flip.abs(), y_test_pred, y_test_pred_flip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzkEuhBwEXBl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Adjust predictions"
      ]
    },
    {
      "metadata": {
        "id": "89y4w6drFKSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'MASK_CUTOFF:{MASK_CUTOFF}, ZERO_MASK_CUTOFF:{ZERO_MASK_CUTOFF}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSe7dmyMqnPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_adj = adjust_predictions(ZERO_MASK_CUTOFF, X_test, y_test_pred.gt(MASK_CUTOFF))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pd9DjVswEwUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Show segmentation masks for a few images"
      ]
    },
    {
      "metadata": {
        "id": "c9j_HYo6ExVL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    rand_id = np.random.choice(X_test_id_batch)\n",
        "    print(f'Image ID: {rand_id}')\n",
        "    img = X_test[rand_id]/255\n",
        "    mask_pred = y_test_pred.ge(0.5)[rand_id]\n",
        "    plot_img_mask_pred([img, mask_pred], range(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bmi3NISwEaOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare for submission"
      ]
    },
    {
      "metadata": {
        "id": "fATv5NS6hnkU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_rle = rle_encoder3d(y_test_pred_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBNylCIDhnkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_pred_adj.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hwSpGmvthnkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle = pd.DataFrame(index=misc_data['np_test_ids'], data=y_test_pred_rle).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r3bS6FoNhnki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.columns = ['id', 'rle_mask']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRDcCLpohnkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle[df_test_rle.rle_mask==''].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkOmz86lhnkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xr_NOtxBhnky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_test_rle.to_csv(f'submission_{get_current_time_as_fname()}.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n__2CiMjhnk2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCv-diichnk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgzFDdcShnlA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('submission_2018_09_20_23_11_23.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1D61fkPaiUR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}